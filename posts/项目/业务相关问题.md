
# 业务相关问题

## 推荐系统之特征一致性

### 什么是特征一致性

对于同一个输入特征，无论离线还是线上，经过特征抽取后，得到的输出值也相同。即特征一致性的两个比较对象是指离线和在线。具体而言：

* 离线：对离线样本（有标签）调用Spark或者Flink等任务，得到离线特征输出值
* 线上：对线上样本（无标签）调用C++调用特征抽取服务，得到线上特征输出值

![image-20240904102219-tuenw0g](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20240904102219-tuenw0g.png)​

#### 特征不一致原因

由于离线和线上数据流转的链路不同，即使是相同的特征处理逻辑，有可能得到不同的输出值。具体而言，存在两大方面原因：

**1）输入特征不一致**

* 线上获取不到某个特征导致和离线特征对不齐（离线特征同步任务失败 或者 透传字段协议变更）

  * 简单说就是，离线取值时候，可能是前两天或者晚上的数据，而在线侧是实时的值（比如价格，库存已经变更过）
* 线上特征查询时，代码bug（key错误或者redis配置错误），导致查询结果异常

**2）特征抽取逻辑不一致**

* 线上特征由C++处理，离线特征由 Scala/sql处理。不同语言底层库实现存在区别差异，导致在线/离线特征diff
* 即使对齐底层库实现，由于不同语言的重复代码逻辑开发，难免产生编写bug，导致在线/离线特征diff

#### 特征一致性校验方案设计实践

**1）针对 输入特征不一致（版本号）**

基于protocol格式的Snapshot特征快照——离线/在线统一特征定义。

在线上实时预估同时会将全部特征落下（该特征称为Snapshot特征快照，而这些特征都来自于特征服务）。

**2）针对 特征抽取逻辑不一致**

Feature Extractor算子库 + 特征[配置文件](https://zhida.zhihu.com/search?q=%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6&zhida_source=entity&is_preview=1)——离线/在线统一特征抽取

构建特征抽取算子库，将所有算子封装成**一套特征抽取算子库，** 抽成一个jar包，算法侧调用jar包使用。

这带来两点好处：

* 只要在线/离线输入数据一致，则特征抽取结果必然一致
* 避免不同语言代码的重复开发

具体使用方式为：

* 离线：在Spark中通过JNI调用jar包特征抽取算子so，生成离线的哈希样本，用于离线模型训练
* 在线：实时预估框架调用算子，生成在线的哈希样本，用于在线模型推理

### 特征一致性校验方案设计

#### 背景

新模型上线前需要进行离线线上特征一致性校验。人工手动检验，费时费力。这里介绍一套规范的特征一致性校验方案设计，可为算法效果迭代提效。

本文假设离线采用线上和离线不一致产生的根源为：线上和线下的用户特征不一样。

* 线上：拼上**实时的**用户侧特征后，将样本送入在线模型进行打分。
* 离线：拼上**前一天**的离线用户侧特征，将样本送入离线模型打分。

线上和线下的模型是完全一样的，但是用户的特征不一样。由于用户侧特征的差异，造成线上和线下打分存在一定的偏差。对于一致性的校验，存在两个不同层次的维度：

1）打分一致性

将线上打分的日志落下来，包括每个特征，然后再把包含特征的样本输入到离线的模型中，得到的打分和线上的打分对比，如果流程是正确的，那么两者的打分也一定是相同的（相当于在还原当时的情况）。这样就验证了线上和线下是一致的。

2）特征一致性

只要打分一致，说明特征一定一致。反之可不一定成立。

#### 具体流程

![image-20240904102432-aqcdq1k](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20240904102432-aqcdq1k.png)​

* tep0：通过『[月光宝盒](https://zhida.zhihu.com/search?q=%E6%9C%88%E5%85%89%E5%AE%9D%E7%9B%92&zhida_source=entity&is_preview=1)』，录制线上流量。将基线模型的Request和Response存入后台ES中。
* Step1：线上部分。在预发环境部署新的模型服务，对其进行流量回放。服务打开debug开关，将『线上pb样本』和『线上hash样本』落入kafka。
* Step2：离线部分。消费kafka中『线上pb样本』落地hdfs，并执行离线spark调用jni包抽取得到『离线hash样本』，再对『离线hash样本』调用离线模型预估出离线打分（offline score2）
* Step3：将『线上hash样本』和『离线hash样本』进行一致性对比，验证特征一致性
* Step4：将Response中基线模型的打分（online score1）和新模型线上打分（online score2）以及新模型离线打分（offline score2）三者之间对比，验证打分一致性
* Step5：借用『月光宝盒』现有能力，进行前端页面结果展示

> 备注：月光宝盒——具有流量录制和回访功能的一个服务，类似于蓄水池。同时还支持统计和UI页面展示等功能。

# 推荐模型离线评测效果好，线上效果却不佳的原因

在推荐算法领域，时常会出现模型离线评测效果好，比如AUC、准召等指标大涨，但上线后业务指标效果不佳，甚至下降的情况，比如线上CTR或CVR下跌。

本文尝试列举一些常见的原因，为大家排查问题提供一点思路。

## **离线、在线特征不一致**

### 特征处理，离线侧和在线侧实现不一致

离线、在线特征的ETL过程通常不是由同一份代码完成的，比如，离线特征的计算过程一般是使用SQL语言在大数据平台上完成，而在线特征的加工通常是由C++、Go这样的语言计算得到。这样就存在相同的逻辑需要实现两次，而且可能是不同的人来实现，如果不仔细测试，出现不一致的可能性还是很高的。要严格保证线上线下的特征一致性，最根本的方法就是同一套代码和数据源抽取特征。

### **输入特征不一致**

离线侧取值时候，可能是前两天或者晚上的数据，而在线侧是实时的值（比如价格，库存已经变更过）

### **特征更新存在延迟**

一些需要实时计算得到的特征，如实时统计特征、序列特征等，离线模拟时不存在问题，然而，上线后由于各种原因，如果不能及时更新，那就造成了离线、在线的特征分布不一致，相当于是模型[过拟合](https://zhida.zhihu.com/search?q=%E8%BF%87%E6%8B%9F%E5%90%88&zhida_source=entity&is_preview=1)了。小时级更新、天级更新的特征，也有可能出现更新延迟的问题。

## **存在数据泄露**

数据泄露（data leakage），有时也叫做泄露、穿越等。

* **训练数据泄露**：在预处理数据时错误地使用了测试数据或未来数据来影响训练数据。
* **特征泄露**：在特征选择时错误地包括了直接或间接包含目标变量信息的特征。

> 假设你正在构建一个模型来预测用户是否会点击在线广告。
>
> **场景**：你决定使用用户是否与广告发生了交互（比如点击广告）作为特征之一。
>
> **错误做法**：如果你在训练模型时包括了“用户是否点击了广告”作为特征，那么这个特征实际上就是你的目标变量（标签）。这意味着模型可以直接使用这个特征来预测结果，而不是学习如何基于其他特征来预测点击行为。
>
> **正确做法**：应该排除任何直接或间接包含目标变量信息的特征。在这个例子中，你需要排除“用户是否点击了广告”这个特征，而应该使用其他可能与点击行为相关的特征，如用户的历史行为、广告的展示位置、广告内容等。

## **数据分布不一致**

* **数据分布随时间发在漂移**。例如，营销平台的大促活动、季节的变化、流行元素和审美标准的变化等等。
* 同期，同一个品类，看其他平台是否有大促（之前就遇到过，某个品类cvr降的很多，后来发现是pp再搞大促）

## **时间序列偏差**

假设离线评测用的测试数据是与训练数据是根据最近14天的一些数据产生的，假如训练和用来验证的数据是9:1，如果随机hash(queryId)就可能造成数据一些极端的情况。比如训练是最近13天的数据，而验证是14天前的数据，这样就没有意义了，效果也自然不会好。

一般像这种预测类的，训练数据都是取近14天（剔除掉t-1的数据），然后用t-1的数据进行验证。

‍
