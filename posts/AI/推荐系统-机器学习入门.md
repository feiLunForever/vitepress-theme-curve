---
title: 推荐系统-机器学习入门
tags:
  - AI
categories:
  - AI
date: '2025-01-13'
description: 欢迎使用 Curve 主题，这是你的第一篇文章
articleGPT: 这是一篇初始化文章，旨在告诉用户一些使用说明和须知。
#cover: "/images/logo/logo.webp"
---

#   推荐系统-机器学习入门

# 推荐系统-机器学习入门

‍

## 协调过滤物料生成 和 召回机制拆解

### 协调过滤

协同过滤这一经典且有效的推荐系统召回机制，包括基于用户兴趣和基于内容相似性的两种协同方式。通过用户行为日志训练模型，生成物料向量并存储在数据库中，实现快速召回相关物料。协同过滤适用于信息流、短视频等产品，能显著提升用户关注度和兴趣匹配度。

#### 分类

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828101720-wnys6vt.png)​

##### 基于用户协同

举个简单例子，在这里面假设有一个用户他看过了A和C的内容，另外一个用户看过ACD由于他们俩同时都看了A和C我们在这里面就可以判断做了一个初步的判断。这两个用户很相似。那么当这个用户在刷新新的内容的时候，我们会将他们这个跟他相似，另外别的用户看过的内容推给他。那这就跟我们朋友圈的一样，就是说你的朋友的朋友的朋友，他大家都看了好几篇文章。那么相信你跟他们成为朋友的话，按理说你们的兴趣是相同的那这样会把那些内容推给你，其实这个就是基于用户一些兴趣的一个聚合的方式来去做协同。



##### 基于内容协同

另外一种方式是反过来，我们不关注用户，关注的是内容。那就是说如果很多人都同时都访问了A和C那么我认为A和C相似的。那以后当有人看了A了之后，我们会给他推荐C这是你这么个思路。

> 其实用户协同和内容协同，他们的本质都是基于用户的行为来去做一个统计和一个叫做聚类的一个挖掘。无论是哪种方法，其目标都是通过对大量用户行为数据的统计和挖掘，构建用户与内容之间的关联网络，以实现更精准、个性化的推荐。这种机制特别适用于大规模数据集，且随着参与用户数量的增加，推荐的准确度将持续提升。

#### 召回

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828101810-648slrf.png)​

#### 适用场景

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828101832-vrhamsh.png)​

协同过滤是一种广泛应用于信息流、短视频产品和电商平台的推荐系统技术，能够基于用户的历史行为或偏好进行个性化内容推荐。

* 其中，`用户协同`​主要挖掘用户的共同兴趣，适合信息更新迅速、用户群体较为稳定的场景（冷启动有问题）；

  * 举个简单例子，拿头条和微博来说的话，用户的关注度可能相对来说会或者兴趣度相对来说是比较相似的。
  * 当有新的一些新闻或者新的一些事件产生的时候，其实我们只要我知道有朋友看过了，我朋友的朋友给我看过了之后，我们把相关内容推荐给这个新的同学。在这里边的话，它的好处是在于对我们这种内容这一块的响应和快速更新这一块是非常适合的。
  * 但是它有个问题是在于，如果我来了一个新的用户，在新的用户我跟别的就是别的我们就是用户的这种用户群其实是没有任何的交集，因为它没有产生任何的行为，我们也获取不到这用户他的一个是实际的这种兴趣是什么样的。这时候冷启动是存在问题的。

* 而`内容协同`​则侧重于通过分析物品本身的属性来进行推荐，特别适合处理长尾物品和解决冷启动问题。

  * 一般是也是常见于在电商和相对来说我们物品比较固定的一些场景里边。
  * 电商里边它的就是一个假设是用户的兴趣相对稳定，内容的话就是说我们通过内容的这种相似来去满足用户的这种兴趣。那么在这里边如果是长尾的物品的话，是非常适合的，而且它也对冷启动来说比较友好。
  * 因为我们不需要关注是这个用户访问过哪些内容。我只关心这个内用户访问这个商品的时候，我给他推荐相类似的商品。

为了提高推荐系统的性能，可以采用多路召回策略，并通过向量召回方法综合考虑不同类型的召回结果，从而实现更加准确和个性化的推荐服务。

### 常见召回算法

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828110320-12u8r5f.png)​

### 物料向量召回机制拆解

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828101859-2o524jt.png)​

> 在前面的多路召回里边的话，其实有一个问题，就是说我们同时很多路内容召回回来的时候会有一个问题，我们会不断的去调整了一些参数。
>
> 比如说不同的召回我们的权重是多少？比如说同样都是1000条，我应该多侧重给热门的还是兴趣的，还是给那个协同过滤的，可能会调整比例，这里边就会涉及到大量的这种调试和尝试的问题。
>
> 有没有一种方式说既考虑了前面的这些几个，不管是热门也好，还有兴趣也好，还是协同的也好这种特点。同时又能满足我们的一些往召回方面的一些性能方面的要求。

边业内有一个叫做向量召回的方式，原理是这样的，就是说用户的特征和物料的特征，我们放到模型里面进行相互学习，得到一个近似的空间分布的时候。最后在这个图上的话，这个空间我们相似的时候，最后当我们拿用户的一些特征的时候，我们放在模型会得到用户的一些向量。意味着跟这个用户限量那些物料，就是我们要召回的内容。

在这里边的话会用到一些神经网络，就是我们深度学习神经网络的一些算法。

#### 过程

首先是分两个大环节。

* 第一个环节是我们物料要进行一个生成，物料向量生成。
* 首先我们会拿用户的行为日志，比如说拼接成相应的样本之后，我们放到模型里面进行训练。
* 训练好了模型，其实我们都得到双塔了，就可以大家理解为两个输入。左边一个user的一些特征，要特别是item的特征放在这里边的话，会生成相关的一些，我们会拿的我们新的一些物料会生成相关的向量，得到向量之后放到我的向量数据库里面，就是物料的向量数据库。
* 之后在我们在线召回的时候，首先先拿到用户的特征。拿了用户的特征之后，通过这个模型得到用户的向量。这个向量。然后得到用户向量之后，我们做一个检索，就是我要做向量检索之后，会得到相关类似的物料和item的一些列表，最后再给排序。

## 预测评估排序

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828103548-olsgxey.png)​

### 常见的过滤策略

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828103614-4sv3182.png)​

* 垃圾内容过滤：涉黄涉政内容的排除。
* 控制数量和比例：提升推荐内容多样性，避免推荐越窄。
* 重复内容过滤：避免推荐相似内容，提高用户体验。
* 黑名单策略：已读内容的排除。

### 排序机制

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828103735-y1y2wv7.png)​

> 粗排与精排：例如，粗排环节可能根据用户在线阅读时长进行排序，筛选出可能感兴趣的内容；精排环节则可能根据预设点击率模型进行更细致的排序。

#### 人工策略实现

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828104206-vjphny1.png)​

1. 总体策略：例如，电商平台如淘宝在推荐时，不仅考虑头部商家的商品，也会给予中小商家适当的流量扶持。
2. 合规性要求：例如，确保推荐内容的合法性和符合社会公正原则。
3. 内容多样性调整：例如，即使某些内容的排序得分较低，也会根据策略进行适当提权，以丰富推荐内容的多样性。
4. 时间降权：例如，对于新闻类信息流，随着时间推移，旧新闻的推荐权重会降低。
5. 运营扶持：例如，扶持大V账号，或者对某些长尾物料进行提权，以促进平台内容的多样性。
6. 召回策略调整：例如，根据不同召回环节的特点，调整其权重，以优化推荐效果。

#### 排序过程中的特征工程

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828104045-y9okigx.png)​

排序过程中的特征工程：例如，对于用户特征，可能包括用户兴趣、活跃度、手机终端类型、网络环境、地理位置等；对于物料特征，可能包括内容的标签、质量等级、热度等。

## 机器学习

### 机器学习基础概念

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828104920-mvp9k7q.png)​

机器学习可以理解为一系列数学公式或算法，其输入是内容信息（如商品、视频等），结合用户和上下文环境信息，输出是预测的目标（如购买、点击、阅读时长等）。

### 机器学习与推荐系统的结合

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828105028-0d1lgei.png)​

* 机器学习在推荐系统中的应用，特别是在召回和排序环节的作用。
* 推荐系统中，算法只是其中一小部分，大部分工作涉及数据处理、样本拼接、特征处理等。

### base离线机器学习

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828105231-dxufuqz.png)​

#### 推荐系统的整体流程

1. 内容发布与审核

    * 用户发布内容（如商品、短视频）后，系统进行人工智能审核，包括垃圾内容过滤和时政敏感内容审核。
2. 内容理解

    * 使用机器学习算法（如NLP、CV）对多媒体和文本内容进行理解，生成特征并存入特征库。
3. 物料挖掘与召回

    * 根据用户行为日志生成用户特征和内容特征，用于物料挖掘和召回策略。
4. 用户行为记录

    * 用户看到的内容和其行为信息被记录到系统中，通常存储在数据仓库（如Hadoop Hive）。

#### 机器学习的实现环节

1. 离线样本生成

    * 使用SQL（如Hive SQL、Spark SQL）生成离线样本。
2. 模型训练

    * 模型训练涉及大量数据（数千万到数亿样本），训练完成后生成模型。
3. 在线服务

    * 将模型加载到机器学习推理机上，通过RPC或HTTP接口提供在线服务。

### 在线机器学习

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828105526-7t9d6oh.png)​

* 在线机器学习能实时捕获用户行为和兴趣分布，提高模型迭代速度和实时性。
* 技术实现：使用消息队列（如Kafka）和实时处理技术（如Flink）。

## 矩阵分解

### 矩阵分解的背景与目的

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828110320-12u8r5f.png)





* 矩阵分解是协同过滤的一种实现机制，用于解决大规模用户和内容之间的推荐问题。
* 传统协同过滤方法通过找到相似的用户或内容来推荐，而矩阵分解通过矩阵分解的方式实现。

### 原理

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828110835-rtjuawy.png)​

* 矩阵分解将用户对内容的评分矩阵分解为两个矩阵：用户的特征矩阵和内容的特征矩阵。
* 这两个矩阵通过一个共同的特征向量（k）连接，k的大小通常较小（如30到100）。
* 特征向量挖掘用户和内容之间的共同特征，如类型、年龄等。

> 下面是一个简化的例子来说明这一过程：

假设有一个用户-物品评分矩阵，其中包含1000个用户和1000个物品，每个单元格表示一个用户对一个物品的评分。这个矩阵可以表示为：

```java
    A   B   C   D   E
1  5.0  4.0  3.0  2.0  1.0
2  4.0  5.0  3.0  2.0  1.0
3  3.0  4.0  5.0  2.0  1.0
...  ...  ...  ...  ...  ...
1000 1.0  2.0  3.0  4.0  5.0
```

矩阵分解的目标是将这个高维的评分矩阵分解为两个低维的矩阵：一个用户的特征矩阵和一个物品的特征矩阵。假设我们选择一个特征向量k（特征向量的数量），这个特征向量可以是[3, 2, 1]，代表三个特征，每个特征的大小分别为3, 2, 1。

用户特征矩阵和物品特征矩阵可以通过以下方式计算：

用户特征矩阵（用户1到用户1000）:

```java
    A'   B'   C'
1  5.0  4.0  3.0
2  4.0  5.0  3.0
3  3.0  4.0  5.0
...  ...  ...  ...
1000 1.0  2.0  3.0
```

物品特征矩阵（物品1到物品1000）:

```java
    A''   B''   C''
1  5.0  4.0  3.0
2  4.0  5.0  3.0
3  3.0  4.0  5.0
...  ...  ...  ...
1000 1.0  2.0  3.0
```

其中，A’, B’, C’, …, A’‘, B’‘, C’', … 是对应的特征值。

最后，我们可以通过用户特征矩阵和物品特征矩阵计算出一个近似的评分矩阵：

```java
    A   B   C   D   E
1  5.0  4.0  3.0  2.0  1.0
2  4.0  5.0  3.0  2.0  1.0
3  3.0  4.0  5.0  2.0  1.0
...  ...  ...  ...  ...  ...
1000 1.0  2.0  3.0  4.0  5.0
```

这个近似的评分矩阵是通过用户特征矩阵和物品特征矩阵的点积得到的：

```java
A = U * V^T
```

其中，U是用户特征矩阵，V是物品特征矩阵。通过这个近似的评分矩阵，我们可以对未评分的内容进行预测，从而实现推荐。

> 总结来说，矩阵分解通过将高维的评分矩阵分解为低维的用户特征矩阵和物品特征矩阵，从而降低了计算的复杂度，使得推荐系统能够在大规模数据集上进行有效的推荐。

### 矩阵分解的使用场景

#### 用户对内容的推荐（u to i）

* 通过矩阵分解得到的近似矩阵预测用户可能喜欢的内容。
* 计算内容得分的top结果，作为召回结果。

> * 假设用户A之前没有看过电影《妇联4》和《你好，李焕英》。
> * 通过矩阵分解，系统可以预测用户A对这些电影的潜在喜好，并给出一个评分。
> * 系统会计算一个top结果，即用户A可能喜欢的内容列表，并将这些内容作为召回结果推荐给用户A。

#### 内容对内容的推荐（i to i）

* 基于内容和内容之间的相似度进行推荐。
* 例如，如果一个用户喜欢一部科幻片，系统可能会推荐其他科幻片。

> * 假设用户A观看了电影《流量地球》。
> * 系统会基于电影《流量地球》和《妇联4》的相似度，推荐其他与《流量地球》相似的电影给用户A，例如《战狼》。
> * 这里，系统通过矩阵分解计算出电影之间的相似度，从而实现内容对内容的推荐。

#### 用户对用户的推荐（u to u to i）

* 基于用户和UP主之间的相似度，推荐UP主相似的内容。

> * 假设用户A和用户B都喜欢同一个UP主的内容。
> * 系统会计算用户A和用户B之间的相似度，并根据这个相似度推荐用户B喜欢的内容给用户A。
> * 这里，系统通过矩阵分解计算用户之间的相似度，从而实现用户对用户的推荐。

### 矩阵分解的实现流程

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828111544-uv6a73g.png)​

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828112201-z67qnfg.png)​

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828112254-tmp8wt5.png)​

1. 生成样本

    * 一般是记录用户行为日志，存储到离线HIVE表
    * 基于用户行为日志，统计评分，一般来说，会将用户的点击、评论、赞、转发、关注等显示互动行为，和阅读/播放时长等隐式行为，统计为一个评分。
2. 模型训练

    * 使用Spark或Flink等工具进行模型训练，将样本分解为用户和内容的特征向量。
3. 相似度计算

    * 计算用户和内容、内容之间的相似度。
4. 物料入库

    * 离线计算，存入redis中
5. 内容召回

    * 从物料库中召回用户可能喜欢的内容。

### 矩阵分解的特点

1. 结合了语义信息和机器学习特性。
2. 精准度高，效果优于传统统计类方法。
3. 实现简单，时间和空间复杂度较低。
4. 具有embedding特性，可以应用于多种场景。
5. 训练耗时较长，依赖大量训练数据。
6. 可解释性不强，需要调优和调参。
7. 缺乏上下文信息，难以捕捉用户真实兴趣。

### 总结

* 矩阵分解是一种优秀的推荐算法，适用于新产品早期阶段，具有简单清晰的工程实现流程。
* 其离线计算部分对稳定性要求较低，而线上调用部分较为稳定。

## word2vec原理

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828134320-ubdf5z0.png)​

* Word2Vec是一种计算模型，能够将单词映射到向量空间中，捕捉单词之间的语义关系。
* 它分为两种模型：CBOW（Continuous Bag-of-Words）和Skip-Gram。

### Word2Vec在NLP中的应用

* **向量Embedding**：Word2Vec的重要功能是将单词通过k维向量表示，类似于矩阵分解中的内容表示。
* **用户行为序列**：将用户的行为（如点击视频）转化为单词序列，用于后续的向量表示和相似度计算

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828142028-4xu7iqj.png)​

### Word2Vec的实现机制

* **行为记录与序列化**：首先记录用户的行为，形成序列，这些序列作为模型的输入。
* **向量生成**：通过模型处理序列，生成每个内容（如视频）的向量表示。
* **相似度计算**：计算内容向量之间的相似度，形成相似度矩阵。

### 使用场景

* 内容相关推荐i2i:

  * 计算内容相关的内容，将最相似的TopN作为召回结果，如实现相关视频推荐，点击vid2vid。
  * 可以组成序列的sequence的都可以用word2vec学习其embedding表示。
* 用户行为序列相关推荐u2i2i:

  * 根据用户的行为(近期访问内容) ，捕获其兴趣，寻找内容相关的内容。
  * 用户-行为序列sequence，获取兴趣表达，寻找类似兴趣的内容。

### 工业生产流程

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828142955-e9fl7my.png)​

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828143040-vo44om3.png)​

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828144023-ilflsjr.png)​

**样本生成**：与矩阵分解不同，Word2Vec需要生成基于用户行为的序列样本。

**模型训练**：使用Spark等工具进行模型训练，生成内容向量。

**物料入库与召回**：计算内容相似度，将结果存入物料库，用于后续的推荐召回。

### Word2Vec的特点与局限

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828145331-rw9gix8.png)​

* **内容相似度聚焦**：相比于矩阵分解，Word2Vec更关注内容相似度。
* **行为序列引入**：通过引入行为序列，Word2Vec能更精准地捕获个人兴趣。
* **持续训练需求**：对于新内容，需要持续训练以更新向量表示。
* **可解释性不足**：与矩阵分解类似，Word2Vec在可解释性上存在局限。
* **顺序无关性**：Word2Vec对用户行为的顺序不敏感，可能不适合时序敏感的内容推荐。

## 向量检索技术

### faiss 基础介绍

Faiss是Facebook团队开源的向量检索工具，针对高维空间的海量数据，提供高效可靠的检索方式。其优越的性能,广泛应用于推荐系统、图片和视频搜索等业务。

* 应用于推荐系统

几乎是早期大部分互联网公司向量召回的标配工具。

召回算法中矩阵分解、word2vec、youtube dnn,dssm双塔等模型生成的向量信息，都可以通过Faiss进行检索实现召回。

* 应用于搜索

图片搜索，图片信息量较大，维度较高：高x宽xRGB ，Faiss将高维的图片降维如64维，实现相似度检索。

视频搜索，通过抽帧采样，视频可以转化为一批图片集合总和（视频指纹） ，Faiss也常用视频搜索。

视频去重，在内容信息流推荐系统中，如何确认视频是否原创，后发布者与首次发布视频视频指纹相似度。

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828162850-i0401vv.png)​

### 索引方式

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828162948-ob8mi1u.png)​

#### 精确索引IndexFlatL2 【慢】

欧式距离L2 (未开方) = (A1-B1)^2 + (A2-B2)^2 + ... + (An-Bn)^2

#### 倒排快速索引IndexIVFFlat 【较快】

大数据量时，对入库的向量数据，进行分割为多个空间。

查询阶段，将查询向量落入的空间中的数据库向量进行比较，返回k个最近邻结果，大幅缩减索引时间。

#### 乘积量化索引IndexIVFPQ 【超快】

上述两种索引方式中，在index中都保存了完整的数据库向量，在数据量非常大的时候会占用太多内存，甚至超出内存限制。

在faiss中，当数据量非常大的时候，可采用乘积量化方法保存原始向量的有损压缩形式，在查询阶段返回近似结果。

超大数据集，如百万-千万，基本都要进行压缩，使用PQ技术，近似检索。

> 所以，基于Product Quantizer(乘积量化)的[压缩算法](https://zhida.zhihu.com/search?q=%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95&zhida_source=entity&is_preview=1)编码向量到指定字节数来减少内存占用。但这种情况下，存储的向量是压缩过的，所以查询的距离也是近似的。

### 数百万物料检索示例

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828163415-ofjc5dm.png)​​​

#### IndexIVFPQ原理

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828163448-z8t20ac.png)​

##### 1. 向量切割

假设我们有1000万个User向量，每个向量是128维的特征向量。首先，我们将每个128维的User向量分割成8个短向量，每个短向量是16维。这意味着每个User向量被拆分为8个部分，每个部分都是16维。

##### 2. 聚类

接下来，我们在每一堆短向量中使用聚类算法（如K-Means）进行聚类。假设我们为每一堆短向量聚类成256类，这意味着每堆短向量都被划分为256个不同的类别。

##### 3. 编码向量

对于每个短向量，我们找到它属于256类中的哪一类。由于每个短向量有256种选择，因此一个User向量通过8个短向量可以表示为64位二进制数（8\*8bit）。这样，每个User向量都被编码为一个64位的索引值。

##### 4. 压缩

每个原始向量通过上述步骤被压缩成一个M个索引值构成的压缩向量。在这个例子中，M是8（因为有8个短向量），每个索引值对应一个聚类中心。这样，压缩向量实际上就是M个索引值，每个索引值指向一个聚类中心。

##### 检索过程

假设用户查询一个视频的128维向量，我们想要找到与该查询最相似的视频。

1. **用户查询**：用户查询一个视频的128维向量。
2. **PQ编码**：查询向量被编码为8个16维的短向量。
3. **搜索倒排文件**：

    * 使用PQ向量搜索倒排文件，找到最相似的5个簇中心。
    * 倒排文件中存储了每个PQ向量对应的簇索引和位置。
4. **查询原始数据**：

    * 根据这5个簇中心，在原始数据中检索到与查询向量最相似的视频。
    * 检索时，我们计算查询向量与每个簇中心向量的距离，找到最相似的视频。

### faiss应用-大规模物料向量召回

![image](./%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.assets/image-20240828163600-4lpmmhw.png)​

### Faiss工具的优势与局限

**优势**：

* 优秀的性能，支持大规模数据检索。
* 通过GPU加速，提升性能4-10倍。
* 多种索引方式，平衡性能和空间需求。

**局限**：

* 单机部署，稳定性受限。
* 容量受限，不适合大规模部署。

‍
