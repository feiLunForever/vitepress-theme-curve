---
title: 第零章、基础篇
tags:
  - MySQL
categories:
  - 数据库
date: '2025-01-03'
description: 欢迎使用 Curve 主题，这是你的第一篇文章
articleGPT: 这是一篇初始化文章，旨在告诉用户一些使用说明和须知。
#cover: "/images/logo/logo.webp"
---

# 基础篇

## MyISAM 对比 InnoDB

- MyISAM 只有表锁，InnoDB 表锁，行锁
- MyISAM 不支持事务，InnoDB 支持
- MyISAM 不支持外键，InnoDB 支持
- MyISAM 不支持 MVCC，InnoDB 支持

## sql 执行慢的原因

### 偶尔慢

- flush 刷新脏页

  - redo log 写满了
  - 内存不够
  - mysql 认为系统空闲
  - mysql 正常关闭
- 竞争锁

  - show processlist

### 一直很慢

- sql 慢查询

  - 没有用到索引，考虑索引失效
  - 表数据量太大，考虑分表分库
  - 优化器选错了索引，考虑 force index

## 一颗 b+ 树存储多少条数据

- B+ 树存放的总记录数 = `根节点指针数` * `单个叶子节点记录行数`
- innoDb 页大小默认是 16KB，假设索引字段是 bigint，长度 8 字节，指针是 6 字节，非叶子节点（一页）可以存储 16384 / 14 = 1170 个指针
- 假设一行数据的大小是 1k 字节，16K / 1K = 16，一页是 16 条数据
- 树深=2 时，1170 * 16 = 1.87w 条数据
- 树深=3 时，1170 * 1170 * 16 = 2.2kw 的数据
- 一张 2000w 左右的表，最多 3 次 IO

## cpu 飙升

- top 观察是否是 mysql 导致
- `show processlist` 查看 sql 运行
- 找出消耗高的 sql，看看执行计划是否准确， 索引是否缺失，数据量是否太大

**如何处理：**

1. kill 掉这些线程 (同时观察 cpu 使用率是否下降)
2. 进行相应的调整 (比如说加索引、改 sql、改内存参数)
3. 重新跑这些 SQL。

**其他情况：**

1. 也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的新 session 连接进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。

## **百万级别或以上的数据如何删除**

关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加，修改，删除，都会产生额外的对索引文件的操作,这些操作需要消耗额外的 IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询 MySQL 官方手册得知删除数据的速度和创建的索引数量是成正比的。

1. 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）
2. 然后删除其中无用数据（此过程需要不到两分钟）
3. 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。
4. 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。

## 深度分页，limit 1000000

- 如果 id 是连续的，返回上次查询的最大记录(偏移量)，再往下 limit

```sql
select id，name from employee where id>1000000 limit 10
```

- order by + 索引（id 为索引）

```sql
select id，name from employee order by id limit 1000000，10
```

- 延迟关联（先快速定位需要获取的 id 段，然后再关联）

```sql
SELECT a.* FROM employee a, (select id from employee where 条件 LIMIT 1000000,10 ) b where a.id = b.id
```

## count(1)、count(*)、count(列)

- count(1) 忽略列，统计行数，不忽略 null
- count(*) 包括列，统计行数，不忽略 null
- count(列) 统计行数，忽略 null

## union、unionAll

- union 两个结果并集，去重，默认排序
- union all 不去重，不排序
- UNION ALL 的效率高于 UNION

## 一条 Sql 的执行顺序

- from< 左表的名字 >
- on join< 条件 >
- where< 条件 >
- group by
- having< 条件 >
- select
- distinct
- order by
- limit

<img src="./%E7%AC%AC%E9%9B%B6%E7%AB%A0%20%E5%9F%BA%E7%A1%80%E7%AF%87.assets/image-20250226163045987.png" alt="image-20250226163045987" style="zoom:40%;" />

## 数据库连接池的必要性

众所周知，当要在`Java`中创建一个数据库连接时，首先会去读取配置文件中的连接地址、账号密码等信息，然后根据配置的地址信息，发起网络请求获取数据库连接对象。在这个过程中，由于涉及到了网络请求，那此时必然会先经历`TCP`三次握手的过程，同时获取到连接对象完成`SQL`操作后，又要释放这个数据库连接，此时又需要经历`TCP`四次挥手过程。

> 从上面的描述中可以明显感知出，在Java中创建、关闭数据库连接的过程，过程开销其实比较大，而在程序上线后，又需要频繁进行数据库操作。因此如果每次操作数据库时，都获取新的连接对象，那整个`Java`程序至少会有四分之一的时间内在做`TCP`三次握手/四次挥手工作，这对整个系统造成的后果可想而知....

也正是由于上述原因，因此大名鼎鼎的「数据库连接池」登场了，「数据库连接池」和「线程池」的思想相同，会将数据库连接这种较为珍贵的资源，利用池化技术对这种资源进行维护。也就代表着之后需要进行数据库操作时，不需要自己去建立连接了，而是直接从「数据库连接池」中获取，用完之后再归还给连接池，以此达到复用的效果。

> 当然，连接池中维护的连接对象也不会一直都在，当长时间未进行`SQL`操作时，连接池也会销毁这些连接对象，而后当需要时再次创建，不过何时创建、何时销毁、连接数限制等等这些工作，都交给了连接池去完成，无需开发者自身再去关注。

OK~，回到前面抛出的问题，有了`MySQL`连接池为何还需要在客户端维护一个连接池？

> 对于这个问题，相信大家在心里多少都有点答案了，原因很简单，两者都是利用池化技术去达到复用资源、节省开销、提升性能的目的，只不过针对的方向不同。

`MySQL`的连接池主要是为了实现复用线程的目的，因为每个数据库连接在`MySQL`中都会使用一条线程维护，而每次为客户端分配连接对象时，都需要经历创建线程、分配栈空间....这些繁重的工作，这个过程需要时间，同时资源开销也不小，所以`MySQL`利用池化技术解决了这些问题。

而客户端的连接池，主要是为了实现复用数据库连接的目的，因为每次`SQL`操作都需要经过`TCP`三次握手/四次挥手的过程，过程同样耗时且占用资源，因此也利用池化技术解决了这个问题。

> 其实也可以这样理解，`MySQL`连接池维护的是工作线程，客户端连接池则维护的是网络连接。

## sql 语句执行过程

### 查询 sql

<img src="./%E7%AC%AC%E9%9B%B6%E7%AB%A0%20%E5%9F%BA%E7%A1%80%E7%AF%87.assets/image-20250303102655722.png" alt="image-20250303102655722" style="zoom:80%;" />

- 执行前

  - 验证用户名，密码等
  - 建立 DB 连接，从连接池中获取连接
  - 查询用户权限表，查看是有有权限
- 开始执行

  - 先将`SQL`发送给`SQL`接口，`SQL`接口会对`SQL`语句进行`hash`处理。
  - sql 接口根据 hash 值检索是否有缓存
  - 缓存中未命中时会将`SQL`交给解析器，解析器会判断`SQL`语句是否正确
  - 优化器根据`SQL`制定出不同的执行方案，并择选出最优的执行计划
  - 调用存储引擎执行 `sql`
  - 存储引擎进行 IO 检索数据，返回给 `sql` 接口
  - `sql` 接口将结果集处理(剔除列，合并数据)返回

### 写 sql

<img src="./%E7%AC%AC%E9%9B%B6%E7%AB%A0%20%E5%9F%BA%E7%A1%80%E7%AF%87.assets/image-20250303102716690.png" alt="image-20250303102716690" style="zoom:80%;" />

* 执行前

  * 验证用户名，密码等
  * 建立 DB 连接，从连接池中获取连接
  * 查询用户权限表，查看是有有权限
* 开始执行

  * 先将`SQL`发送给`SQL`接口，`SQL`接口会对`SQL`语句进行`hash`处理
  * sql 接口根据 hash 值检索是否有缓存，如果有，对应缓存删掉
  * 经过缓存后会将`SQL`交给解析器，解析器会判断`SQL`语句是否正确
  * 优化器制定执行计划
  * 在执行开始之前，先记录一下 `undo-log` 日志和 `redo-log(prepare 状态)`日志
  * 在缓冲区中查找是否存在当前要操作的行记录或表数据（内存中）：

    * 存在，对缓冲区进行写操作，利用 `checkpoint` 机制刷盘
    * 不在，调用存储引擎，从磁盘上的数据库文件中读取相应的数据页到缓冲池
  * 写操作完成后，记录 `bin-log` 日志，同时将 `redo-log` 日志中的记录改为 `commit` 状态
  * 将 `SQL` 执行耗时及操作成功的结果返回给 `SQL` 接口，再由 `SQL` 接口返回给客户端
