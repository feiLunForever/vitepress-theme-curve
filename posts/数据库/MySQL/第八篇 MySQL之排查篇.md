
# 第八篇 排查篇

数据库出现问题一般会发生在下述几方面：

- ① 撰写的`SQL`语句执行出错，俗称为业务代码`Bug`。
- ② 开发环境执行一切正常，线上偶发`SQL`执行缓慢的情况。
- ③ 线上部署`MySQL`的机器故障，如磁盘、内存、`CPU100%`，`MySQL`自身故障等。

## SQL语句执行出错排查

> 定位问题：通过相关的 `日志系统` 的辅助，以更“细粒度”的手段，将引发问题的原因定位到精准位置。

一般根据错误码，直接就能定位问题，并很快能给解决掉。

## MySQL线上慢查询语句排查

### 查看慢查询日志

开启慢查询日志需要配置两个关键参数：

- `slow_query_log`：取值为`on、off`，默认为`off`关闭，项目上线前需要手动开启。
- `long_query_time`：指定记录慢查询日志的阈值，单位是秒，要指定更细粒度可以用小数表示。

模拟一下：

```sql
-- 在MySQL客户端中直接使用 set 的方式修改

-- 先开启慢查询日志
set global slow_query_log = on;

-- 再查询默认的慢查询阈值（默认为10秒）
show variables like 'long_query_time';
+-----------------+-----------+
| Variable_name   | Value     |
+-----------------+-----------+
| long_query_time | 10.000000 |
+-----------------+-----------+

-- 手动修改慢查询阈值（设置为10ms）
set global long_query_time = 0.01;

-- 由于前面使用了global关键字设置了全局生效，因此需要重新连接
quit

-- 重连后再次查询慢查询阈值（已生效）
show variables like 'long_query_time';
+-----------------+----------+
| Variable_name   | Value    |
+-----------------+----------+
| long_query_time | 0.010000 |
+-----------------+----------+
```

上面这组配置的含义是：当有查询语句的执行时长超过`10ms`，`MySQL`就会自动将其记录到慢查询日志中，下面来执行一条`SQL`试试感`jio~`：

```sql
-- 一条普普通通的子查询语句
select 
    * 
from 
    zz_users 
where 
    user_id in (
        select user_id from zz_users where user_id < 5
    ) 
and 
    register_time < now();
+---------+-----------+----------+----------+---------------------+
| user_id | user_name | user_sex | password | register_time       |
+---------+-----------+----------+----------+---------------------+
|       1 | 熊猫      | 女       | 6666     | 2022-08-14 15:22:01 |
|       2 | 竹子      | 男       | 1234     | 2022-09-14 16:17:44 |
|       3 | 子竹      | 男       | 4321     | 2022-09-16 07:42:21 |
|       4 | 黑熊      | 男       | 8888     | 2022-09-17 23:48:29 |
+---------+-----------+----------+----------+---------------------+
4 rows in set (0.015 sec)
```

从上述的执行结果来看，其实这里执行的耗时为`15ms`，已经超出了咱们设定的`10ms`，那接着一起去看看磁盘中的慢查询日志吧！如果你不清楚你本地慢查询日志文件的位置，可以通过下述命令查询：

- `show variables like 'slow_query_log_file';`

此时找到本地的慢查询日志，接着打开它来瞧瞧其中是否有数据呢？如下：

![image-20250528173915166](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250528173915166.png)

从上面日志中记录的查询信息来看，可以得知几个信息：

- 执行慢查询`SQL`的用户：`root`，登录`IP`为：`localhost[127.0.0.1]`。
- 慢查询执行的具体耗时为：`0.014960s`，锁等待时间为`0s`。
- 本次`SQL`执行后的结果集为`4`行数据，累计扫描`6`行数据。
- 本次慢查询发生在`db_zhuzi`这个库中，发生时间为`1667466932（2022-11-03 17:15:32）`。
- 最后一行为具体的慢查询`SQL`语句。

### 排查SQL执行缓慢问题

读取慢查询日志后，能够让咱们精准定位到发生慢查询 `SQL` 的用户、客户端机器、执行耗时、锁阻塞耗时、结果集行数、扫描行数、发生的库和时间、以及具体的慢查询 `SQL` 语句，得到了这些信息后，其实排查引起慢查询的原因就比较简单了。步骤如下：

- 先根据本地慢查询日志文件中的记录，得到具体慢查询 `SQL` 执行的相关信息。
- 查看 `Look_time`  的耗时，判断本次执行缓慢，是不是由于并发事务导致的长时间阻塞。
- 如果不是，则通过[《SQL优化篇》](https://juejin.cn/post/7164652941159170078)中说的 `explain` 索引分析工具，先判断索引的使用情况。

一般来说在开发环境中没有问题的 `SQL` 语句，放到线上环境出现执行缓慢的情况，多半原因是由于并发事务抢占锁，造成当前事务长时间无法获取锁资源，因此导致当前事务执行的 `SQL` 出现超时，这种情况下需要去定位操作相同行数据的大事务，一般长时间的阻塞是由于大事务持有锁导致的，找出对应的大事务并拆解或优化掉即可。

通过`show status like 'innodb_row_lock_%';`命令可以查询`MySQL`整体的锁状态，如下：

![image-20250528174219584](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250528174219584.png)

- `Innodb_row_lock_current_waits`：当前正在阻塞等待锁的事务数量。
- `Innodb_row_lock_time`：`MySQL `启动到现在，所有事务总共阻塞等待的总时长。
- `Innodb_row_lock_time_avg`：平均每次事务阻塞等待锁时，其平均阻塞时长。
- `Innodb_row_lock_time_max`：`MySQL `启动至今，最长的一次阻塞时间。
- `Innodb_row_lock_waits`：`MySQL` 启动到现在，所有事务总共阻塞等待的总次数。

如果你在慢查询日志中，看到了大量由于锁阻塞导致执行超出慢查询阈值的 `SQL`，那可以执行上述这条指令看看整个 `MySQL` 的锁状态，如果这些值都比较大时，就意味着你当前这个 `MySQL` 节点承载的并发压力过高，此时就急需进行[《MySQL架构优化》](https://juejin.cn/post/7163894728201601060#heading-23)。

## MySQL线上机器故障排查

`MySQL`  数据库线上的机器故障主要分为两方面，一方面是由于 `MySQL` 自身引起的问题，比如连接异常、死锁问题等，另一方面则是部署 `MySQL` 的服务器硬件文件，如磁盘、`CPU100%` 等现象，对于不同的故障问题排查手段也不同。

### 客户端连接异常

客户端连接异常也是一种较为常见的故障，这里有可能是因为多方面原因导致的，常见如下：

- 数据库总体的现有连接数，超出了 `MySQL` 中的最大连接数，此时再出现新连接时会出异常。

- 部署 `MySQL` 的机器资源被耗尽，如 `CPU`、硬盘过高，导致 `MySQL` 没有资源分配给新连接。
  - 去查一下部署 `MySQL` 服务的机器，其硬件的使用情况，如 `CPU`、内存、磁盘等，如果其中一项达到了`100%`，这时就能够确定问题了

### MySQL死锁频发

`MySQL`内部其实会默认开启死锁检测算法，当运行期间出现死锁问题时，会主动介入并解除死锁，但要记住：**虽然数据库能够主动介入解除死锁问题，但这种方法治标不治本**！

为啥治标不治本呢？因为死锁现象是由于业务不合理造成的，能出现一次死锁问题，自然后续也可能会多次出现，因此优化业务才是最好的选择，这样才能根治死锁问题。

从业务上解决死锁问题，首先咱们得先定准定位到产生死锁的 `SQL` 语句，对于这点需要在 `MySQL` 内部会有一个日志，来记录着它自身捕获到的死锁，可以通过如下命令查看：

- `SHOW ENGINE INNODB STATUS\G;`：查看 `InnoDB` 存储引擎的运行状态日志。

当出现死锁时，`MySQL` 会将死锁对应的信息记录到该日志中，但这个日志会记录着 `InnoDB` 运行期间的所有状态日志，因此输入之后，要先找到 `LATEST DETECTED DEADLOCK` 这块区域的日志：

![image-20250528175013213](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250528175013213.png)

在上面的日志中，基本上已经写的很清楚了，在 `2022-11-04 23:04:34` 这个时间点上，检测到了一个死锁出现，该死锁主要由两个事务产生，`SQL` 如下：

- `(1)：UPDATE `zz_account` SET balance = balance + 888 WHERE user_name = "熊猫";`
- `(2)：UPDATE `zz_account` SET balance = balance + 666 WHERE user_name = "竹子";`

在事务信息除开列出了导致死锁的 `SQL` 语句外，还给出了两个事务对应的线程`ID`、登录的用户和 `IP`、事务的存活时间与系统线程`ID`、持有的锁信息与等待的锁信息.....。

最后一条信息中，给出 了`MySQL `介入解除死锁的方案，也就是回滚了事务`(2)` 的操作，强制结束了事务`(2)` 并释放了其持有的锁资源，从而能够让事务`(1) ` 继续运行。

> 想要彻底解决死锁问题的方案也很简单了，根据日志中给出的信息，去找到执行相应 `SQL` 的业务和库表，优化 `SQL` 语句的执行顺序，或 `SQL` 的执行逻辑，从而避免死锁产生即可。

### 服务器CPU100%

- top 观察是否是 mysql 导致
- 配合 `show processlist` 查看 sql 运行
- 根据经验，找出消耗高的 `sql`，看看执行计划是否准确， 索引是否缺失，数据量是否太大

**如何处理：**

1. kill 掉这些线程 (同时观察 cpu 使用率是否下降)
2. 进行相应的调整 (比如说加索引、改 sql、改内存参数)
3. 重新跑这些 SQL。

**其他情况：**

1. 也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的新 session 连接进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。

### MySQL磁盘100%

所谓的磁盘 `100%` 不是指磁盘空间被用光，而是指磁盘 `IO` 达到 `100%` 利用率，这种情况下一般会导致其他读写操作都被阻塞，因为操作系统中的 `IO` 总线会被占满，无法让给其他线程来读写数据，先来总结一下出现磁盘 `IO` 占用过高的原因：

- ①突然大批量变更库中数据，需要执行大量写入操作，如主从数据同步时就会出现这个问题。
- ②`MySQL` 处理的整体并发过高，磁盘 `I/O` 频率跟不上，比如是机械硬盘材质，读写速率过慢。
- ③内存中的 `BufferPool` 缓冲池过小，大量读写操作需要落入磁盘处理，导致磁盘利用率过高。
- ④频繁创建和销毁临时表，导致内存无法存储临时表数据，因而转到磁盘存储，导致磁盘飙升。
- ⑤执行某些 `SQL` 时从磁盘加载海量数据，如超 `12` 张表的联查，并每张表数据较大，最终导致 `IO` 打满。
- ⑥日志刷盘频率过高，其实这条是①、②的附带情况，毕竟日志的刷盘频率，跟整体并发直接挂钩。

一般情况下，磁盘 `IO` 利用率居高不下，甚至超过`100%`，基本上是由于上述几个原因造成的，当需要排查磁盘 `IO` 占用率过高的问题时，可以先通过 `iotop` 工具找到磁盘 `IO` 开销最大的线程，然后利用 `pstack` 工具查看其堆栈信息，从堆栈信息来判断具体是啥原因导致的，如果是并发过高，则需要优化整体架构。如果是执行 `SQL` 加载数据过大，需要优化 `SQL` 语句......

磁盘利用率过高的问题其实也比较好解决，方案如下：

- ①如果磁盘不是 `SSD` 材质，请先将磁盘升级成固态硬盘，`MySQL `对 `SSD` 硬盘做了特殊优化。
- ②在项目中记得引入 `Redis` 降低读压力，引入 `MQ` 对写操作做流量削峰。
- ③调大内存中 `BufferPool` 缓冲池的大小，最好设置成机器内存的 `70~75%` 左右。
- ④撰写 `SQL` 语句时尽量减少多张大表联查，不要频繁的使用和销毁临时表。

基本上把上述工作都做好后，线上也不会出现磁盘 `IO` 占用过高的问题，对于前面说到的：利用 `iotop、pstack` 工具排查的过程，就不再做实际演示了，其过程与前面排查 `CPU` 占用率过高的步骤类似，大家学习 `iotop、pstack` 两个工具的用法后，其实实操起来也十分简单。 
