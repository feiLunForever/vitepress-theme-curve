# 项目亮点

Caffeine

protobuf

es

ohc

## OHCache 堆外缓存

### 背景

搜推中的召回过滤 `recommend-recall`​ 服务，定义了大量的过滤算子，因为rt要求较高，所以需要将一些数据加载到缓存中，过滤的时候尽量去做内存计算。

之前用的是Caffeine缓存，但是由于门店大促等请求，导致qps较高时，会频繁出现 Mixed GC 或 Full GC 的情况，将缓存中的数据gc掉，观察`Prometheus`​监控，会发现 很多的cache数据，频繁的新增删除，很多的突刺。

那如何能尽量较多的缓数据，避免 GC 带来的影响呢？

我们想到了把缓存对象移到堆外，这样可以不受堆内内存大小的限制；并且堆外内存，并不受 JVM GC 的管控，避免了缓存过大对 GC 的影响。经过调研，我们决定采用成熟的开源堆外缓存组件 OHC 。

### OHC 介绍

OHC 全称为 off-heap-cache，即堆外缓存，是 2015 年针对 Apache Cassandra 开发的缓存框架，后来从 Cassandra 项目中独立出来，成为单独的类库，其项目地址为：

> https://github.com/snazy/ohc

其特性如下：

- 数据存储在堆外，只有少量元数据存储堆内，不影响 GC
- 支持为每个缓存项设置过期时间
- 支持配置 LRU、W\_TinyLFU 驱逐策略
- 能够维护大量的缓存条目
- 支持异步加载缓存
- 读写速度在微秒级别

**（2）OHC 用法**

快速开始：

```java
OHCache ohCache = OHCacheBuilder.newBuilder().
    keySerializer(yourKeySerializer)
    .valueSerializer(yourValueSerializer)
.build();
```

可选配置项：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190110333.png" alt="image-20250614190110333" style="zoom:70%;" />

在我们的服务中，设置 capacity 容量 12G，segmentCount 分段数 1024，序列化协议使用 kryo。

key 和 value 的序列化方式并没有给我们提供，而是需要我们进行自定义，这一点在它的 README 中也提到了：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190125467.png" alt="image-20250614190125467" style="zoom:60%;" />

它说 key 和 value 的序列化需要去实现 CacheSerializer 接口，这个接口三个方法，分别是对象序列化之后的长度，序列化和反序列化方法。

### Quickstart

```java
public class OhcDemo {

    public static void main(String[] args) {
        OHCache ohCache = OHCacheBuilder.<String, String>newBuilder()
                .keySerializer(OhcDemo.stringSerializer)
                .valueSerializer(OhcDemo.stringSerializer)
                .build();
        ohCache.put("hello","why");
        System.out.println("ohCache.get(hello) = " + ohCache.get("hello"));
    }

    public static final CacheSerializer<String> stringSerializer = new CacheSerializer<String>() {
        public void serialize(String s, ByteBuffer buf) {
            // 得到字符串对象UTF-8编码的字节数组
            byte[] bytes = s.getBytes(Charsets.UTF_8);
            // 用前16位记录数组长度
            buf.put((byte) ((bytes.length >>> 8) & 0xFF));
            buf.put((byte) ((bytes.length) & 0xFF));
            buf.put(bytes);
        }

        public String deserialize(ByteBuffer buf) {
            // 获取字节数组的长度
            int length = (((buf.get() & 0xff) << 8) + ((buf.get() & 0xff)));
            byte[] bytes = new byte[length];
            // 读取字节数组
            buf.get(bytes);
            // 返回字符串对象
            return new String(bytes, Charsets.UTF_8);
        }

        public int serializedSize(String s) {
            byte[] bytes = s.getBytes(Charsets.UTF_8);
            // 设置字符串长度限制，2^16 = 65536
            if (bytes.length > 65535)
                throw new RuntimeException("encoded string too long: " + bytes.length + " bytes");

            return bytes.length + 2;
        }
    };
}
```

### **对比**

为了让你能更加直观的看到堆外内存和堆内内存的区别，我给你搞两段程序跑跑。

首先是我们堆内内存的代表选手，HashMap：

```java
/**
 * -Xms100m -Xmx100m
 */
public class HashMapCacheExample {
    private static HashMap<String, String> HASHMAP = new HashMap<>();

    public static void main(String[] args) throws InterruptedException {
        hashMapOOM();
    }
    private static void hashMapOOM() throws InterruptedException {
        //准备时间，方便观察
        TimeUnit.SECONDS.sleep(10);
        int num = 0;
        while (true) {
            //往 map 中存放 1M 大小的字符串
            String big = new String(new byte[1024 * 1024]);
            HASHMAP.put(num + "", big);
            num++;
        }
    }
}
```

通过 JVM 参数控制堆内存大小为 100m，然后不断的往 Map 中存放 1M 大小的字符串，那么这个程序很快就会出现 OOM：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190148808.png" alt="image-20250614190148808" style="zoom:70%;" />

其对应的在 visualvm 里面的内存走势图是这样的：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190202817.png" alt="image-20250614190202817" style="zoom:70%;" />

程序基本上属于一启动，然后内存就被塞满了，接着立马就凉了。

属于秒了，被秒杀了。

但是，当我们同样的逻辑，用堆外内存的时候，情况就不一样了：

```java
/**
 * -Xms100m -Xmx100m
 */
public class OhcCacheDemo {

    public static void main(String[] args) throws InterruptedException {
        //准备时间，方便观察
        TimeUnit.SECONDS.sleep(10);
        OHCache ohCache = OHCacheBuilder.<String, String>newBuilder()
        .keySerializer(stringSerializer)
        .valueSerializer(stringSerializer)
        .build();
        int num = 0;
        while (true) {
            String big = new String(new byte[1024 * 1024]);
            ohCache.put(num + "", big);
            num++;
        }
    }

    public static final CacheSerializer<String> stringSerializer = new CacheSerializer<String>() {//前面写过，这里略了};
    }
```

关于上面程序中的 stringSerializer 需要注意一点的是我做测试的时候把这个大小的限制取消掉了，目的是和 HashMap 做测试是用同样大小为 1M 的字符串：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190223644.png" alt="image-20250614190223644" style="zoom:70%;" />

这是程序运行了 3 分钟之后的内存走势图：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190236679.png" alt="image-20250614190236679" style="zoom:70%;" />

这个图怎么说呢？

丑是丑了点，但是咱就是说至少没秒，程序没崩。

当这两个内存走势图一对比，是不是稍微就有那么一点点感觉了。

但是另外一个问题就随之而来了：我怎么看 OHCache 这个玩意占用的内存呢？

前面说了，它属于堆外内存。JVM 的堆外，那就是我本机的内存了。

打开任务管理器，切换到内存的走势图，正常来说走势图是这样的，非常的平稳：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190251538.png" alt="image-20250614190251538" style="zoom:50%;" />

从上面截图可以看到，我本机是 16G 的内存大小，目前还有 9.9G 的内存可以使用。

也就是说截图的这个时刻，我能使用的堆外内存顶天了也就是 9.9G 这个数。

那么我先用它个 6G，程序一启动，走势图就会变成这样：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190304743.png" alt="image-20250614190304743" style="zoom:50%;" />

而程序一关闭，内存占用立马就释放了：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190319901.png" alt="image-20250614190319901" style="zoom:50%;" />

也许你没注意到，前面我说了一句“用它个 6G”，我怎么控制这个 6G 的呢？

因为我在程序里面加了这样一行代码：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190335169.png" alt="image-20250614190335169" style="zoom:80%;" />

如果你不加的话，默认只会使用 64M 的堆外内存，看不出啥曲线。

### OHC 的底层原理

##### 整体架构

OHC 以 API 的方式供其他 Java 程序调用，其 org.caffinitas.ohc.OHCache 接口定义了可调用的方法。对于缓存来说，最常用的是 get 和 put 方法。针对不同的使用场景，OHC提供了两种OHCache的实现：

- org.caffinitas.ohc.chunked.OHCacheChunkedImpl
- org.caffinitas.ohc.linked.OHCacheLinkedImpl

以上两种实现均把所有条目缓存在堆外，堆内通过指向堆外的地址指针对缓存条目进行管理。

其中，linked 实现为每个键值对分别分配堆外内存，适合中大型键值对。chunked 实现为每个段分配堆外内存，适用于存储小型键值对。由于 chunked 实现仍然处于实验阶段，所以我们选择 linked 实现在线上使用，后续介绍也以linked 实现为例，其整体架构及内存分布如下图所示，下文将分别介绍其功能。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190351096.png" alt="image-20250614190351096" style="zoom:50%;" />

##### OHCacheLinkedImpl

`OHCacheLinkedImpl`​是堆外缓存的具体实现类，其主要成员包括：

- 段数组：OffHeapLinkedMap[]
- 序列化器与反序列化器：CacheSerializer

`OHCacheLinkedImpl`​ 中包含多个段，每个段用 `OffHeapLinkedMap`​ 来表示。同时，`OHCacheLinkedImpl`​ 将Java对象序列化成字节数组存储在堆外，在该过程中需要使用用户自定义的 `CacheSerializer`​。

`OHCacheLinkedImpl`​ 的主要工作流程如下：

1. 计算 key 的 hash值，根据 hash值 计算段号，确定其所处的 OffHeapLinkedMap
2. 从 OffHeapLinkedMap 中获取该键值对的堆外内存指针
3. 对于 get 操作，从指针所指向的堆外内存读取 byte[]，把 byte[] 反序列化成对象
4. 对于 put 操作，把对象序列化成 byte[]，并写入指针所指向的堆外内存

##### 段的实现：OffHeapLinkedMap

在OHC中，每个段用 `OffHeapLinkedMap`​ 来表示，段中包含多个分桶，每个桶是一个链表，链表中的元素即是缓存条目的堆外地址指针。

`OffHeapLinkedMap`​ 的主要作用是根据 hash值 找到 键值对 的 堆外地址指针。

在查找指针时，OffHeapLinkedMap 先根据 hash值 计算出 桶号，然后找到该桶的第一个元素，然后沿着第一个元素按顺序线性查找。

> 举个例子，OffHeapLinkedMap中包含两个分桶，分桶1中有两个键值对：
>
> - 元素1：name:Jack，堆外地址为1024
> - 元素2：age:20，堆外地址为8192
>
> 分桶2中也有两个键值对：
>
> - 元素1：animal:cat，堆外地址为2048
> - 元素2：color:black，堆外地址为4096
>
> 同时，所有分桶第一个元素的地址，会存在一个连续的内存空间。这里我们假设该空间从12000出开始，那么12000出将存储1024（分桶1首元素的地址）和2048（分桶2首元素的地址）。上述示例的数据在堆外分布如下图所示。需要注意的是，上述数据均保存在堆外，在堆内只需要保存一个地址指针（12000）即可。当我们要查找color对应的值时，
>
> 1. 先计算color的hash值
> 2. 根据hash值计算桶号，这里是2号分桶
> 3. 从堆外12000处，获取2号分桶对应的起始地址，这里是2048
> 4. 访问2048，发现key是animal， 和 color不匹配，得到下一个地址4096
> 5. 访问4096，发现命中color，返回
>
> <img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190405824.png" alt="image-20250614190405824" style="zoom:80%;" />

##### 空间分配

OHC 的 `linked`​ 实现为每个键值对分别分配堆外内存，因此 **键值对** 实际是零散地分布在堆外。

OHC提供了`JNANativeAllocator`​ 和 `UnsafeAllocator`​ 这两个分配器，分别使用 `Native.malloc(size)`​ 和 `Unsafe.allocateMemory(size)`​ 分配堆外内存，用户可以通过配置来使用其中一种。

OHC 会把 `key`​ 和 `value`​ 序列化成 `byte[]`​ 存储到堆外，用户需要通过实现 `CacheSerializer`​ 来自定义类完成 **序列化** 和 **反序列化**。因此，占用的空间实际取决于用户自定义的序列化方法。

除了 `key`​ 和 `value`​ 本身占用的空间，OHC 还会对 `key`​ 进行 8位 对齐。比如用户计算出 `key`​ 占用 3个字节，OHC会将其对齐到8个字节。另外，对于每个键值对，OHC需要额外的64个字节来维护偏移量等元数据。

因此，对于每个键值对占用的堆外空间为：

> **每个条目占用堆外内存 = key占用内存(8位对齐) + value占用内存 + 64字节**

##### **操作堆外内存**

一般我们申请堆外内存，就会这样去写：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190423072.png" alt="image-20250614190423072" style="zoom:80%;" />

这个方法最终会调用 Unsafe 里面的 allocateMemory 这个 native 方法，它相当于 C++ 的 malloc 函数：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190439620.png" alt="image-20250614190439620" style="zoom:70%;" />

这个方法会为我们在操作系统的内存中去分配一个我们指定大小的内存供我们使用，这个内存就叫做堆外内存，不由 JVM 控制，即不在 gc 管理范围内的。

这个方法返回值是 long 类型数值，也就是申请的内存对应的首地址。

但是需要注意的是，JVM 有个叫做 `-XX:MaxDirectMemorySize`​（最大堆外内存）的配置，如果使用 `ByteBuffer.allocateDirect`​ 申请堆外内存，大小会受到这个配置的限制，因为会调用这个方法：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190454829.png" alt="image-20250614190454829" style="zoom:80%;" />

OHC 要使用堆外内存，必然也是通过某个方法向操作系统申请了一部分内存，那么它申请内存的方法，是不是也是 `allocateMemory`​ 呢？

在 github 上作者给出了否认三连，不仅告诉了你没有使用，还告诉了你为什么没有使用：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190508798.png" alt="image-20250614190508798" style="zoom:60%;" />

作者说，绕过 `ByteBuffer.allocateDirect`​ 方法，直接分配堆外内存，对 GC 来说是更加平稳的，因为我们可以明确控制内存分配，更重要的是可以由我们自己完全控制内存的释放。

如果使用 `ByteBuffer.allocateDirect`​ 方法，可能在垃圾回收期间，就释放了堆外内存。

这句话对应到代码中就是这里，而这样的操作，在 OHC 里面是不需要的。OHC 希望由框架自己来全权掌握什么时候应该释放：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190524007.png" alt="image-20250614190524007" style="zoom:70%;" />

然后作者接着说：此外，如果分配内存的时候，没有更多的堆外内存可以使用，它可能会触发一个 Full GC，如果多个申请内存的线程同时遇到这种情况，这是有问题的，因为这意味着大量 Full GC 的连续发生。

这句话对应的代码是这里：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190542738.png" alt="image-20250614190542738" style="zoom:70%;" />

如果堆外内存不足的时候，会触发一次 Full GC。可以想象，在机器内存吃紧的时候，程序还在不停的申请堆外内存，继而导致 Full GC 的频繁出现，是一种什么样的“灾难性”的后果，基本上服务就处于不可用状态了。

OHC 需要避免这种情况的发生。

然后他还提了一个建议：

> and recommends to preload jemalloc on Linux systems to improve memory managment performance.

建议在 Linux 系统上预装 `jemalloc`​ 以提高内存管理性能。

弦外之音就是要拿它来替换 `glibc`​ 的 `malloc`​ 嘛，jemalloc 基本上是碾压 malloc。

现在我们知道 OHC 并没有使用常规的 `ByteBuffer.allocateDirect`​ 方法来完成堆外内存的申请，那么它是怎么实现这个“骚操作”的呢？

在 `UnsafeAllocator`​ 实现类里面是这样写的：

> `org.caffinitas.ohc.alloc.UnsafeAllocator`​

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190559489.png" alt="image-20250614190559489" style="zoom:70%;" />

通过反射直接获取到 `Unsafe`​ 并进行操作，没有任何多余的代码。

而在 `JNANativeAllocator`​ 实现类里面，则采用的是 `JNA`​ 的方式操作内存：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190614967.png" alt="image-20250614190614967" style="zoom:90%;" />

OHC 框架默认采用的是 JNA 的方式，这一点通过代码或者日志输出也能进行验证：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190633577.png" alt="image-20250614190633577" style="zoom:70%;" />

另外，我必须得多说一句，通过反射拿 Unsafe 这段代码可是个好东西啊，建议熟读、理解、融会贯通：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190647885.png" alt="image-20250614190647885" style="zoom:70%;" />

在 OHC 里面不就是一个非常好的例子嘛，虽然有现成的方法，但是和我的场景不是非常的匹配，我并不需要一些限制性的判断，只是想要简简单单的要一个堆外内存来用一用而已。

那我就绕过中间商，自己直接调用 `Unsafe`​ 里面的方法。

怎么拿到 `Unsafe`​ 呢？

就是前面这段代码，就是通过反射，你在其他的开源框架里面可以看到非常多类似的或者一模一样的代码片段。

背下来就完事。

#### 方案选型与应用

##### 生产环境的配置

OHC支持大量配置选项，供使用方根据自身业务场景进行选择，这里介绍下在我们业务中相关参数的配置。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190703648.png" alt="image-20250614190703648" style="zoom:70%;" />

###### 总容量

最开始使用OHC时，我们设置的上限为4G左右。随着业务的发展和数据量的增长，逐渐增大到10G，基本可以覆盖热点数据。

###### 段数量

一方面，OHC使用了分段锁，多个线程访问同一个段时会导致竞争，所以段数量不宜设置过小。同时，当段内条目数量达到一定负载时 OHC 会自动 rehash，段数量过小则会允许段内存储的条目数量增加，从而可能导致段内频繁进行rehash，影响性能。另一方面，段的元数据是存储在堆内的，过大的段数量会占用堆内空间。因此，应该在尽量减少rehash的次数的前提下，结合业务的QPS等参数，将段数量设置为较小的值。

###### 哈希算法

通过压测，我们发现使用 CRC32、CRC32C 和 MURMUR3 时，键值对的分布都比较均匀，而 CRC32C 的 CPU使用率相对较低，因此使用 CRC32C 作为哈希算法。

###### 逐出算法

选用10G的总容量，基本已经覆盖了大部分热点数据，并且很少出现偶发性或者周期性的批量操作，因此选用了LRU。

##### 线上表现

使用OHC管理的单机堆外内存在 10G 左右，可以缓存的条目为 百万量级。我们主要关注 命中率、读取 和 写入速度 这几个指标。

OHC#stats 方法会返回 OHCacheStats 对象，其中包含了命中率等指标。

当内存配置为10G时，在我们的业务场景下，缓存命中率可以稳定在95%以上。同时，我们在调用 get 和 put 方法时，进行了日志记录，get 的平均耗时稳定在 20微妙 左右，put 则需要 100微妙。

需要注意的是，get 和 put 的速度 和 缓存的键值对大小呈正相关趋势，因此不建议缓存过大的内容。可以通过org.caffinitas.ohc.maxEntrySize 配置项，来限制存储的最大键值对，OHC发现单个条目超过该值时不会将其放入堆外缓存。

##### 实践优化

(1)异步移除过期数据

在 OffHeapLinkedMap 的原始实现中，读取键值对 时 会判断其是否过期，如果过期则立即将其移除。移除键值对是相对比较 “昂贵” 的操作，可能会阻塞当前读取线程，因此我们对其进行了异步改造。读取键值对时，如果发现其已经过期，则会将其存入一个队列。同时，在后台加入了一个清理线程，定期从队列里面读取过期内容并进行移除。

(2)加锁方式优化

OHC本身是线程安全的，因为每个段都有自己的锁，在读取 和 写入时都会加锁。其源代码中使用的是 CAS锁（compare-and-set），在更新失败时尝试挂起线程并重试：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190720740.png" alt="image-20250614190720740" style="zoom:60%;" />

每个线程都有自己的缓存，当变量标记为脏时线程会更新缓存。但是，无论是否成功设置该值，CAS锁在每次调用变量时都会将其标记为脏数据，这会导致在线程竞争激烈时性能下降。使用 CASC（compare-and-set-compare）锁可以尽量减少 CAS 的次数，从而提高性能：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190736878.png" alt="image-20250614190736878" style="zoom:70%;" />

### 内存泄漏

直接在灰度环境开始运行\~. 起初一切良好. 我以20G的JVM堆,100G堆外内存配置. 成功运行了服务. (之前以120G的JVM运行, GC特别严重.)

但是很快问题出现了. 在接入线上小流量之后, 机器内存占用持续升高. 如下图:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190753376.png" alt="image-20250614190753376" style="zoom:20%;" />

在服务启动, 加载数据期间, 内存占用快速上升, 之后的几个小时内, 内存占用缓慢上升,直到到达 物理内存上线, 程序OOM进行重启.

#### 排查内存泄漏

物理内存共150G, 程序申请了20G JVM堆, 以及100G的堆外缓存. 理论上至少还有20+G的空闲, 但是机器内存爆掉了. 且从top命令结果来看, 确实是该进程占用内存达到了150G.

第一个排查思路就是: 产生了堆外内存泄漏.

##### JVM内存占用

首先, 确认下JVM堆的配置,以及占用是否正常.

使用命令 jhsdb jmap --heap --pid pid 查看 JVM占用. 结果如下:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190810159.png" alt="image-20250614190810159" style="zoom:50%;" />

可以看到其中 MaxHeapSize\=20480.0MB. 也就是说. 我们的JVM堆确实是占用了20G.

从JVM提供的查看(堆内内存、Code区域或者使用unsafe.allocateMemory和DirectByteBuffer申请的堆外内存)工具来看.

在项目中添加-XX:NativeMemoryTracking\=detailJVM 参数重启项目，使用命令jcmd pid VM.native\_memory detail 查看到的内存分布如下：

其中JVM相关的部分:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190835131.png" alt="image-20250614190835131" style="zoom:50%;" />

可以看到Java Heap 也是使用了20G. class thread 等其他部分, 占用量很少.

该命令, 还可以帮助我们查看部分堆外内存的占用, 主要是通过JDK提供的接口来申请的堆外内存. 包括使用unsafe.allocateMemory和DirectByteBuffer申请的堆外内存.

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190846471.png" alt="image-20250614190846471" style="zoom:60%;" />

可以看到堆外内存占用量很少. 因为:

1. 我们使用的OHC, 申请堆外内存,并不是通过这两个接口, 因此不在监控内.
2. “可能发生的内存泄漏”, 也不是使用这两个接口申请的.

##### OHC缓存占用

堆外内存并没有特别好的观测方法, 我们使用定时打印OHC缓存统计信息, 来判断OHC缓存占用.

```java
OHCacheStats{hitCount=1503972, missCount=23014, evictionCount=0, expireCount=0, size=167057308, capacity=91268055040, free=10803907716, rehashCount=1024, put(add/replace/fail)=167057308/0/0, removeCount=0, segmentSizes(#/min/max/avg)=128/1300746/1308479/1305135.22, totalAllocated=-1, lruCompactions=0}
```

根据上面的统计信息, 我们可以看到, 这次测试中, 我们给了85G的堆外内存容量, 当前只使用了75G左右. 远远没有达到100G. 更何况150G的物理内存.

##### 物理内存占用

我们使用pmap -x pid | sort -k 3 -n -r 命令, 查看该进程占用的所有内存:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190904567.png" alt="image-20250614190904567" style="zoom:60%;" />

最上面是一整块内存, 是JVM占用的20G. 除此之外有部分是缓存对象. 也没有找到明显的, 可疑的内存占用.

至此, 得到的结论是:

- 150G物理内存, 确实是被该进程占用了.
- JVM堆占用了20G. 通过OHCCache自带的统计来看, OHCache 使用量远远不足100G.
- 其他堆外内存, 没有有效观测手段.

因为是引入堆外内存后出现的问题, 因此首先怀疑OHC导致的, 主要有两个方向:

- OHC 存储我们的缓存之外,还有一些额外的堆外内存占用. 且没有统计到内存占用量中.
- OHC 包有bug. 尤其是发生 put 时, 没有释放掉老的对象的内存.

###### OHC 额外内存占用

我使用的是 `OHCCache的OHCacheLinkedImpl`​ 实现. 查看源码后发现, 在`put`​方法`org.caffinitas.ohc.linked.OHCacheLinkedImpl#putInternal`​的实现中, 计算写入当前 `k\=v`​ 需要的内存大小时, 使用了`org.caffinitas.ohc.linked.Util#allocLen`​ 方法. 实现如下:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190925943.png" alt="image-20250614190925943" style="zoom:50%;" />

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614190942066.png" alt="image-20250614190942066" style="zoom:70%;" />

已经提前计算了存储需要的额外内存占用, 主要是:

- 对key进行8位补齐.
- 64位的额外信息存储.

因此, OHC使用的所有堆外内存, 应该都是在内存统计信息中的. 也就是说, OHC没有占用更多的堆外内存了.

###### OHC put未释放旧内存

首先, 怀疑这个问题就显得我很蠢, 而且我在这个问题上花费了一下午时间….

首先, 这是OHC 最基本的能力, 不应该会有bug. 尤其是在应用如此广泛的情况下.

其次, 我简化代码, 单元测试. 在本地启动程序, 调用Cache.put().

- 缓存中不存在, 大量新增.
- 缓存中存在, 大量替换.

这两种情况下, 堆外内存的占用, 都是比较稳定的.

#### 元空间内存泄漏

Java8之后, 元空间的默认大小时机器物理内存大小,理论上存在内存泄漏可能性.

[一次完整的JVM堆外内存泄漏故障排查记录 | HeapDump性能社区](https://heapdump.cn/article/1821465)

这篇文章讲的挺好, 可惜经过验证, 不符合我的情况.

#### glibc

在网上看到很多内存泄漏的文章, 提到使用`pmap`​查看内存区域时, 有大量`64M`​内存块, 导致内存泄漏.

[glibc虚拟内存问题](https://stackoverflow.com/questions/561245/virtual-memory-usage-from-java-under-linux-too-much-memory-used)

文章指出造成应用程序大量申请`64M`​大内存块的原因是由`Glibc`​的一个版本升级引起的，通过`export MALLOC\_ARENA\_MAX\=4可`​以解决`VSZ`​占用过高的问题。虽然这也是一个问题，但却不是我们想要的，因为我们增长的是物理内存，而不是虚拟内存。

不过不死心的我, 还是尝试了`export MALLOC\_ARENA\_MAX\=4`​, 限制使用的内存池数量, 之后启动进程, 问题依旧\~.

### 内存碎片

在我们安装了`jemalloc`​并强制`JVM`​应用它之后, 我们花了几个小时分析他的内存申请,没有找到任何可疑的地方. 但是我们发现, 内存增长的速度极大的放缓了.

同时我们了解到, `glibc`​标配的`ptmalloc`​在处理高并发的情况下, 内存碎片管理的不够好.

这两个因素, 与我们相当符合:

- 高并发. 我们单机接口2w+ qps, 每次接口调用会进行1600+次的cache查询.
- 我们的缓存很少会移除, 但是更新频率极高. 也就是说, OHC需要大量的释放旧值,替换新值.

因此, 我们用`jemalloc`​替换原装的`ptmalloc`​, 且关闭掉`jeprof`​. 灰度了一台机器, 接收部分流量. 与直接使用`OHC+ptmalloc`​的机器进行内存占用对比, 如下图:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191003414.png" alt="image-20250614191003414" style="zoom:20%;" />

其中: 黄色线条\=`OHC+ptmalloc`​, 绿色线条\=`OHC+jemalloc`​.

可以看到, 在6个小时中, `ptmalloc`​的机器, 在一次OOM之后,内存又上涨到了99%,即将OOM重启. 而`jemalloc`​的机器, 内存仅仅从93.5%-\>94.6%. 这个内存上涨是符合预期的, 因为我们的缓存也会实时增加一部分.

### 问题解决

观察了两天, 线上问题解决. 符合预期正常运行.

因此,暂定以下结论:

- 问题: 使用OHC管理100G左右堆外内存(更新频率较高,缓存条目较多,单个条目不大),占用内存远高于100G, 且不止于150G.
- 解决方案: 使用`jemalloc`​替换linux默认的`ptmalloc`​. 问题得到解决.
- 猜测原因: 大量更新堆外缓存,导致内存碎片化很严重. OHC确实调用了释放内存的接口. 但是由于`ptmalloc`​的原因, 这些内存没有被真正的释放掉,归还给操作系统. 持续占用.

## Protobuf: 高效数据传输的秘密武器

> GitHub：[github.com/protocolbuf…](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf "https://github.com/protocolbuffers/protobuf")
>
> 官方文档：[protobuf.dev/overview/](https://link.juejin.cn/?target=https%3A%2F%2Fprotobuf.dev%2Foverview%2F "https://protobuf.dev/overview/")

[Protobuf: 高效数据传输的秘密武器](https://juejin.cn/post/7231704360668495930?searchId=202407181405554F3CB637AF3E8A87CD0A#heading-7)

### Protobuf 介绍

Protobuf 的核心思想是**使用协议（Protocol）来定义数据的结构和编码方式**。使用 Protobuf，可以先定义数据的结构和各字段的类型、字段等信息，**然后使用Protobuf提供的编译器生成对应的代码**，**用于序列化和反序列化数据**。由于 Protobuf 是基于二进制编码的，因此可以在数据传输和存储中实现更高效的数据交换，同时也可以**跨语言**使用。

相比于 XML 和 JSON，**Protobuf 有以下几个优势**：

- **更小的数据量**：Protobuf 的二进制编码通常比 XML 和 JSON 小 3-10 倍，因此在网络传输和存储数据时可以节省带宽和存储空间。
- **更快的序列化和反序列化速度**：由于 Protobuf 使用二进制格式，所以序列化和反序列化速度比 XML 和 JSON 快得多。
- **跨语言**：Protobuf 支持多种编程语言，可以使用不同的编程语言来编写客户端和服务端。这种跨语言的特性使得 Protobuf 受到很多开发者的欢迎（JSON 也是如此）。
- **易于维护可扩展**：Protobuf 使用 .proto 文件定义数据模型和数据格式，这种文件比 XML 和 JSON 更容易阅读和维护，且可以在不破坏原有协议的基础上，轻松添加或删除字段，实现版本升级和兼容性。

### 为什么高效？

**Protobuf 是如何实现这种高效紧凑的数据编码和解码的呢？**

首先，Protobuf 使用二进制编码，会提高性能；其次 Protobuf 在将数据转换成二进制时，会对字段和类型重新编码，减少空间占用。

它采用 `TLV`​ 格式来存储编码后的数据。`TLV`​ 也是就是 **Tag-Length-Value** ，是一种常见的编码方式，因为数据其实都是键值对形式，所以在 `TAG`​ 中会存储对应的**字段和类型**信息，`Length`​ 存储内容的长度，`Value`​ 存储具体的内容。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191024523.png" alt="image-20250614191024523" style="zoom:30%;" />

还记得上面定义结构体时每个字段都对应一个数字吗？如 `=1`​,`=2`​,`=3`​.

```shell
message Person {
  optional int32 id = 1;
  optional string name = 2;
  optional string email = 3;
}
```

在序列化成二进制时候就是通过这个数字来标记对应的字段的，二进制中只存储这个数字，反序列化时通过这个数字找对应的字段。这也是上面为什么说尽量使用 1-15 范围内的数字，因为一旦超过 15，就需要多一个 bit 位来存储。

那么类型信息呢？比如 `int32`​ 怎么标记，因为类型个数有限，所以 Protobuf 规定了每个类型对应的二进制编码，比如 `int32`​ 对应二进制 `000`​，`string`​ 对应二进制 `010`​，这样就可以只用三个比特位存储类型信息。

> 这里只是举例描述大概思想，具体还有一些变化。
>
> 详情可以参考官方文档：htt[ps://protobuf.dev/programming-guides/encoding/](https://link.juejin.cn/?target=)

其次，Protobuf 还会采用一种**变长编码的方式来存储数据**。这种编码方式能够保证数据占用的空间最小化，从而减少了数据传输和存储的开销。具体来说，Protobuf 会将整数和浮点数等类型变换成一个或多个字节的形式，其中每个字节都包含了一部分数据信息和一部分标识符信息。这种编码方式可以**在数据值比较小的情况下，只使用一个字节来存储数据**，以此来提高编码效率。

最后，Protobuf 还可以通过**采用压缩算法来减少数据传输的大小**。比如 GZIP 算法能够将原始数据压缩成更小的二进制格式，从而在网络传输中能够节省带宽和传输时间。Protobuf 还提供了一些可选的压缩算法，如 zlib 和 snappy，这些算法在不同的场景下能够适应不同的压缩需求。

综上所述，Protobuf 在实现高效编码和解码的过程中，采用了多种优化方式，从而在实际应用中能够有效地提升数据传输和处理的效率。

### 优点

#### 兼容性好

使用Json的时候，有这么一种情况，某个字段值为null或者某个key为null时，Android或IOS相应的Json解析库可能会报错，而Protobuf很好的解决了这问题。

比如，Json序列化的时候，二进制信息如下：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191041040.png" alt="image-20250614191041040" style="zoom:70%;" />

这种定义，可以对数据顺序写入，然后再顺序读取，这样带来一个问题就是，某些字段没有赋值的情况下，不得不传一个默认值，假如field2没有赋值，那么整个解析包偏移量都会出错，最终整个包的数据读不出。

而Protobuf引入了Tag，解决了这个问题：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191055249.png" alt="image-20250614191055249" style="zoom:70%;" />

每个field都是由tag和value组成，解析的时候，先读tag，然后通过tag知道value的数据类型，再获取value，写的时候也是一样，先写入tag再写入value。

因为每个field都定义了tag，如果field没有赋值，编码的时候tag不会被写入流中，相应的也不会有它的Value，相对应的解析的时候，如果数据中没有这个field的tag，可以直接无视，读取其他field。

比如上述的常规定义的的二进制信息,在field2没有赋值的情况下，protobuf可以这样：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191112933.png" alt="image-20250614191112933" style="zoom:70%;" />

还有另外一种兼容的情况，比如：message需要增加一个字段，如果客户端没有升级，服务端升级了，这个时候客户端是旧的message，服务端用的是新的message。

客户端的旧的message：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191127094.png" alt="image-20250614191127094" style="zoom:20%;" />

服务端的新的message：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191139524.png" alt="image-20250614191139524" style="zoom:20%;" />

这样子，客户端接收到服务端发送过来的数据流是这样的：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191158270.png" alt="image-20250614191158270" style="zoom:20%;" />

而当客户端解析这数据的时候，发现数据流里面有个tag为3，但是在客户端的协议里找不到对应的tag，然后通过数据流这个tag，这点了它是数据类型是int64，所以知道了这个tag的值占了8个字节，于是Protobuf就会跳过这8个字节，继续解析后面的数据。

#### 效率高、体积小

Protobuf之所以效率比Json、XML高，是因为内部采用了很巧妙的编码方式，来达到数据压缩的目的，比如：  
对于 int32类型的数字，一般需要4个字节表示，比如1和300：

```java
00000000 00000000 00000000 00000001 //1
00000000 00000000 00000001 00101100 //300
```

而通过Protobuf压缩之后是这样的：

```java
00000001 //1
10101100 00000010 //300
```

##### Varint编码

> 原理：值越小的数字，使用越少的字节数表示
>
> 作用：通过减少表示数字的字节数从而进行数据压缩

Varint编码高位有特殊含义：如果是1，表示后续的字节也是该数字的一部分，如果是0，表示这是最后一个字节，且剩余7位都用来表示数字。

举例下Varint编码和解码过程：

客户端发送300给服务端，通过Protobuf编码过程：

首先300的源数据是：

```java
00000000 00000000 00000001 00101100
```

前面两个字节没有意义，Varint会丢掉前面两字节，这里标记为字节0变成：

```java
 00000001 00101100
```

然后从字节0的尾部开始，取7位，变成新字节1，并在最高位补1，最高位补1还是0，取决于后面还有没有字节，字节1为：

```java
10101100
```

然后继续在字节0中取7位，标记为字节2，由于这次取完后面已经没有字节了，所以字节2高位为0：

```java
00000010
```

最后，最终编码后的数据变成字节1+字节2：

```java
10101100 00000010
```

以上就完成了Varint对300编码，接下来看下服务端接收到编码后的数据怎么解析：

首先，接收到的数据是：

```java
10101100 00000010
```

首先分析下这段数据，有两个字节，每个字节的最高位只是标记的作用，1代表后面的字节是数字的一部分，0表示这个字节是最后一个字节了，所以去掉各自的最高位，变成：

```java
0101100 0000010
```

然后Varint会将字节调转，变成：

```java
0000010 0101100
```

对比300的源数据：

```java
 0000010 0101100
 00000000 00000000 00000001 00101100
```

调转后的数据：256+32+8+4 \= 300

##### 实际例子

**定义Protobuf：**

```java
message person
 { 
    int32   id = 1;  
    // wire type = 0，field_number =1 
    string  name = 2;  
    // wire type = 2，field_number =2 
  }

person.setId(1);
person.setName("testing");
```

上面的wire type的值，Protobuf内部已经定义好了:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191221463.png" alt="image-20250614191221463" style="zoom:70%;" />

###### **首先分析字段** **​`int32 id = 1`​**​ **：**

由于是 int32 类型，所以数据是tag-value形式：

**tag：**

表达式：Tag \= (field\_number \<\< 3) | wire\_type

字段int32 id \= 1的field\_number为1，左移三位变成：

```java
00001000
```

然后数据类型是int32，所以 wire\_type为0，则最终得出的tag为：

```java
00001000
```

**value:**

根据Varint编码，变成1字节：

```java
00000001
```

**最终**

字段 int32 id \= 1变成：

```java
00001000 00000001    //即8 和 1
```

###### 然后分析字段 `string name = 2`​：

由于是string类型，所以是tag-length-value形式，value采用UTF编码

**tag:**

field\_number为2，左移3位：

```java
00010000
```

string类型wire type为2，最终tag为：

```java
00010010
```

**Value:**

上面的例子是字符串testing，经过UTF8编码后，变成：

```java
116，101，115，116，105，110，103
```

**Length**

value的长度，所以是7，即00000111

**最终**

数据为：

```java
00010010  00000111  116，101，115，116，105，110，103
```

### 总结

ProtoBuf 是一种**轻量、高效**的数据交换格式，它具有以下优点：

- **语言中立**，可以支持多种编程语言；
- 数据结构清晰，易于维护和扩展；
- 二进制编码，数据**体积小，传输效率高**；
- 自动生成代码，开发效率高。

但是，ProtoBuf 也存在以下缺点：

- 学习成本较高，需要掌握其语法规则和使用方法；
- 需要先定义数据结构，然后才能对数据进行序列化和反序列化，增加了一定的开发成本；
- 由于二进制编码，**可读性较差，这点不如 JSON 可以直接阅读**。

总体来说，**Protobuf 适合用于数据传输和存储等场景，能够提高数据传输效率和减少数据体积**。但对于需要人类可读的数据，或需要实时修改的数据，或者对数据的传输效率和体积没那么在意的场景，选择更加通用的 JSON 未尝不是一个好的选择。

## 向量检索技术

### faiss 基础介绍

Faiss是Facebook团队开源的向量检索工具，针对高维空间的海量数据，提供高效可靠的检索方式。其优越的性能,广泛应用于推荐系统、图片和视频搜索等业务。

- 应用于推荐系统

几乎是早期大部分互联网公司向量召回的标配工具。

召回算法中矩阵分解、word2vec、youtube dnn,dssm双塔等模型生成的向量信息，都可以通过Faiss进行检索实现召回。

- 应用于搜索

图片搜索，图片信息量较大，维度较高：高x宽xRGB ，Faiss将高维的图片降维如64维，实现相似度检索。

视频搜索，通过抽帧采样，视频可以转化为一批图片集合总和（视频指纹） ，Faiss也常用视频搜索。

视频去重，在内容信息流推荐系统中，如何确认视频是否原创，后发布者与首次发布视频视频指纹相似度。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191242236.png" alt="image-20250614191242236" style="zoom:40%;" />

### 索引方式

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191257350.png" alt="image-20250614191257350" style="zoom:40%;" />

#### 精确索引IndexFlatL2 【慢】

欧式距离L2 (未开方) = (A1-B1)^2 + (A2-B2)^2 + ... + (An-Bn)^2

#### 倒排快速索引IndexIVFFlat 【较快】

大数据量时，对入库的向量数据，进行分割为多个空间。

查询阶段，将查询向量落入的空间中的数据库向量进行比较，返回k个最近邻结果，大幅缩减索引时间。

#### 乘积量化索引IndexIVFPQ 【超快】

上述两种索引方式中，在index中都保存了完整的数据库向量，在数据量非常大的时候会占用太多内存，甚至超出内存限制。

在faiss中，当数据量非常大的时候，可采用乘积量化方法保存原始向量的有损压缩形式，在查询阶段返回近似结果。

超大数据集，如百万-千万，基本都要进行压缩，使用PQ技术，近似检索。

> 所以，基于Product Quantizer(乘积量化)的[压缩算法](https://zhida.zhihu.com/search?q=%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95&zhida_source=entity&is_preview=1)编码向量到指定字节数来减少内存占用。但这种情况下，存储的向量是压缩过的，所以查询的距离也是近似的。

### 数百万物料检索示例

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191316204.png" alt="image-20250614191316204" style="zoom:40%;" />

#### IndexIVFPQ原理

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191329946.png" alt="image-20250614191329946" style="zoom:40%;" />

##### 1. 向量切割

假设我们有1000万个User向量，每个向量是128维的特征向量。首先，我们将每个128维的User向量分割成8个短向量，每个短向量是16维。这意味着每个User向量被拆分为8个部分，每个部分都是16维。

##### 2. 聚类

接下来，我们在每一堆短向量中使用聚类算法（如K-Means）进行聚类。假设我们为每一堆短向量聚类成256类，这意味着每堆短向量都被划分为256个不同的类别。

##### 3. 编码向量

对于每个短向量，我们找到它属于256类中的哪一类。由于每个短向量有256种选择，因此一个User向量通过8个短向量可以表示为64位二进制数（8\*8bit）。这样，每个User向量都被编码为一个64位的索引值。

##### 4. 压缩

每个原始向量通过上述步骤被压缩成一个M个索引值构成的压缩向量。在这个例子中，M是8（因为有8个短向量），每个索引值对应一个聚类中心。这样，压缩向量实际上就是M个索引值，每个索引值指向一个聚类中心。

##### 检索过程

假设用户查询一个视频的128维向量，我们想要找到与该查询最相似的视频。

1. **用户查询**：用户查询一个视频的128维向量。
2. **PQ编码**：查询向量被编码为8个16维的短向量。
3. **搜索倒排文件**：

    - 使用PQ向量搜索倒排文件，找到最相似的5个簇中心。
    - 倒排文件中存储了每个PQ向量对应的簇索引和位置。
4. **查询原始数据**：

    - 根据这5个簇中心，在原始数据中检索到与查询向量最相似的视频。
    - 检索时，我们计算查询向量与每个簇中心向量的距离，找到最相似的视频。

### faiss应用-大规模物料向量召回

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614191345885.png" alt="image-20250614191345885" style="zoom:40%;" />

### Faiss工具的优势与局限

**优势**：

- 优秀的性能，支持大规模数据检索。
- 通过GPU加速，提升性能4-10倍。
- 多种索引方式，平衡性能和空间需求。

**局限**：

- 单机部署，稳定性受限。
- 容量受限，不适合大规模部署。
