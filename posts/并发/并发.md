# 并发

## 并发基础

### 三大特性

众所周知，CPU、内存、I/O 设备的速度是有极大差异的（可以参考这篇文章：[性能第二讲：性能优化-每个程序员都应该知道的数字](https://blog.csdn.net/qq_28959087/article/details/127471432)），为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:

- CPU 增加了缓存，以均衡与内存的速度差异；// 导致 `可见性`问题
- 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 `原子性`问题
- 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 `有序性`问题

**1、原子性**：原子性指的是一个操作是不可分割、不可中断的，要么全部执行并且执行的过程不会被任何因素打断，要么就全都不执行。

**2、可见性**：可见性指的是一个线程修改了某一个共享变量的值时，其它线程能够立即知道这个修改。

**3、有序性**：有序性指的是对于一个线程的执行代码，从前往后依次执行，单线程下可以认为程序是有序的，但是并发时有可能会发生指令重排。

### 并行和并发

从操作系统的角度来看，线程是 CPU 分配的最小单位。

> 1. 并行就是同一时刻，两个线程都在执行。要求有两个 CPU 去分别执行两个线程。

2. 并发就是同一时刻，只有一个执行，但是一个时间段内，两个线程都执行了。并发的实现依赖于 CPU 切换线程，因为切换的时间特别短，所以基本对于用户是无感知的。(单位时间内不一定同时执行)

### LockSupport

- LockSupport 是用来创建锁和共他同步类的基本线程阻塞原语。
- **LockSuport 是一个线程阻塞工具类，所有的方法都是静态方法**，可以让线程在任意位置阻塞，阻塞之后也有对应的唤醒方法。归根结底，LockSupport 调用的 **Unsafe 中的 native** 代码。
- LockSupport 提供 park() 和 unpark() 方法实现 **阻塞线程** 和 **解除线程阻塞** 的过程
- LockSupport 和每个使用它的线程都有一个许可(<span data-type="text" style="color: var(--b3-font-color13);">permit</span>)关联。

  - permit相当于1，0的开关，默认是0，
  - 调用一次unpark就加1变成1，
  - 调用一次park会消费permit，也就是将1变成0，同时park立即返回。
  - 如再次调用 park 会变成阻塞 (因为 permit 为零了会阻塞在这里，一直到 permit 变为1)，这时调用unpark会把permit置为1。每个线程都有一个相关的permit，permit最多只有一个，重复调用 unpark 也不会积累凭证。

### 线程、程序与进程

- 进程

  - 进程是代码在数据集合上的一次运行活动，是 `操作系统` 进行 `资源分配` 和 `调度` 的基本单位
- 线程

  - 线程是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程的资源，`线程` 是处理器 `任务调度` 和 `执行` 的基本单位。
- 程序

  - 含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。

### sleep() 和 wait()

- `Thread.sleep()` 方法自会 `让出` CPU，但 `没有` 释放锁；`Object.wait()` 方法不仅 `让出` CPU，并 `释放` 了锁
- 两者都可以 `暂停线程` 的执行
- `wait() ` 通常被用于 `线程间交互/通信`，`sleep() ` 通常被用于 `暂停执行`
- `wait()` 方法被调用后，线程 `不会自动苏醒`，需要别的线程调用同一个对象上的 `notify()` 或者 `notifyAll()` 方法。`sleep()` 方法执行完成后，线程会 `自动苏醒`。或者可以使用 wait(long timeout) 超时后线程会自动苏醒

### Object.wait()和Condition.await()的区别

`Object.wait()` 和`Condition.await()` 的原理是基本一致的，不同的是**Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的**。

- `Object.wait()`是Java对象监视器（Object Monitor）的一部分，用于线程同步。
- `Condition.await()`是`Condition`接口的一部分，它提供了更灵活的线程同步和等待机制。

### Thread.sleep()和LockSupport.park()的区别

- 从功能上来说，`Thread.sleep()`和`LockSupport.park()`方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源；
- `Thread.sleep()`没法从外部唤醒，只能自己醒过来；
- `LockSupport.park()`方法可以被另一个线程调用`LockSupport.unpark()`方法唤醒；
- `Thread.sleep()`方法声明上抛出了`InterruptedException`中断异常，所以调用者需要捕获这个异常或者再抛出；
- `LockSupport.park()`方法不需要捕获中断异常；
- `Thread.sleep()` 本身就是一个native方法；
- `LockSupport.park()` 底层是调用的Unsafe的native方法；

### Object.wait()和LockSupport.park()的区别

- `Object.wait()` 方法需要在`synchronized`块中执行；
- `LockSupport.park()` 可以在任意地方执行；
- `Object.wait()` 方法声明抛出了中断异常，调用者需要捕获或者再抛出；
- `LockSupport.park()` 不需要捕获中断异常；
- `Object.wait()` 不带超时的，需要另一个线程执行`notify()`来唤醒，但不一定继续执行后续内容；
- `LockSupport.park()` 不带超时的，需要另一个线程执行`unpark()`来唤醒，一定会继续执行后续内容；

`park()`/`unpark()` 底层的原理是“二元信号量”，你可以把它想象成只有一个许可证的`Semaphore`，只不过这个信号量在重复执行`unpark()`的时候也不会再增加许可证，最多只有一个许可证。

### LockSupport.park()会释放锁资源吗?

不会，它只负责阻塞当前线程，释放锁资源实际上是在`Condition`的`await()`方法中实现的。

### 守护线程

Java 中的线程分为两类，分别为 `daemon 线程（守护线程）` 和 `user 线程（用户线程）`。

> 在 JVM 启动时会调用 main 函数，main 函数所在的线程就是一个用户线程。
>
> 其实在 JVM 内部同时还启动了很多守护线程， 如：垃圾回收线程，当我们的程序中不再有任何运行的 Thread，程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是 JVM 上仅剩的线程时，垃圾回收线程会自动离开。

- 有的时候应用中需要一个 `长期驻留的服务程序`，但是 `不希望其影响应用退出`，就可以将其设置为守护线程，如果 JVM 发现只有守护线程存在时，将结束进程
- 守护线程的优先级比较 `低`，用于为系统中的其它对象和线程提供服务
- 通过 `setDaemon(true)` 来设置线程为“守护线程”
- 在 Daemon 线程中产生的新线程也是 Daemon 的

### 线程的状态

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233355843.png" alt="image-20250613233355843" style="zoom:50%;" />

#### `NEW`：新建状态，线程被创建但未启动的状态

> 创建线程有三种⽅式，分别为继承 Thread 类、实现 Runnable 接口、实现 Callable 接口。
>
> 1. 继承 `Thread` 类，重写 run()方法，调用 start()方法启动线程
> 2. 实现 `Runnable` 接口，重写 run()方法，最后通过 Thread 包装并启动 new Thread(task).start();
> 3. 实现 `Callable` 接口，重写 call()方法，这种方式可以通过 FutureTask 获取任务执行的返回值

#### `RUNNABLE`（就绪状态）：调⽤ start 之后运⾏之前的状态

- JVM 执行 `start()`，会先创建一条线程，由创建出来的新线程去执行 thread 的 `run()`，这才起到多线程的效果。
- 如果直接调用 Thread 的 `run()` 方法，那么 run 方法还是运行在主线程中，相当于 `顺序执行`，就起不到多线程的效果。

#### `RUNNING`（运⾏状态）：线程正在运⾏

#### `BLOCKED`（阻塞状态）：进⼊以下状态，有以下⼏种情况

- BLOCKED

  - 阻塞状态（同步阻塞）：锁被其他线程占⽤，如等待进⼊`synchronized`⽅法或者代码块
- WAITING

  - 等待状态（主动阻塞）：执⾏`Object.wait()`，`Thread.join()` 等
- TIME_WAITING

  - (等待阻塞）：执⾏`Object.wait(long)`，`Thread.sleep(long)` 等，该状态不同于 `WAITIND`，它是可以在指定的时间自行返回的

#### `TERMINATED`（终⽌状态）：线程执⾏完毕

### 终止线程

#### 使用 `interrupt()`

- 1. **线程处于阻塞状态：**

     - 例如使用了 sleep，同步锁 wait，sleep 方法，socket 的 receiver、accept 等方法时，会使得线程处于阻塞状态。
     - 当调用线程的 `interrupt` 方法时，会抛出 `InterruptException` 异常。一定要先 `捕获` `InterruptedException` 异常之后通过 break 来跳出循环
  2. **线程未处于阻塞状态：** 需要使用 `interrupted()` 判断线程的中断标识来退出循环。

     - 当使用 `interrupt()` 方法时，中断标志会置位 true，**此时使用自定义标志来控制循环是一样的道理。**

#### 直接使用 `thread.stop()`

- 创建子线程的线程就会抛出 `ThreadDeatherror` 的错误
- 会释放子线程所持有的所有锁(不可控制)
- 不推荐

### 上下文切换

使用多线程的目的是为了充分利用 CPU，但是我们知道，并发其实是一个 CPU 来处理多个线程。
为了让用户感觉多个线程是在同时执行的， CPU 资源的分配采用了时间片轮转也就是给每个线程分配一个时间片，线程在时间片内占用 CPU 执行任务。当线程使用完时间片后，就会处于就绪状态并让出 CPU 让其他线程占用，这就是上下文切换。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233425362.png" alt="image-20250613233425362" style="zoom:80%;" />

> - 上下文
>
>   - 是指某一时间点 CPU 寄存器和程序计数器的内容。
> - 寄存器
>
>   - 是 CPU 内部的数量较少但是速度很快的内存(与之对应的是 CPU 外部相对较慢的 RAM 主内存)。
>   - 寄存器通过对常用值(通常是运算的中间值)的快速访问来提高计算机程序运行的速度。
> - 程序计数器
>
>   - 是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置，具体依赖于特定的系统。
> - PCB-“切换桢”
>
>   - 上下文切换可以认为是内核(操作系统的核心)在 CPU 上对于进程(包括线程)进行切换，上下文切换过程中的信息是保存在进程控制块(PCB, process control block)中的。
>   - PCB 还经常被称作“切换桢” (switchframe)。信息会一直保存到 CPU 的内存中，直到他们被再次使用。

#### 上下文切换的活动

- 挂起一个进程，将这个进程的 `上下文` 信息存储在 cpu 的内存中
- 在内存中检索下一个进程的 `上下文` 并将其在 CPU 的 `寄存器` 中恢复
- 跳转到 `程序计数器` 所指向的位置(即跳转到进程被中断时的代码行)，以恢复该进程在程序中

#### 引起线程上下文切换的原因

1. 当前执行任务的时间片用完之后，系统 CPU 正常调度下一个任务;
2. 当前执行任务碰到 IO 阻塞，调度器将此任务挂起，继续下一任务;
3. 多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务;
4. 用户代码挂起当前任务，让出 CPU 时间;
5. 硬件中断;

### CAS

> CAS(V,E,N)
>
> - V：需要操作的共享变量
> - E：预期值
> - N：新值

在调用 `compareAndSwap` 函数的时候会判断，是否当前变量的数值和 E 是相同的，如果相同则进行修改，否则就说明当前有其他线程修改该值，从而放弃本次修改操作。

通常 CAS 操作会结合一个循环一起使用，当尝试执行 cas 操作却修改失败之后，就会重新将 V 值读出来赋予给 E，然后接着再执行修改操作，直达最终修改成功为止。这个不断尝试修改的过程，我们一般称之为**自旋操作**。所以常见的 cas 结合循环重试的整体流程如下图所示：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233440349.png" alt="image-20250613233440349" style="zoom:80%;" />

#### 存在的问题

- **自旋导致 CPU 消耗升高**

  - 当一个原子类在进行 CAS 操作过多的时候，会导致 CPU 一直被占用，一直消耗资源。通常这种情况发生在高并发场景下会比较多。
- **只能保证一个共享变量原子操作**
- **ABA** 问题

  - > CAS 需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是 A，后来变成了 B，然后又变成了 A，那么 CAS 进行检查时会发现值没有发生变化，但是实际上是有变化的。
    >
  - ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A。
  - 从Java 1.5开始，JDK的Atomic包里提供了一个类`AtomicStampedReference`来解决ABA问题。
  - `AtomicStampedReference` 对象包含两个值：一个对象引用和一个版本号。在 CAS 操作中，它不仅比较对象的引用，还比较版本号。如果对象的引用和版本号都匹配，则更新操作成功；如果只有对象的引用匹配，但版本号不匹配，则更新操作失败，表明变量已经被其他线程更新过。

### 死锁

#### 互斥

- 在一段时间内某资源只能由一个执行实体使用

#### 不可剥夺

- 不能被剥夺，只能使用完自己释放
- 破坏不可剥夺，如果获取不到下一步资源，主动释放之前获取的资源

#### 请求与保持

- 一次性分配所有的资源
- 超时释放资源

#### 环路等待

- 控制资源的请求顺序，尽量防止出现环路等待

### 程序计数器为什么是私有的

程序计数器主要有下面两个作用：

> 1. 节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理
> 2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来时能够知道该线程上次运行到哪儿了

所以，程序计数器私有主要是为了**`线程切换后能恢复到正确的执行位置`**。

### 虚拟机栈和本地方法栈为什么是私有的

> - **虚拟机栈**：每个 Java 方法在执行的同时会创建一个 `栈帧` 用于存储 `局部变量表`、`操作数栈`、`常量池引用` 等信息。从方法调用直至执行完成的过程，就对应着一个 `栈帧` 在 Java 虚拟机栈中 `入栈` 和 `出栈` 的过程。
> - **本地方法栈**：和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 `Native` 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

为了**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的。

### 安全点是什么，如果一段代码怎么走到安全点会怎样？

安全点是程序执行的一个点，在该点上，所有的内存引用都已经稳定，这意味着在该点之后，程序不会修改任何内存引用。安全点通常用于操作系统和数据库管理系统中的检查点操作，以确保数据的一致性和持久性。

在多线程环境中，线程可能会同时访问和修改内存中的数据。为了确保数据的一致性，操作系统和数据库管理系统需要定期将内存中的数据写入磁盘，这个过程称为检查点操作。在进行检查点操作时，需要保证所有线程都已经稳定，即它们不会在检查点操作期间修改内存中的数据。安全点就是这样一个稳定点，所有线程都已经完成了它们的操作，不会影响检查点操作的结果。

如果一段代码进入不了安全点，可能会导致以下问题：

1. **数据不一致**：如果检查点操作在代码不稳定时执行，可能会导致数据不一致，因为线程可能在检查点操作期间修改了内存中的数据。
2. **检查点失败**：如果检查点操作在代码不稳定时执行，可能会导致检查点操作失败，因为无法保证所有线程都已经稳定。
3. **性能问题**：如果检查点操作频繁执行，可能会导致性能问题，因为线程需要在每次检查点操作前稳定。

为了确保安全点，操作系统和数据库管理系统通常会提供机制来检测和等待所有线程稳定。例如，在某些数据库管理系统中，系统会在安全点之前等待所有线程完成它们的操作，确保在检查点操作期间不会发生数据不一致的问题。

## 三大特性以及 JMM 如何解决

### JMM java 内存模型

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233459722.png" alt="image-20250613233459722" style="zoom:50%;" />

> - java 虚拟机定义的一种规范，屏蔽硬件与操作系统的内存访问差异，实现各个平台统一的访问效果
> - 规定所有的变量都是存在 `主内存` 当中，每个线程都有自己的 `工作内存`
> - 线程的 `工作内存` 保存了被该线程使用的变量的 `主内存副本`，线程对变量的所有操作都必须在 `工作内存` 中进行，而不能直接操作操作 `主内存`。并且每个线程不能访问其他线程的 `工作内存`

### 三大特性

#### 原子性（分时复用引起）

> 一组操作，要么全部执行成功，要么全部失败

举个简单的例子，看下面这段代码：

```java
int i = 1;

// 线程1执行
i += 1;

// 线程2执行
i += 1;
```

这里需要注意的是：`i += 1`需要三条 CPU 指令

1. 将变量 i 从内存读取到 CPU寄存器；
2. 在CPU寄存器中执行 i + 1 操作；
3. 将最后的结果i写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。

由于CPU分时复用（线程切换）的存在，线程1执行了第一条指令后，就切换到线程2执行，假如线程2执行了这三条指令后，再切换会线程1执行后续两条指令，将造成最后写到内存中的i值是2而不是3。

#### 可见性（JMM工作内存引起）

> 可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值
>
> - 在多线程中，由于线程对 `共享变量` 的操作都是线程拷贝到各自的 `工作内存` 进行操作后才写回到 `主内存` 中的
>
>   - 这就可能存在一个 `线程A` 修改了共享变量 `i` 的值，还未写回 `主内存` 时，另外一个 `线程B` 又对主内存中同一个共享变量 `i` 进行操作
>   - 但此时 `A` 线程 `工作内存` 中共享变量 ` i` 对线程 `B` 来说并不可见，这种 `工作内存` 与 `主内存` 同步延迟现象就造成了可见性问题。
> - 另外 `指令重排` 以及 `编译器优化` 也可能导致可见性问题

#### 有序性（重排序引起）

> - 有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，这样的理解如果是放在单线程环境下没有问题，毕竟对于单线程而言确实如此，代码由编码的顺序从上往下执行，就算发生指令重排序，由于所有硬件优化的前提都是必须遵守 as-if-serial 语义，所以不管怎么排序，都不会且不能影响单线程程序的执行结果，我们将这称之为有序执行。
> - 反之，对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象，重排后的指令与原指令的顺序未必一致。要明白的是，在 Java 程序中，倘若在本线程内，所有操作都视为有序行为，如果是多线程环境下，一个线程中观察另外一个线程，所有操作都是无序的，前半句指的是单线程内保证串行语义执行的一致性，后半句则指指令重排现象和工作内存与主内存同步延迟现象。

##### 编译器优化指令重排

```java
int a = 0;
int b = 0;

//线程A                   线程B
代码1：int x = a;         代码3：int y = b;
代码2：b = 1;             代码4：a = 2;
```

两个线程同时执行，从程序的执行上来看由于并行执行的原因最终的结果 x = 0;y=0; 本质上是不会出现 x = 2;y = 1; 这种结果，但是实际上来说这种情况是有概率出现的，因为编译器一般会对一些代码前后不影响、耦合度为 0 的代码行进行编译器优化的指令重排，假设此时编译器对这段代码指令重排优化之后，可能会出现如下情况：

```java
//线程A                   线程B
代码2：b = 1;         代码4：a = 2;
代码1：int x = a;     代码3：int y = b;         
```

这种情况下再结合之前的线程安全问题一起理解，那么就可能出现 x = 2;y = 1; 这种结果，这也就说明在多线程环境下，由于编译器会对代码做指令重排的优化的操作（因为一般代码都是由上往下执行，指令重排是 OS 对单线程运行的优化），最终导致在多线程环境下时多个线程使用变量能否保证一致性是无法确定的。

> PS：编译器重排的基础是代码不存在依赖性时才会进行的，而依赖性可分为两种：
>
> - 数据依赖
>
>   - `int a = 1;int b = a;`
> - 控制依赖
>
>   - `boolean f = ture; if(f){sout("123");}`

##### 处理器指令重排

**对于** **`单线程`** **而已指令重排几乎不会带来任何影响，毕竟重排的前提是保证** **`串行语义执行的一致性`** **，但对于多线程环境而已，指令重排就可能导致严重的程序轮序执行问题。**

```java
public class Singleton {
    private static Singleton singleton;
    private Singleton() {

    }
    public static Singleton getInstance() {
        if (singleton == null) {//1
            synchronized {//2
                if (singleton == null) {//3
                    singleton = new Singleton();//4             
                }
            }
        }
    }
}
```

> 这样实现的单例其实是不安全的，执行语句 4 时，实际包含 3 个步骤：
>
> - **给 singleton 分配内存**
> - **在内存中初始化 singleton 对象**
> - 将内存地址赋给 singleton 变量（这时 singleton 变量就不为 null 了）

因为编译器会进行 `指令重排`，如果指令重排之后第 `c` 步先于第 `b` 步执行，那可能会发生如下的错误：

1. `线程1` 执行语句 4，这时 `线程1` 的 `工作内存` 的 `singleton` 变量不为 `null`，可能会立即写回到主存中，也可能迟点再写回到主存中
2. 然后这时线程的时间分片又刚好用完了，就会切换到 `线程2`，如果 `线程1` 的 `singleton` 已经写回到主存中，那么这时 `线程2` 执行语句 1 就为 false，然后返回 `single` 对象，但实际上第 2 步还没执行，即 `对象还没初始化`，使用该对象会导致程序报错。

### JMM 如何解决

JMM本质上可以理解为，**Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法**。具体来说，这些方法包括：

- **volatile、synchronized 和 final 三个关键字**
- **Happens-Before 规则**

#### JMM 中的 happens-before 原则

> 假如在多线程开发过程中我们都需要通过加锁或者 volatile 来解决这些问题的话那么编写程序的时候会非常麻烦，而且加锁其实本质上是让多线程的并行执行变为了串行执行，这样会大大的影响程序的性能，那么其实真的需要嘛？
>
> 不一定需要，因为在 JMM 中还为我们提供了 happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据。
>
> 它真正要表达的是：**前面一个操作的结果对后续操作是可见的**。

happens-before 原则内容如下：

##### 1. 单一线程原则

这条规则是指在 `一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作`。

简单来说就是：一个线程中的每个操作，都`happens-before`该线程中的任意后续操作。

##### 2. 管程中锁的规则

这条规则是指 `对一个锁的解锁 Happens-Before 于后续对这个锁的加锁`。

要理解这个规则，就首先要了解“管程指的是什么”。**管程**是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。

管程中的锁在 Java 里是隐式实现的，例如下面的代码，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。

```java
synchronized (this) { // 此处自动加锁
  // x 是共享变量, 初始值 =10
  if (this.x < 12) {
    this.x = 12; 
  }  
} // 此处自动解锁
```

可以这样理解：假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。这个也是符合我们直觉的，应该不难理解。

##### 3. volatile 变量规则

这条规则是指 `对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作`。

简单的理解就是，**volatile 变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值**。

##### 4. 传递性

这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。

我们将规则 4 的传递性应用到我们的例子中，会发生什么呢？可以看下面这幅图：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233526997.png" alt="image-20250613233526997" style="zoom:40%;" />

从图中，我们可以看到：

> 1. “x=42” Happens-Before 写变量 “v=true” ，这是规则 1 的内容；
> 2. 写变量“v=true” Happens-Before 读变量 “v=true”，这是规则 2 的内容 。

再根据这个传递性规则，我们得到结果：“x=42” Happens-Before 读变量“v=true”。这意味着什么呢？

如果线程 B 读到了“v=true”，那么线程 A 设置的“x=42”对线程 B 是可见的。也就是说，线程 B 能看到 “x == 42” ，有没有一种恍然大悟的感觉？这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大，1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性的，这个在后面的内容中会详细介绍。

##### 5. 线程 start() 规则

这条是关于线程启动的。它是指 `主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作`。

换句话说就是，如果线程 A 调用线程 B 的 start() 方法（即在线程 A 中启动线程 B），那么该 start() 操作 Happens-Before 于线程 B 中的任意操作。具体可参考下面示例代码。

```java
Thread B = new Thread(()->{
  // 主线程调用 B.start() 之前
  // 所有对共享变量的修改，此处皆可见
  // 此例中，var==77
});
// 此处对共享变量 var 修改
var = 77;
// 主线程启动子线程
B.start();
```

##### 6. 线程 join() 规则

这条是关于线程等待的。它是指 `主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作`。当然所谓的“看到”，指的是对**共享变量**的操作。

换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。具体可参考下面示例代码。

```java
Thread B = new Thread(()->{
  // 此处对共享变量 var 修改
  var = 66;
});
// 例如此处对共享变量修改，
// 则这个修改结果对线程 B 可见
// 主线程启动子线程
B.start();
B.join()
// 子线程所有对共享变量的修改
// 在主线程调用 B.join() 之后皆可见
// 此例中，var==66
```

##### 7. 线程中断规则

对 `线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生`，可以通过 Thread.interrupted()方法检测线程是否中断。

##### 8. 对象终结规则

`对象的构造函数执行，结束先于finalize()方法`。

happens-before 原则无需添加任何手段来保证，这是由 JMM 规定的，Java 程序默认遵守如上八条原则。

> 下面我们再通过之前的案例重新认识这八条原则是如何判断线程是否会出现安全问题：

```java
int a = 0;
boolean f = false;
public void methodA(){
    a = 1;
    f = true;
}
public void methodB(){
    if(f) int i = a + 1；
}
```

同样的道理，存在两条线程 A 和 B，线程 A 调用实例对象的 methodA()方法，而线程 B 调用实例对象的 methodB()方法，线程 A 先启动而线程 B 后启动，那么线程 B 读取到的 i 值是多少呢？

现在依据 8 条原则，由于存在两条线程同时调用，因此程序次序原则不合适。methodA()方法和 methodB()方法都没有使用同步手段，锁规则也不合适。没有使用 volatile 关键字，volatile 变量原则不适应。线程启动规则、线程终止规则、线程中断规则、对象终结规则、传递性和本次测试案例也不合适。线程 A 和线程 B 的启动时间虽然有先后，但线程 B 执行结果却是不确定，也是说上述代码没有适合 8 条原则中的任意一条，也没有使用任何同步手段，所以上述的操作是线程不安全的，因此线程 B 读取的值自然也是不确定的。

修复这个问题的方式很简单，要么给 methodA()方法和 methodB()方法添加同步手段（加锁）或者给共享变量添加 volatile 关键字修饰，保证该变量在被一个线程修改后总对其他线程可见。

## 线程间协作（同步）

### join() 稍等，等我结束你再开始

> 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。

对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。

```java
public class JoinExample {

    private class A extends Thread {
        @Override
        public void run() {
            System.out.println("A");
        }
    }

    private class B extends Thread {

        private A a;

        B(A a) {
            this.a = a;
        }

        @Override
        public void run() {
            try {
                a.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("B");
        }
    }

    public void test() {
        A a = new A();
        B b = new B(a);
        b.start();
        a.start();
    }
}
public static void main(String[] args) {
    JoinExample example = new JoinExample();
    example.test();
}
A
B
```

### Object的wait()/notify()/notifyAll()

> - 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。
> - 它们都属于 Object 的一部分，而不属于 Thread。
> - 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。

### Condition的await()/signal()/signalAll()

> java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。

```java
public class AwaitSignalExample {
    private Lock lock = new ReentrantLock();
    private Condition condition = lock.newCondition();

    public void before() {
        lock.lock();
        try {
            System.out.println("before");
            condition.signalAll();
        } finally {
            lock.unlock();
        }
    }

    public void after() {
        lock.lock();
        try {
            condition.await();
            System.out.println("after");
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }
}
public static void main(String[] args) {
    ExecutorService executorService = Executors.newCachedThreadPool();
    AwaitSignalExample example = new AwaitSignalExample();
    executorService.execute(() -> example.after());
    executorService.execute(() -> example.before());
}
before
after
```

### LockSupport 的park()/unpark()

```java
class MyThread extends Thread {
    private Object object;

    public MyThread(Object object) {
        this.object = object;
    }

    public void run() {
        System.out.println("before unpark");
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 获取blocker
        System.out.println("Blocker info " + LockSupport.getBlocker((Thread) object));
        // 释放许可
        LockSupport.unpark((Thread) object);
        // 休眠500ms，保证先执行park中的setBlocker(t, null);
        try {
            Thread.sleep(500);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 再次获取blocker
        System.out.println("Blocker info " + LockSupport.getBlocker((Thread) object));

        System.out.println("after unpark");
    }
}

public class test {
    public static void main(String[] args) {
        MyThread myThread = new MyThread(Thread.currentThread());
        myThread.start();
        System.out.println("before park");
        // 获取许可
        LockSupport.park("ParkAndUnparkDemo");
        System.out.println("after park");
    }
}
```

1. wait():使一个线程处于等待(阻塞)状态，并且释放所持有的对象的锁;
2. sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 InterruptedException 异常;
3. notify():唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一 个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关;
4. notityAll():唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态;

## 线程安全的实现方法

### 阻塞同步

`synchronized` 和 `ReentrantLock` 。

> 互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。
>
> 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。

### 非阻塞同步

**CAS 和 AtomicInteger**

> 随着硬件指令集的发展，我们可以使用**基于冲突检测的乐观并发策略**: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，**否则采取补偿措施(不断地重试，直到成功为止)** 。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。

### 无同步方案

>  要保证线程安全，并不是一定就要进行同步。如果一个方法**本来就不涉及共享数据**，那它自然就无须任何同步措施去保证正确性。

#### **栈封闭**

多个线程访问同一个**方法的局部变量**时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。

```java
public class StackClosedExample {
    public void add100() {
        int cnt = 0;
        for (int i = 0; i < 100; i++) {
            cnt++;
        }
        System.out.println(cnt);
    }
}
public static void main(String[] args) {
    StackClosedExample example = new StackClosedExample();
    ExecutorService executorService = Executors.newCachedThreadPool();
    executorService.execute(() -> example.add100());
    executorService.execute(() -> example.add100());
    executorService.shutdown();
}
```

#### **线程本地存储(Thread Local Storage)**

#### **可重入代码(Reentrant Code)**

> 这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。
>
> 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。

## 线程池

### **使用线程池的好处**

> - **降低资源消耗**
>
>   - 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
> - **提高响应速度**
>
>   - 当任务到达时，任务可以不需要的等到线程创建就能立即执行。
> - **提高线程的可管理性**
>
>   - 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 创建线程池

#### JDK 提供的原生线程池 Executors 类

##### newSingleThreadExecutor

###### 特点

- 核心线程数为 1
- 最大线程数也为 1
- 阻塞队列是无界队列 `LinkedBlockingQueue`，可能会导致 OOM

###### **工作流程：**

- 提交任务
- 线程池是否有一个线程在，如果没有，新建线程执行任务
- 如果有，将任务加到阻塞队列
- 当前的唯一线程，从队列取任务，执行完一个，再继续取，一个线程执行任务

##### newFixedThreadPool

###### 特点

- 核心线程数和最大线程数大小一样
- 没有所谓的非空闲时间，即 keepAliveTime 为 0
- 阻塞队列为无界队列 `LinkedBlockingQueue`，可能会导致 OOM

###### **工作流程：**

- 提交任务
- 如果线程数少于核心线程，创建核心线程执行任务
- 如果线程数等于核心线程，把任务添加到 `LinkedBlockingQueue` 阻塞队列
- 如果线程执行完任务，去阻塞队列取任务，继续执行。

##### newCachedThreadPool

###### 特点

- 核心线程数为 0
- 最大线程数为 `Integer.MAX_VALUE`，即无限大，可能会因为无限创建线程，导致 OOM
- 阻塞队列是 `SynchronousQueue`
- 非核心线程空闲存活时间为 60 秒
- 当提交任务的速度大于处理任务的速度时，每次提交一个任务，就必然会创建一个线程。极端情况下会创建过多的线程，耗尽 CPU 和内存资源。由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。
- **适用于执行大量的短时任务，‌并且SynchronousQueue的特性能够有效地支持这种使用场景**
- `SynchronousQueue`的内部容量为0，‌这意味着它不存储任何数据，‌每个put操作必须等待一个对应的take操作，‌反之亦然。‌这种机制确保了线程之间的直接交互，‌避免了数据的中间存储环节，‌从而减少了线程间的竞争和等待时间。‌

###### **工作流程：**

- 提交任务
- 因为没有核心线程，所以任务直接加到 `SynchronousQueue` 队列。
- 判断是否有空闲线程，如果有，就去取出任务执行。
- 如果没有空闲线程，就新建一个线程执行。
- 执行完任务的线程，还可以存活 60 秒，如果在这期间，接到任务，可以继续活下去；否则，被销毁。

##### newScheduledThreadPool

###### 特点

- 最大线程数为 `Integer.MAX_VALUE`，也有 OOM 的风险
- 阻塞队列是 `DelayedWorkQueue`
- keepAliveTime 为 0
- scheduleAtFixedRate() ：按某种速率周期执行
- scheduleWithFixedDelay()：在某个延迟后执行

###### 工作流程：

- 线程从 DelayQueue 中获取已到期的 ScheduledFutureTask（DelayQueue.take()）。到期任务是指 ScheduledFutureTask 的 time 大于等于当前时间。
- 线程执行这个 ScheduledFutureTask。
- 线程修改 ScheduledFutureTask 的 time 变量为下次将要被执行的时间。
- 线程把这个修改 time 之后的 ScheduledFutureTask 放回 DelayQueue 中（DelayQueue.add()）。

#### ThreadPoolExecutor 类创建

##### 核心参数

- corePoolSize

  - 核心线程池的大小
  - 如果核心线程池有空闲位置，这时新的任务就会被核心线程池新建一个线程执行
- maximumPoolSize

  - 线程池能创建最大的线程数量
- keepAliveTime

  - 非核心线程能够空闲的最长时间，超过时间，线程终止
- unit
- workQueue 阻塞队列

  - `ArrayBlockingQueue`：基于数组的先进先出队列，此队列创建时必须指定大小；
  - `LinkedBlockingQueue`：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为 Integer.MAX_VALUE；
  - `SynchronousQueue`：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。
- threadFactory

  - 线程工厂，用来创建线程
- handler

  - 任务拒绝策略，线程数量 `大于` 最大线程数就会采用拒绝处理策略
  - AbortPolicy

    - 丢弃任务并抛出 RejectedExecutionException 异常
  - DiscardPolicy

    - 丢弃任务，但是不抛出异常
  - DiscardOldestPolicy

    - 丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
  - CallerRunsPolicy

    - 由调用线程处理该任务

##### 线程池参数合理配置

- CPU 密集型

  - cpu 核心数 + 1
- IO 密集型

  - CPU 核心数 * 2
- 混合型

### 原理

#### `execute(Runnable command)`

```java
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();
    // 获取当前的工作线程数量是否小于核心线程数
    if (workerCountOf(c) < corePoolSize) {
        // 创建核心线程
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 如果当前线程数大于核心数且线程是运行中并且能够放入队列（未满）
    if (isRunning(c) && workQueue.offer(command)) {
        //二次检查
        int recheck = ctl.get();
        // 如果二次检查时线程不是运行状态则从队列删除任务，将任务执行拒绝策略
        if (! isRunning(recheck) && remove(command))
            reject(command);
        // 如果是运行状态，则检查当前运行的线程数，是否因为异常或其他原因到只数量为0，此时直接将任务执行，发布为非核心线程
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    else if (!addWorker(command, false))
        reject(command);
}
```

#### `addWorker(Runnable firstTask, boolean core)`

我们重点关注`addWorker`这个方法，这个方法主要就是创建了一个`Worker`对象，并将`Worker`对象中的线程启动起来，这个对象是一个 Runnable 的子类。

```java
private final class Worker extends AbstractQueuedSynchronizer implements Runnable {}
```

Worker 对象本身是一个 Runnable 的子类，在创建 Worker 的时候会调用我们传递的线程工厂（ThreadFactory），创建一个新的线程对象，并将本身传递到线程工厂中。ThreadFactory 会根据传递的 Runable 创建一个线程，保存到变量中，Worker 的构造函数如下：

```java
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c); // 拿到线程池的状态

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN && // 如果当前线程状态不是RUNNING，再次做后续判断，查看当前任务是否可以不处理
            ! (rs == SHUTDOWN && // 线程池状态为SHUTDOWN，并且任务为空，并且工作队列不为空
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            int wc = workerCountOf(c); // 获取当前工作线程数
            if (wc >= CAPACITY || // 判断工作线程是否大于最大值
                wc >= (core ? corePoolSize : maximumPoolSize)) //  如果是核心线程,是否大于设置的corePoolSize
                return false;
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs) // 基于新获取的ctl拿到线程池状态,判断和之前的rs状态是否一致
                continue retry; // 说明并发操作导致线程池状态变化,需要重新判断状态
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        w = new Worker(firstTask); // new Worker构建工作线程，将任务扔到了Worker中
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock(); // 加锁
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get()); // 拿到线程池的状态

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) { // 如果线程池状态为SHUTDOWN并且传入的任务为null
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    workers.add(w); // 将构建好的worker对象添加到workers
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) { // 只要添加工作线程成功，启动线程
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w); // 如果启动工作线程失败，做的补救操作
    }
    return workerStarted;
}
```

1. 获取当前线程池的状态，如果是STOP，TIDYING,TERMINATED状态的话，则会返回false，如果现在状态是SHUTDOWN，但是firstTask不为空或者workQueue为空的话，那么直接返回false。
2. 通过自旋的方式，判断要添加的Worker是否是corePool，如果是的话，那么则判断当前的workerCount是否大于corePoolsize，否则则判断是否大于maximumPoolSize，如果满足的话，说明workerCount超出了线程池大小，直接返回false。如果小于的话，那么判断是否成功将WorkerCount通过CAS操作增加1，如果增加成功的话。则进行到第3步，否则则判断当前线程池的状态，如果现在获取到的状态与进入自旋的状态不一致的话，那么则通过`continue retry`重新进行状态的判断。
3. 如果满足了的话，那么则创建一个新的Worker对象，然后获取线程池的重入锁后，判断当前线程池的状态，如果当前线程池状态为STOP,TIDYING,TERMINATED的话，那么调用decrementWorkerCount将workerCount减一，然后调用tryTerminate停止线程池，并且返回false。
4. 如果状态满足的话，那么则在workers中将新创建的worker添加，并且重新计算largestPoolSize，然后启动Worker中的线程开始执行任务。
5. 重新Check一次当前线程池的状态，如果处于STOP状态的话，那么就调用interrupt方法中断线程执行。

#### `runWorker(Worker w)`

在 worker 的 run 方法中重点调用了`runWorker`方法。我们重点分析`runWorker`方法的源码逻辑：

```java
final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    //获取提交的任务
    Runnable task = w.firstTask;
    try {
        //死循环  如果提交的任务不为空 或者从阻塞队列中取值，没有任务就阻塞等待任务
        while (task != null || (task = getTask()) != null) {
            w.lock();
            try {
                //任务开始前，调用beforeExecute钩子函数
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    //开始执行任务  直接调用提交任务的run方法
                    task.run();
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    //任务执行后 调用钩子函数afterExecute
                    afterExecute(task, thrown);
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
```

### 线程池中非核心线程是如何回收的

```java
final void runWorker(Worker w) {
    Runnable task = w.firstTask; // 获取提交的任务
    w.firstTask = null;
    try {
        // 死循环  如果提交的任务不为空 或者从阻塞队列中取值，没有任务就阻塞等待任务
        // 获取任务的第一个方式,就是执行execute submit时,传入的任务直接处理
        // 获取任务的第二个方式,就是从工作队列中获取任务执行
        while (task != null || (task = getTask()) != null) {
            ......
        }
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}

```

里面是一个while循环，循环判断任务是否为空，若不为空，执行任务；若取不到任务，或发生异常，退出循环，执行`processWorkerExit(w, completedAbruptly);` 在这个方法里把工作线程移除掉。

取任务的来源有两个，一个是`firstTask`，这个是工作线程第一次跑的时候执行的任务，最多只能执行一次，后面得从`getTask()`方法里取任务。

看来，`getTask()`是关键，在不考虑异常的场景下，返回null，就表示退出循环，结束线程。下一步，就得看看，什么情况下`getTask()`会返回null。

#### getTask() 返回null

```java
private Runnable getTask() {
    boolean timedOut = false; // 表示当前线程获取任务是否超时； 默认 false, 未超时

    for (;;) { // 自旋
        int c = ctl.get();
        int rs = runStateOf(c);  // 获取线程池当前运行状态

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) { // 线程池的状态已经是`STOP`，`TIDYING`, `TERMINATED`，或者是`SHUTDOWN`且工作队列为空
            decrementWorkerCount();
            return null;
        }

        int wc = workerCountOf(c); // 获取线程池中的线程数量

        /**
             * true: 表示当前这个线程 获取 task 时 是支持超时机制的
             * false: 表示当前线程不支持超时机制。 核心线程数量内的线程会使用 queue.take();
             * allowCoreThreadTimeOut == ture 表示核心线程数量内的线程，可以被回收； false不可以被回收
             * wc > corePoolSize :  当前线程池中的数量时大于核心线程数的。
             */
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

        /**
             * 条件1:(wc > maximumPoolSize || (timed && timedOut)： 为ture 不代表线程一定返回null
             *    1.1 wc > maximumPoolSize ： 可能外部线程将线程池最大线程数设置为比初始化时的要小
             *    1.2  timed && timedOut ：当前线程使用poll方式获取task。 上一次循环时， 使用 pool方式获取任务时，超时了。
             * 条件二:   (wc > 1 || workQueue.isEmpty())
             *    2.1: wc > 1： 说明当前线程池中，还有其他线程；当前线程可以直接回收，返回null。
             *    2.2: 说明当前任务队列已经为null。 最后一个线程也可以放心退出
             */
        if ((wc > maximumPoolSize || (timed && timedOut))
            && (wc > 1 || workQueue.isEmpty())) {
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue; // CAS失败，就继续；再次自旋时，timed可能为 false
        }

        try {
            Runnable r = timed ?
            workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
            workQueue.take(); // 获取任务的逻辑
            if (r != null)
                return r;
            timedOut = true; // 说明当前线程超时了。
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}
```

##### 总结

`ThreadPoolExecutor`回收工作线程，一旦线程`getTask()`返回null，就会跳出`while`循环，执行`processWorkerExit(w, completedAbruptly)`被回收。

分两种场景。

1. 未调用`shutdown()` ，RUNNING状态下全部任务执行完成的场景

    1. 线程数量大于`corePoolSize`，线程超时阻塞，超时唤醒后`CAS`减少工作线程数，如果`CAS`成功，返回null，线程回收。否则进入下一次循环。当工作者线程数量小于等于`corePoolSize`，就可以一直阻塞了。

2. 调用`shutdown()` ，全部任务执行完成的场景

    `shutdown()` 会向所有线程发出`中断信号`，这时有两种可能。

    1. 所有线程都在阻塞

        1. `中断唤醒`，进入循环，都符合第一个if判断条件，都返回null，所有线程回收。
    2. 任务还没有完全执行完

        1. 至少会有一条线程被回收。在`processWorkerExit(Worker w, boolean completedAbruptly)`方法里会调用`tryTerminate()`，向任意空闲线程发出中断信号。所有被阻塞的线程，最终都会被一个个唤醒，回收。

### 获取任务的时候，线程是如何阻塞的

其实现在阻塞主要是通过`ArrayBlockingQueue`实现的

```java
/** 提供独占锁机制，来保护竞争的资源 */
final ReentrantLock lock;

/** 表示"锁的非空条件"。当某线程想从队列中获取数据的时候，而此时队列中的数据为空，
则该线程通过notEmpty.await()方法进行等待；当其他线程向队列中插入元素之后，
就调用notEmpty.signal()方法进行唤醒之前等待的线程 */
private final Condition notEmpty;

/** 表示“锁满的条件“。当某个线程向队列中插入元素，而此时队列已满时，该线程等待，
即阻塞通过notFull.wait()方法；其他线程从队列中取出元素之后，就唤醒该等待的线程，
这个线程调用notFull.signal()方法 */
private final Condition notFull;
```

详见 ArrayBlockingQueue

### **提交到线程池里的任务，是如何知道直接结束，如何能拿到任务结果的？**

详见 futureTask

## volatile

### 作用

- 保证可见性
- 禁止指令重排序

### 原理

- 对 `volatile` 修饰的变量

  - 写操作 `之后`，编译器会插入一个 `写屏障`
  - 读操作 `之前`，编译器会插入一个 `读屏障`
- happens-before 原则，重排序时不能把后面的指令重排序到 `内存屏障` 之前的位置
- 写入动作也会引起别的 CPU 或者别的内核无效化其 Cache，相当于让新写入的值对别的线程可见

### volatile 和 synchronized

synchronized 关键字和 volatile 关键字是两个 `互补` 的存在，而不是对立的存在！

- `volatile` 只能修饰变量，`synchronized` 还可以修饰方法以及代码块
- `volatile` 只能保证数据的可见性，不能保证原子性，`synchronized` 关键字两者都能保证
- `volatile` 关键字是线程同步的 `轻量级` 实现，所以 volatile `性能` 肯定比 synchronized 关键字要好
- `volatile` 关键字主要用于解决变量在多个线程之间的 `可见性`，而 `synchronized` 关键字解决的是多个线程之间 `访问资源` 的同步性

### 适用场景

- 一次性安全发布

  - 双重检查锁定
- 读多写少

  - `volatile` 修饰变量，读时无锁，写时加 `synchronized`

## synchronized

### 使用方式

- 修饰实例方法

  - `synchronized void method() {}`
  - **对象实例锁**
- 修饰静态方法

  - `synchronized void staic method() {}`
  - **class 锁**
- 修饰代码块

  - `synchronized(this) {}`
  - **对象实例锁**

### 底层原理

#### monitorenter、monitorexit、ACC_SYNCHRONIZED

##### 同步代码块

- 代码块前形成 `monitorenter` 字节码指令
- 代码块后形成 `monitorexit` 字节码指令
- 执行 `monitorenter` 指令时，首先尝试获取对象的锁，如果这个锁没有被锁定或者当前线程已经拥有了那个对象的锁，锁的计数器就 +1
- 执行 `monitorexit` 指令时会将锁的计数器减 1，当减为 0 的时候就释放锁
- 如果获取对象锁一直失败，那当前线程就要阻塞等待，直到对象锁被另一个线程释放为止

##### 同步方法

- JVM 可以从方法常量池的方法表结构中的 `ACC_SYNCHRONIZED` 访问标志得知一个方法是否声明为同步方法
- 当方法调用的时，调用指令会检查方法的 `ACC_SYNCHRONIZED` 访问标志是否被设置
- 如果设置了，执行线程就要求先持有 `monitor` 对象，然后才能执行方法
- 最后当方法执行完（无论是正常完成还是非正常完成）时释放 `monitor` 对象

#### monitor监视器

monitor是什么呢？操作系统的管程（monitors）是概念原理，ObjectMonitor是它的原理实现。

在Java虚拟机（HotSpot）中，Monitor（管程）是由ObjectMonitor实现的，其主要数据结构如下：

```c++
 ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 记录个数
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL;  // 处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ;  // 处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
  }
```

ObjectMonitor中几个关键字段的含义如图所示：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233626349.png" alt="image-20250613233626349" style="zoom:80%;" />

#### Java Monitor 的工作机理

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233639304.png" alt="image-20250613233639304" style="zoom:70%;" />

- 想要获取monitor的线程,首先会进入_EntryList队列。
- 当某个线程获取到对象的monitor后,进入Owner区域，设置为当前线程,同时计数器count加1。
- 如果线程调用了wait()方法，则会进入WaitSet队列。它会释放monitor锁，即将owner赋值为null,count自减1,进入WaitSet队列阻塞等待。
- 如果其他线程调用 notify() / notifyAll() ，会唤醒WaitSet中的某个线程，该线程再次尝试获取monitor锁，成功即进入Owner区域。
- 同步方法执行完毕了，线程退出临界区，会将monitor的owner设为null，并释放监视锁。

#### 对象与monitor关联

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233658847.png" alt="image-20250613233658847" style="zoom:70%;" />

- 在HotSpot虚拟机中,对象在内存中存储的布局可以分为3块区域：对象头（Header），实例数据（Instance Data）和对象填充（Padding）。
- 对象头主要包括两部分数据：Mark Word（标记字段）、Class Pointer（类型指针）。
- Mark Word 是用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等。
- 重量级锁，指向互斥量的指针。其实synchronized是重量级锁，也就是说Synchronized的对象锁，Mark Word锁标识位为10，其中指针指向的是Monitor对象的起始地址。

### 锁膨胀

#### 无锁态

- 延迟 4s，偏向锁

  - 当我们在 Java 程序中 new 一个对象时，会默认启动匿名偏向锁，但是值得注意的是有个小细节，偏向锁的启动有个延时，默认是 4 秒
  - JVM 启动四秒之后再开启匿名偏向锁，在 JVM 启动时前四秒内 new 的对象不会启动匿名偏向锁
  - JVM 虚拟机自己有一些默认启动的线程，里面有好多 sync 代码，这些 sync 代码启动时就知道肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作，效率较低
- `markword` 中的 `threadId` 为空，相当于无锁

#### 偏向锁

##### 引入目的

- 在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得
- 因此为了减少同一线程获取锁(会涉及到一些 CAS 操作,耗时)的代价而引入偏向锁

##### 核心思想

- 如果一个线程获得了锁，那么锁就进入偏向模式，此时 `Mark Word` 的结构也变为偏向锁结构
- 当这个线程再次请求锁时，无需再做任何同步操作，这样就省去了大量有关锁申请的操作，从而也就提升程序的性能

##### 执行流程

- `线程1` 获取锁对象时，会在 java `对象头` 中记录 `threadId`（偏向锁不会主动释放）
- 以后 `线程1` 再获取锁时，比较 `当前线程id` 与 java `对象头` 的 `threadId` 是否一致（无需 CAS 和加锁）
- 如果不一致，查看 java `对象头` 中的 `线程1` 是否 `存活`，如果不存话，重置为无锁状态，`重新竞争`
- 如果存活，查找 `线程1` 的 `栈帧` 信息，看看是否还需要持有这个锁对象，如果需要，`升级` 轻量级锁

#### 轻量级锁

##### 引入目的

- 竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景。
- 因为阻塞线程需要 CPU 从 `用户态` 转到 `内核态`，代价较大，如果刚刚阻塞不久这个锁就被释放了，那这个代价就有点得不偿失了
- 因此这个时候就干脆不阻塞这个线程，让它 `自旋` 这等待锁释放

自旋次数有 `限制`，会升级重量级锁

###### 自适应自旋锁

线程空循环等待的自旋次数并非是固定的，而是会动态着根据实际情况来改变自旋等待的次数。

#### 重量级锁

**`锁可以升级不可以降级，但是偏向锁状态可以被重置为无锁状态`** **。**

### thread 等待唤醒机制

- `notify`/`notifyAll` 和 `wait` 方法必须在 `synchronized` 代码块或者方法中

  - 调用方法前，必须拿到 `monitor` 对象
  - `monitor` 存在对象头 `MarkWord`(monitor 引用指针)
  - `synchronized` 可以获取 `monitor`，所以必须在 `synchronized` 中

**注意**

- `sleep()` 只是线程休眠，不释放锁
- `notify` 不会立马释放 `monitor` 锁，而是等到 `synchronized` 执行结束

### Synchronized 与 ReentrantLock

#### 为什么重复造轮子

##### 能够响应中断

- `synchronized` 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。
- 但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。这样就破坏了 `不可抢占条件` 了

##### 支持超时

- 如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。这样也能破坏 `不可抢占条件`

##### 非阻塞地获取锁

- 如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏 `不可抢占条件`

#### 区别

- `ReentrantLock` 实现了 Lock 接口，`synchronized` 是系统关键字
- `ReentrantLock` 需要手动指定锁范围，`synchronized` 支持同步块、同步方法
- 都具有可重入性
- 默认都是 `非公平` 锁，`ReentrantLock` 还支持公平模式，但性能会急剧下降
- `ReentrantLock` 需要显示的获取锁、释放锁
- `ReentrantLock` 可以同时绑定多个 `Condition` 条件对象

### JVM锁的优化

- 锁的粗化
- 锁消除

  - 局部变量，并且不会被其他线程所使用

> 通过运行时**JIT编译器的逃逸分析**来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配 (同时还可以减少Heap上的垃圾收集开销)

- 自适应自旋锁

## atomic

所谓原子类说简单点就是具有原子/原子操作特征的类。

### 原理

> - CAS + volatile 保证原子性

AtomicInteger 类的部分源码：

```java
public class AtomicInteger extends Number implements java.io.Serializable {
    private static final long serialVersionUID = 6214790243416807050 L;
    // setup to use Unsafe.compareAndSwapInt for updates
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;
    static {
        try {
            valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));
        } catch(Exception ex) {
            throw new Error(ex);
        }
    }
    private volatile int value;
    public native long objectFieldOffset(Field var1);
}
```

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

## LongAdder

LongAdder 是 Striped64 的子类，Striped64 是 Number 子类

```java
public class LongAdder extends Striped64 {}
abstract class Striped64 extends Number {}

base: 类似于AtomicLong中全局的value值。在没有竞争情况下数据直接累加到base上，或者cells扩容时,也需要将数据写入到base上
collide: 表示扩容意向，false一定不会扩容，true可能会扩容
cellsBusy: 初始化cells或者扩容cells需要获取锁，0表示无锁状态，1表示其他线程已经持有了锁
casCellsBusy: 通过CAS操作修改cellsBusy的值， CAS成功代表获取锁，返回true
NCPU: 当前计算机CPU数量，Cell数组扩容时会使用到
getProbe(): 获取当前线程的hash值
advanceProbe(): 重置当前线程的hash值

==============================================================
abstract class Striped64 extends Number {

    // CPU数量，即Cells数组的最大长度
    static final int NCPU = Runtime.getRuntime().availableProcessors();

    // 存放Cell的hash表，大小为2的幂
    // 这里的Cell是Striped64的静态内部类，懒惰初始化
    transient volatile Cell[] cells;

    /*
    1.在开始没有竞争的情况下，将累加值累加到base；
    2.在cells初始化的过程中，cells处于不可用的状态，这时候也会尝试将通过cas操作值累加到base
    */
    transient volatile long base;

    /*
    cellsBusy，它有两个值0或1，它的作用是当要修改cells数组时加锁,
    防止多线程同时修改cells数组(也称cells表)，0为无锁，1位加锁，加锁的状况有三种:
    (1)cells数组初始化的时候；
    (2)cells数组扩容的时候；
    (3)如果cells数组中某个元素为null，给这个位置创建新的Cell对象的时候；
    */
    transient volatile int cellsBusy;
}
```

### LongAdder为什么快？

- LongAdder基本思路就是分散热点，将value分散到一个Cell数组中，不同线程会命中数组的不同槽位中，各个线程只对自己槽位的value进行CAS操作，这样热点就被分散了，冲突概率小了
- sum()会将所有Cell数组中的value和base累加作为返回值，核心思想就是将之前AtomicLong一个value的更新压力分散到多个value中去，从而降级更新热点
- 内部有一个base+一个Cell[ ]数组

  - base变量：低并发，直接累加到该变量上
  - Cell[ ]数组：高并发，累加到各个线程自己的槽Cell[i]中

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233729105.png" alt="image-20250613233729105" style="zoom:70%;" />

- LongAdder在无竞争的情况下，跟AtomicLong一样， 对同一个base进行操作
- 当出现竞争时，则采用化整为零分散热点的做法，用空间换时间，用一个数组cells，将一个value拆分进这个数组cells
- 多个线程需要同时对value进行操作的时候，可以对线程id进行hash得到hash值，再根据hash值映射到这个数组cells的某个下标，再对该下标所对应的值进行自增操作
- 当所有线程操作完毕，将数组cells的所有值和base都加起来作为最终结果

### LongAdder之缓存行伪共享

#### Striped64中静态内部类Cell源码

```java
abstract class Striped64 extends Number {
    // 防止缓存行伪共享 注解
    @sun.misc.Contended
    static final class Cell { // Cell 即为累加单元
        // 保存累加结果
        volatile long value;
        // 构造方法为value赋初始值
        Cell(long x) { value = x; }
        
        // 最重要的方法, 用来 cas 方式进行累加, prev 表示旧值, next 表示新值
        final boolean cas(long prev, long next) {
          return UNSAFE.compareAndSwapLong(this, valueOffset, prev, next);
        }
        // 省略其他代码
    }
}
```

#### CPU缓存结构

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233753026.png" alt="image-20250613233753026" style="zoom:60%;" />

#### **分析**

```java
static final class Cell { // 对象头16字节
    volatile long value; // long 8字节
 }
```

因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 对象为 24 字节（16 字节的对象头和 8 字节的 long 类型的 value），缓存行一般存64字节，所以可以存下 2 个 Cell 对象（Cell[0]、Cell[1]）。

这样问题来了，假设：

- Core-0 要修改 Cell[0]
- Core-1 要修改 Cell[1]

1. 无论谁修改成功，都会导致对方 Core 的缓存行失效

    1. 比如 Core-0 中 Cell[0]=6000, Cell[1]=8000 只累加Cell[0]，累加后Core-0 中 Cell[0]=6001, Cell[1]=8000
    2. 虽然Core-0 中 Cell[1]=8000没累加，但是 Cell[0]、 Cell[1]是在同一个缓存行里，所以Core-1的缓存行需要整行失效，重新从头读取Cell[0]=6001，Cell[1]=8000，这就出现了伪共享问题，从而影响效率

2. @sun.misc.Contended 就是用来解决伪共享，它的原理是在使用此注解的对象或字段的前后各增加 128 字节大小的padding（空白，用来占位），从而让 CPU 将对象预读至缓存时，占用不同的缓存行（例如：让Cell[0]、Cell[1]占用不同的缓存行，占用Cell[0]变了不会影响Cell[1]），这样，不会造成对方缓存行的失效

伪共享（False Sharing）是指多个线程同时读写同一个缓存行的不同变量时，导致 CPU缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，引发性能下降。

### LongAdder 源码

#### add方法

```java
LongAdder adder = new LongAdder();
adder.increment();
long x: 累加值
Cell[] as: 累加单元数组cells的引用
long b: 获取的base值
long v: 期望值（当前cell存储的值）
int m: cells数组的长度
Cell a: 当前线程命中的cell单元格
boolean uncontended: 表示cell是否没有竞争
========================================================================
public class LongAdder extends Striped64 implements Serializable {

    public void increment() {
        add(1L);
    }

    public void add(long x) {
        Cell[] as; long b, v; int m; Cell a;
        // 进入 if 的两个条件
       // 条件1：as 有值, 表示已经发生过竞争, 进入 if
       // 条件2：cas 给 base 累加时失败了, 表示 base 发生了竞争, 进入 if
       // 由于 cells 是懒惰初始化，刚开始是null，会先进行casBase操作
        if ((as = cells) != null || !casBase(b = base, b + x)) {    
            boolean uncontended = true;
            /*
          条件1: cells为空，说明正在出现竞争，上面是从条件2过来的，说明!casBase(b = base, b + x))=true
               会通过调用longAccumulate(x, null, uncontended)新建一个数组，默认长度是2
          条件2: 默认会新建一个数组长度为2的数组，m = as.length - 1 < 0 应该不会出现
          条件3: 当前线程所在的cell为空，说明当前线程还没有更新过cell，uncontended为true，应初始化一个cell
          条件4: 更新当前线程所在的cell失败，说明竞争很激烈，多个线程hash到同一个Cell，uncontended为false，应扩容
          **/
            if (as == null || (m = as.length - 1) < 0 || (a = as[getProbe() & m]) == null || !(uncontended = a.cas(v = a.value, v + x)))
                longAccumulate(x, null, uncontended); // 创建cells数组的流程
        }
    }
}
```

**add 各种场景：**

1. cells = null，casBase(b = base, b + x)累加失败，执行 longAccumulate(x, null, uncontended);
2. cells != null，as[getProbe() & m] == null 表示当前线程还没创建cell，执行 longAccumulate(x, null, uncontended);
3. cells != null，如果as[getProbe() & m] != null 表示当前线程创建了cell，执行累加单元cell的cas操作：a.cas(v = a.value, v + x)，失败则执行 longAccumulate(x, null, uncontended);

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233815257.png" alt="image-20250613233815257" style="zoom:50%;" />

小结：

1. 最开始只更新base
2. 更新失败，则新创建一个Cell[]数组
3. 多个线程竞争到同一个Cell时，进行Cell[]数组扩容

#### 继承Striped64中的 longAccumulate方法

##### getProbe()方法获取线程hash值

```java
// Striped64中的longAccumulate方法
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    // 存储线程的hash值，有了hash值就可以知道当前线程进入哪个槽位
    int h;
    // 如果getProbe()方法返回0，说明随机数未初始化，需要初始化后，线程才能进入对应槽位
    if ((h = getProbe()) == 0) {
       // 使用ThreadLocalRandom为当前线程重新计算一个hash值，强制初始化
       ThreadLocalRandom.current(); 
       // 重新获取hash值
       h = getProbe();
       // 重新获取hash值后，认为此次不算是一次竞争，都未初始化，肯定还不存在竞争激烈，所以wasUncontended竞争状态为true
       wasUncontended = true;
}

// Striped64中的getProbe方法，得到当前线程的hash值PROBE
static final int getProbe() {
     return UNSAFE.getInt(Thread.currentThread(), PROBE);
}
```

##### longAccumulate方法总体逻辑

![image-20250613233837054](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233837054.png)

① 第一个线程创建cells 并初始化 一个累加单元cell

```java
long x: 累加值
LongBinaryOperator fn: 默认null
boolean wasUncontended: 是否没竞争，false表示有竞争；只有cells初始化之后，并且CAS累加值失败，才为false

long base: 类似于AtomicLong中全局的value值。在没有竞争情况下数据直接累加到base上，或者cells扩容时,也需要将数据写入到base上
boolean collide: 表示扩容意向，false一定不会扩容，true可能会扩容
cellsBusy: 初始化cells或者扩容cells需要获取锁，0表示无锁状态，1表示其他线程已经持有了锁
casCellsBusy: 通过CAS操作修改cellsBusy的值， CAS成功代表获取锁，返回true
NCPU: 当前计算机CPU数量，Cell数组扩容时会使用到
getProbe(): 获取当前线程的hash值
advanceProbe(): 重置当前线程的hash值

=================================================================================================

final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    int h;
    // 获取线程hash值，前面已经分析过，将代码隐藏
    if ((h = getProbe()) == 0) {...}
    boolean collide = false;             
    for (;;) {
        Cell[] as; Cell a; int n; long v;
        // 后面分析第一个if,先将代码隐藏
        if ((as = cells) != null && (n = as.length) > 0) {...}
            // 创建cells的场景
        else if (cellsBusy == 0 && cells == as && casCellsBusy()) {
            boolean init = false;
            try {                           // Initialize table
                if (cells == as) { // 再次检查cells引用是否改变，双重检测是为了避免并发场景下，重复创建cells
                    Cell[] rs = new Cell[2]; // 创建长度为2的cell数组
                    rs[h & 1] = new Cell(x); // 将累加值x随机存放到cell数组对应的索引下标位置
                    cells = rs; // 再将创建的cell数组引用赋值给cells
                    init = true;
                }
            } finally {
                cellsBusy = 0; // 创建完cell数组后，解锁
            }
            if (init)
                break; // 退出循环
        }
            // 尝试cas累加
        else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
            break;                          // Fall back on using base
    }
}
```

1. 进入for循环，先进入第一个else if，cellsBusy == 0 还未加锁，cells == as 表示cells是当前线程的引用，其他线程还未创建cells，casCellsBusy()方法通过cas尝试将cellsBusy改为1表示加锁，加锁成功，其他线程就不会来干扰cells的创建
2. casCellsBusy()方法通过cas尝试加锁失败后，进入第二个else if，casBase()方法尝试cas累加，成功则返回，失败则重新进入for循环

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233851198.png" alt="image-20250613233851198" style="zoom:50%;" />

② 在第一个线程基础上，第二个线程赋值给cell中的空槽位

```java
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    int h;
    if ((h = getProbe()) == 0) {...}
    boolean collide = false;         
    for (;;) {
        Cell[] as; Cell a; int n; long v;
        // 分析第一个if
        if ((as = cells) != null && (n = as.length) > 0) { // cells已经被创建
            if ((a = as[(n - 1) & h]) == null) {// cells虽然创建了，但是其中累加单元cell[0]或cell[1]还没被其他线程使用，则进入该if
                if (cellsBusy == 0) { // 其他线程没使用，自然也就没加锁  
                    Cell r = new Cell(x); // 创建累加单元，还没赋值到cells数组中 
                    // 该if是将创建的累加单元，设置到cells数组的空位置（cell[0]或cell[1]位置）
                    // 双重检测cellsBusy == 0，避免并发场景时重复赋值
                    if (cellsBusy == 0 && casCellsBusy()) {// 进入该if之前casCellsBusy()尝试加锁，保证赋值时是线程安全的
                        boolean created = false;
                        try {               // Recheck under lock
                            Cell[] rs; int m, j;
                            if ((rs = cells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {// 再次判断即将赋值的槽位不为空
                                rs[j] = r; // 赋值到空槽位
                                created = true;
                            }
                        } finally {
                            cellsBusy = 0; // 解锁
                        }
                        if (created)
                            break;  // 退出
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
                ......
        }
        else if (cellsBusy == 0 && cells == as && casCellsBusy()) {...}
        else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
            break;                          // Fall back on using base
    }
}
```

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233905427.png" alt="image-20250613233905427" style="zoom:50%;" />

③ 线程获取到了已经有值的累加单元cell，并在该cell上尝试进行累加

```java
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    int h;
    if ((h = getProbe()) == 0) {...}
    boolean collide = false;           
    for (;;) {
        Cell[] as; Cell a; int n; long v;
        if ((as = cells) != null && (n = as.length) > 0) {
            // 已经分析过
            if ((a = as[(n - 1) & h]) == null) {...}
            else if (!wasUncontended)       // wasUncontended为false说明在同一个槽位竞争失败
                wasUncontended = true;      // 跳到下面h = advanceProbe(h)位置，重新hash换一个槽位累加

                // 尝试对已经有值的累加单元cell进行累加，成功则退出
            else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
                break;

                // 累加失败，判断是否超过CPU上限  
            else if (n >= NCPU || cells != as)
                // 这个设计很巧妙
                // 超过CPU上限后，设置collide = false，为了让下次循环进入 else if (!collide)而不是进入下面的else if (cellsBusy == 0 && casCellsBusy())，防止进行扩容
                // 跳到下面h = advanceProbe(h)位置，重新hash换一个槽位累加
                collide = false;       
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 && casCellsBusy()) {// 其他线程没加锁，当前线程进入时再自己加锁
                try {
                    // 对cells进行扩容
                    if (cells == as) {      // Expand table unless stale
                        Cell[] rs = new Cell[n << 1]; // 每次扩容2倍，创建更多空槽位的累加单元
                        for (int i = 0; i < n; ++i)
                        rs[i] = as[i]; // 将旧数组拷贝到新数组
                        cells = rs;
                    }
                } finally {
                    cellsBusy = 0; // 解锁
                }
                collide = false;
                continue;  // 重新找槽位                 // Retry with expanded table
            }
            // 执行到这一步说明，前面的步骤都没成功，需要尝试换一个累加单元进行累加
            h = advanceProbe(h);
        }
        else if (cellsBusy == 0 && cells == as && casCellsBusy()) {...}
        else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
            break;                          // Fall back on using base
    }
}
```

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233919930.png" alt="image-20250613233919930" style="zoom:50%;" />

##### 小结：longAccumulate方法流程图

![image-20250613233931851](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233931851.png)

#### sum 方法

- 返回当前总和，返回的值不是原子快照；
- 在没有并发更新的情况下调用会返回准确的结果，但在计算总和时发生的并发更新可能不会被合并。

```java
public long sum() {
    Cell[] as = cells; Cell a;
    long sum = base;
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}
```

### **高并发下sum的值不精确的原因**

**sum执行时，并没有限制对base和cells的更新。所以LongAdder不是强一致性，而是最终一致性**

- 首先，最终返回的sum局部变量，初始被赋值为base，在最终返回时，可能有其他线程再次更新base，而此时局部变量sum不会更新，造成不一致
- 其次，这里对cell的读取也无法保证是最后一次写入的值

### LongAdder 总结

#### 采用分段CAS降低重试频率（这种分段的做法类似于JDK7中ConcurrentHashMap的分段锁）

- 高并发环境下，value变量其实是一个热点数据，也就是N个线程竞争一个热点。
- LongAdder的基本思路就是分散热点，将value值的新增操作分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个value值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。
- LongAdder有一个全局变量volatile long base值，当并发不高的情况下都是通过CAS来直接操作base值，如果CAS失败，则针对LongAdder中的Cell[]数组中的Cell进行CAS操作，减少失败的概率。
- 统计累加数据：sum() = base + Cell[]中的各Cell对象的value值之和。
- 而AtomicLong是多个线程针对单个热点value值进行原子操作。

#### 惰性求值

- LongAdder只有在使用longValue()获取当前累加值时才会真正的去结算计数的数据，longValue()方法底层就是调用sum()方法，对base和Cell数组的数据累加然后返回，做到数据写入和读取分离。
- 而AtomicLong使用incrementAndGet()每次都会返回long类型的计数值，每次递增后还会伴随着数据返回，增加了额外的开销。

#### AtomicLong VS LongAdder

AtomicLong：

- AtomicLong实现原理是基于CAS+自旋操作，CAS是基于硬件来实现原子性，保障线程安全。
- AtomicLong使用场景：低并发下的全局计数器、序列号生成器。
- AtomicLong优势：占用空间小；缺点：高并发下性能急剧下降（N个线程同时进行自旋，N-1个线程会自旋失败、不断重试）。

LongAdder：

- LongAdder设计思想：空间换时间，分散value值的热点数据；实现原理：高并发时采用Cell数组进行分段CAS。
- LongAdder使用场景：高并发下的全局计数器。
- LongAdder优势：能减少CAS重试次数、能防止伪共享、惰性求值；缺点：使用sum统计时如果有并发更新，可能导致统计的数据有误差。

![image-20250613233947075](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233947075.png)

## threadlocal

### 作用

- 提供线程 `局部变量`，每个线程 `Thread` 拥有一份自己的 `副本变量`，多个线程互不干扰

### 使用场景

- 上下文 context 传递

  - 一个对象需要在多个方法中层次传递使用，比如用户身份、任务信息、调用链 ID、关联 ID(如日志的 uniqueID，方便串起多个日志)等，如果此时使用责任链模式给每个方法添加一个 context 参数会比较麻烦，而此时就可以使用 ThreadLocal 设置参数，需要使用时 get 一下即可。
- 线程间数据隔离

  - spring 事务通过 threadlocal 保证单个线程中的数据库操作使用的是同一个 `Connection` 链接

### 底层结构

![image-20250613234000563](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234000563.png)

- `Thread` 中有 `threadLocals` 对象

  - ThreadLocal.ThreadLocalMap，即 ThreadLocalMap 是 ThreadLocal 的静态内部类
- 也就是说每一个 `线程` 中都有一个 `ThreadLocalMap`（Map）对象，操作自己的 map 肯定线程安全

#### ThreadLocalMap 的底层结构

```java
static class ThreadLocalMap {

    private Entry[] table;
    
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
}
```

ThreadLocalMap 的数据结构其实是很像 HashMap，但是也有一些差异：

- 它并未实现 Map 接口，而且他的 Entry 是继承 WeakReference（弱引用）的。
- 没有像 HashMap 有 next 指针，所以 ThreadLocalMap 不存在链表。

> - key -> threadLocal
>
>   - 弱引用
> - value -> 存储的值

下面看个例子：

```java
public class Test {

    public ThreadLocal<String> threadLocal1 = new ThreadLocal<>();
    public ThreadLocal<Map<String, Integer>> threadLocal2 = new ThreadLocal<>();

    public void test() {
        threadLocal1.set("1");
        Map<String, Integer> hashMap = new HashMap<>();
        hashMap.put("test", 2);
        threadLocal2.set(hashMap);
    }
}
```

**最终 Thread 中的 threadLocals 对象为：**

![image-20250613234017660](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234017660.png)

一个线程可以有**多个** `ThreadLocal` 来存放不同类型的对象，所以需要数组来存。

#### **为什么要设计为弱引用**

我们在上文分析过，`ThreadLocal` 是和线程挂钩的，当一个线程的任务运行完毕后，`ThreadLocal` 的值就再也用不上了，因为它只服务于这个线程里面的任务，任务都运行完了，那么 `ThreadLocal` 的存在就没有用了。正是考虑到这个问题，所以 JVM 希望在一个任务运行完毕后，`ThreadLocal` 能够自己清理掉一部分无用数据以节省内存！

那么，`ThreadLocal` 是如何自己清理这一部分无用数据的呢？我们分析一下 `set` 方法：

```java
private void set(ThreadLocal<?> key, Object value) {
    ....
    if (!cleanSomeSlots(i, sz) && sz >= threshold)
      //重新进行哈希运算  
      rehash();
}
```

`rehash` 中会调用 `resize` 方法，最终在 `resize` 方法中会做 `key` 的清理：

```java
    private void resize() {
      ....
        for (int j = 0; j < oldLen; ++j) {
            Entry e = oldTab[j];
            if (e != null) {
                ThreadLocal<?> k = e.get();
                //如果key为空
                if (k == null) {
                    //将value也设置为空 以方便value被jvm回收
                    e.value = null; // Help the GC
                } else {
                   ....
                }
            }
        }
      ....
    }
```

我们在调用 set/get/remove/rehash 任意一个方法，ThreadLocal 都会验证 key 是否为 null，如果确实是 key 为 null，则将 value 也设置为 null。这样 value 的强引用就被断开了，value 就会被 JVM 回收。

事实上，我们通过分析可以得知，**弱引用的设计恰恰就是为了帮我们解决内存泄漏的问题的**，弱引用的存在能够使得对象在使用完毕后自动将 key 变为 null，从而使得 ThreadLocal 能够发现这些 key 为 null 的数据然后清除的。

但是因为 ThreadLocalMap 是定义在 Thread 中的，而 Thread 又是**线程池**里面的线程，是一个不会停止的线程，所以导致 ThreadLocalMap 永远也不会释放。我们在使用 ThreadLocal 往里面 set 值的时候如果不调用 set/get/remove/rehash 任意一个方法，那么就会导致 ThreadLocalMap 中的 `null -> value` 即使已经完全没有作用，但是这辈子也不会被释放的问题！

> **注意**，即使我们不使用线程池也绕不开这个问题，你不主动使用线程池但是你所用的 Tomcat 里面用的有线程池呀，一个请求被分发到 controller 这个过程其实就对应着一个 Tomcat 线程池中的线程执行任务的过程！
>
> 所以，在使用过程中一定要注意：使用完毕后调用 remove 删除！使用完毕后调用 remove 删除！使用完毕后调用 remove 删除！重要的事情说三遍。

#### 没有了链表怎么解决 Hash 冲突的

![image-20250613234032730](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234032730.png)

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234047454.png" alt="image-20250613234047454" style="zoom:60%;" />

先根据 key(ThreadLocal 对象)计算出在数组中的 index 位置：

1. 如果 index 为空，直接新建一个 Entry 对象放 index 位置上
2. 如果 index 不为空，key(ThreadLocal)对象相等，直接更新 Entry 中 value 值
3. 如果 index 不为空，且 key(ThreadLocal)对象不相等（出现 hash 冲突了），那就找下一个空位置，直到为空为止。

### 原理

- 通过 threadlocal 获取 thread 对象
- 获取 thread 对象中的 threadlocal map 对象
- 操作自己的 map 对象

### 内存泄漏

分析一下以下代码的引用关系：

```java
public class Test {

    public ThreadLocal<Map<String, Integer>> threadLocal1 = new ThreadLocal<>();

    public void test() {
        Map<String, Integer> hashMap = new HashMap<>();
        hashMap.put("key1", 1);
        hashMap.put("key2", 2);
        hashMap.put("key3", 3);
        hashMap.put("key4", 4);
        threadLocal1.set(hashMap);
    }
}
```

- ![image-20250613234107534](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234107534.png)
- 代码运行时

  - Thread `强引用` ThreadLocalMap，`强引用` value(hashMap)
  - Thread `强引用` ThreadLocalMap，`弱引用` key(threadLocal1 对象)
  - Test 对象 `强引用` threadLocal1 对象
- 代码运行完

  - Test 对象被回收，失去对 threadLocal1 的引用
  - ThreadLocalMap 对 ThreadLocal 对象是弱引用，gc 时也会被回收
  - value 对象是被 ThreadLocalMap 引用，而 ThreadLocalMap 被 Thread 引用线程池复用，只要 Thread 不被销毁，则 value 对象一直无法被回收

![image-20250613234121516](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234121516.png)

##### 如何解决

`Thread` 对象被线程池控制，我们很难干预。所以我们关键解决思路是去掉 `ThreadLocalMap` 对 `value` 对象的引用。

**当 ThreadLocal(key）被垃圾回收后，ThreadLocalMap 的 key 变为了 null, 但 value 值依然存在：**

![image-20250613234135566](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234135566.png)

- 在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录
- 使用完 ThreadLocal 对象后 `手动remove`

##### ThreadLocalMap 设计的时候为什么不把 value 也设计成弱引用？

ThreadLocalMap 的 key 设计成了弱引用，而弱引用在垃圾回收的时候就会被回收掉，如果我写的程序运行时间较长，岂不是很危险。程序运行到一半，ThreadLocal 对象就被回收了？

**看看上面我分析过的代码：**

```java
public class Test {

    public ThreadLocal<Map<String, Integer>> threadLocal1 = new ThreadLocal<>();

    public void test() {
        Map<String, Integer> hashMap = new HashMap<>();
        hashMap.put("key1", 1);
        hashMap.put("key2", 2);
        hashMap.put("key3", 3);
        hashMap.put("key4", 4);
        threadLocal1.set(hashMap);
    }
}
```

**引用关系：**

![image-20250613234150135](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234150135.png)

**为什么不会有问题？**

虽然 ThreadLocalMap 对 key（ThreadLocal）是弱引用，但是业务代码 Test 对象对 key（ThreadLocal）对象**是强引用**。所以 ThreadLocal 不会被垃圾回收，直到业务代码 Test 对象运行完毕被垃圾回收，然后才会回收 ThreadLocal 对象。这也是 ThreadLocal 设计的精妙的地方。ThreadLocal 对象随业务代码回收而回收。

**那为何 Value 不设置成弱引用？**

因为不清楚这个 Value 除了 ThreadLocalMap 的引用还是否还存在其他引用，如果不存在其他引用，当 GC 的时候就会直接将这个 Value 干掉了，而此时我们的 ThreadLocal 还处于使用期间，就会造成 Value 为 null 的错误，所以将其设置为强引用。

## FastThreadLocal

### **数数 ThreadLocal 的缺点**

ThreadLocal 的一个缺点：hash 冲突用的是[线性探测法](https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E6%8E%A2%E6%B5%8B%E6%B3%95&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，效率低。

![image-20250613234203130](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234203130.png)

图上显示的是经过两个遍历找到了空位，假设冲突多了，需要遍历的次数就多了。并且下次 get 的时候，hash 直接命中的位置发现不是要找的 Entry ，于是就接着遍历向后找，所以说这个效率低。

而像 HashMap 是通过[链表法](https://www.zhihu.com/search?q=%E9%93%BE%E8%A1%A8%E6%B3%95&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)来解决冲突，并且为了防止链表过长遍历的开销变大，在一定条件之后又会转变成[红黑树](https://www.zhihu.com/search?q=%E7%BA%A2%E9%BB%91%E6%A0%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)来查找，这样的解决方案在频繁冲突的条件下，肯定是优于线性探测法，所以这是一个优化方向。

还有一个缺点是 ThreadLocal 使用了 WeakReference 以保证资源可以被释放，但是这可能会产生一些 Etnry 的 key 为 null，即无用的 Entry 存在。

所以调用 ThreadLocal 的 set 方法时，会主动清理无用的 Entry，减轻[内存泄漏](https://www.zhihu.com/search?q=%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)的发生。

### **应该如何针对 ThreadLocal 缺点改进**

前面提到 ThreadLocal hash 冲突的线性探测法不好，还有 Entry 的弱引用可能会发生内存泄漏，这些都和 ThreadLocalMap 有关，所以需要搞个新的 map 来替换 ThreadLocalMap。

而这个 ThreadLocalMap 又是 Thread 里面的一个[成员变量](https://www.zhihu.com/search?q=%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，这么一看 Thread 也得动一动，但是我们又无法修改 Thread 的代码，所以配套的还得弄个新的 Thread。

所以我们不仅得弄个新的 ThreadLocal、ThreadLocalMap 还得弄个配套的 Thread 来用上新的 ThreadLocalMap 。

所以如果想改进 ThreadLocal ，就需要动这三个类。

对应到 Netty 的实现就是 FastThreadLocal、InternalThreadLocalMap、FastThreadLocalThread

![image-20250613234215764](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234215764.png)

然后发散一下思维，既然 Hash 冲突的想线性探测效果不好，你可能比较容易想到的就是上面提到的链表法，然后再基于链表法说个改成红黑树，这个确实是一方面，但是可以再想想。

比如，让 Hash 不冲突，所以设计一个不会冲突的 hash 算法？不存在的！

所以怎么样才不会产生冲突呢？

各自取号入座

什么意思？就是每往 InternalThreadLocalMap 中塞入一个新的 FastThreadLocal 对象，就给这个对象发个唯一的下标，然后让这个对象记住这个下标，到时候去 InternalThreadLocalMap 找 value 的时候，直接通过下标去取对应的 value 。

这样不就不会冲突了？

这就是 FastThreadLocal 给出的方案，具体下面分析。

还有个内存泄漏的问题，这个其实只要规范的使用即用完后 remove 就好了，其实也没太好的解决方案，不过 FastThreadLocal 曲线救国了一下，这个也且看下面的分析！

### **FastThreadLocal 的原理**

![image-20250613234227725](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234227725.png)

可以看到有个叫 variablesToRemoveIndex 的类成员，并且用 final 修饰的，所以等于每个 FastThreadLocal 都有个共同的不可变 int 值。

然后看到这个 index 没，在 FastThreadLocal 构造的时候就被赋值了，且也被 final 修饰，所以也不可变，这个 index 就是我上面说的给每个新 FastThreadLocal 都发个唯一的下标，这样每个 index 就都知道自己的位置了。

上面两个 index 都是通过 `InternalThreadLocalMap.nextVariableIndex()` 赋值的，盲猜一下，这个肯定是用原子类递增实现的。

![image-20250613234240124](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234240124.png)

确实，在 InternalThreadLocalMap 也定义了一个[静态原子类](https://www.zhihu.com/search?q=%E9%9D%99%E6%80%81%E5%8E%9F%E5%AD%90%E7%B1%BB&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，每次调用 nextVariableIndex 就返回且递增，没有什么别的赋值操作，从这里也可以得知 variablesToRemoveIndex 的值为 0，因为它属于[常量赋值](https://www.zhihu.com/search?q=%E5%B8%B8%E9%87%8F%E8%B5%8B%E5%80%BC&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，第一次调用时 nextIndex 的值为 0 。

InternalThreadLocalMap 对标的就是之前的 ThreadLocalMap 也就是 ThreadLocal 缺点集中的类，需要重点看下。

我们再来回顾一下 ThreadLocalMap 的定义。

![image-20250613234252550](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234252550.png)

它是个 Entry 数组，然后 Entry 里面弱引用了 ThreadLocal 作为 Key。

而 InternalThreadLocalMap 有点不太一样：

![image-20250613234303899](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234303899.png)

可以看到， InternalThreadLocalMap 好像放弃了 map 的形式，没用定义 key 和 value，而是一个 Object 数组？

那它是如何通过 Object 来存储  FastThreadLocal 和对应的 value 的呢？我们从 `FastThreadLocal#set` 开始分析：

![image-20250613234321544](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234321544.png)

因为我们已经熟悉 ThreadLocal 的套路，所以我们知道 InternalThreadLocalMap 肯定是 FastThreadLocalThread 里面的一个变量。

然后我们从对应的 FastThreadLocalThread 里面拿到了 map 之后，就要执行塞入操作即 `setKnownNotUnset`。

我们先看一下塞入操作里面的 `setIndexedVariable` 方法：

![image-20250613234334584](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234334584.png)

可以看到，根据传入构造 FastThreadLocal 生成的唯一 index 可以直接从 Object 数组里面找到下标并且进行替换，这样一来压根就不会产生冲突，逻辑很简单，完美。

那如果塞入的 value 不是 UNSET(默认值)，则执行 `addToVariablesToRemove` 方法，这个方法又有什么用呢？

![image-20250613234346264](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234346264.png)

是不是看着有点奇怪？这是啥操作？别急，看我画个图来解释解释：

、![image-20250613234357876](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234357876.png)

这就是 Object 数组的核心关系图了，第一个位置放了一个 set ，set 里面存储了所有使用的 FastThreadLocal 对象，然后数组后面的位置都放 value。

那为什么要放一个 set 保存所有使用的 FastThreadLocal 对象？

用于删除，你想想看，假设现在要清空线程里面的所有 FastThreadLocal ，那必然得有一个地方来存放这些 FastThreadLocal 对象，这样才能找到这些家伙，然后干掉。

所以刚好就把数组的第一个位置腾出来放一个 set 来保存这些 FastThreadLocal 对象，如果要删除全部 FastThreadLocal 对象的时候，只需要遍历这个 set ，得到 FastThreadLocal 的 index 找到数组对应的 位置将 value 置空，然后把 FastThreadLocal 从 set 中移除即可。

刚好 FastThreadLocal 里面实现了这个方法，我们来看下：

![image-20250613234414028](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234414028.png)

我们做下小结，理一理上面说的：

首先 InternalThreadLocalMap 没有采用 ThreadLocalMap k-v形式的存储方式，而是用 Object 数组来存储 FastThreadLocal 对象和其 value，具体是在第一个位置存放了一个包含所使用的 FastThreadLocal 对象的 set，然后后面存储所有的 value。

之所以需要个 set 是为了存储所有使用的 FastThreadLocal 对象，这样就能找到这些对象，便于后面的删除工作。

之所以数组其他位置可以直接存储 value ，是因为每个 FastThreadLocal 构造的时候已经被分配了一个唯一的下标，这个下标对应的就是 value 所处的下标。

看到这里，不知道大家是否有感受到空间的浪费？

我举个例子。

假设系统里面一个 new 了 100 个 FastThreadLocal ，那第 100 个 FastThreadLocal 的下标就是 100 ，这个应该没有疑义。

从上面的 set 方法可以得知，只有调用 set 的时候，才会从当前线程中拿出 InternalThreadLocalMap ，然后往这个 map 的数组里面塞入 value，这里我们再回顾一下 set 的方法。

![image-20250613234426753](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234426753.png)

那这里是什么意思呢？

如果我这个线程之前都没塞过 FastThreadLocal ，此时要塞入第一个 FastThreadLocal ，构造出来的[数组长度](https://www.zhihu.com/search?q=%E6%95%B0%E7%BB%84%E9%95%BF%E5%BA%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)是32，但是这个 FastThreadLocal 的下标已经涨到了 100 了，所以这个线程第一次塞值，也仅仅只有这么一个值，数组就需要扩容。

看到没，这就是我所说的浪费，空间被浪费了。

Netty 相关实现者知道这样会浪费空间，所以数组的扩容是基于 index 而不是原先数组的大小，你看看如果是基于原先数组的扩容，那么第一次扩容 2 倍，32 变成 64，还是塞不下下标 100 的数据，所以还得扩容一次，这就不美了。

所以可以看到扩容传进去的参数是 index 。

![image-20250613234437845](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234437845.png)

可以看到，直接基于 index 的向上 2 次幂取整。然后就是扩容的拷贝，这里是直接进行数组拷贝，不需要进行 rehash，而 ThreadLocalMap 的扩容需要进行rehash，也就是重新基于 key 的 hash 值进行位置的分配，所以这个也是 FastThreadLocal 优于ThreadLocal 的一个点。

对了，上面那个向上 2 [次幂取整](https://www.zhihu.com/search?q=%E6%AC%A1%E5%B9%82%E5%8F%96%E6%95%B4&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)的操作，不知道你们熟悉不熟悉，这个和 HashMap 的实现是一致的。

![image-20250613234451501](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234451501.png)

所以从上面的实现可以得知 Netty 就是特意这样设计的，用多余的空间去换取不会冲突的 set 和 get ，这样写入和获取的速度就更快了，这就是典型的空间换时间。

好了，想必此时你已经弄懂了 FastThreadLocal 的核心原理了，我们再来看看 get 方法的实现，我想你应该能脑补这个实现了。

![image-20250613234520109](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234520109.png)

吧，没啥难度，index 就是 FastThreadLocal 构造时候预先分配好的那个下标，然后直接进行一个数组下标查找，如果没找到就调用 init 方法进行初始化。

我们这里再继续探究一下`InternalThreadLocalMap.get()`，这里面做了一个兼容。不过我要先介绍一下 FastThreadLocalThread ，就是这玩意替代了  Thread。

![image-20250613234532404](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234532404.png)

可以看到它继承了 Thread ，并且弄了一个成员变量就是我们前面说的 InternalThreadLocalMap。

然后我们再来看一下 get 方法，我截了好几个，不过逻辑很简单。

![image-20250613234542611](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234542611.png)

这里之所以分了 fastGet 和 slowGet 是为了做一个兼容，假设有个不熟悉的人，他用了 FastThreadLocal 但是没有配套使用 FastThreadLocalThread ，然后调用 FastThreadLocal#get 的时候去 Thread 里面找 InternalThreadLocalMap 那不就傻了吗，会报错的。

所以就再弄了个 slowThreadLocalMap ，它是个 ThreadLocal ，里面保存 InternalThreadLocalMap 来兼容一下这个情况。

从这里我们也能得知，FastThreadLocal 最好和 FastThreadLocalThread 配套使用，不然就隔了一层了。

```java
FastThreadLocal<String> threadLocal = new FastThreadLocal<String>();
Thread t = new FastThreadLocalThread(new Runnable() { //记得要 new FastThreadLocalThread
     public void run() {
      threadLocal.get()；
      ....
     }
 });
```

好了，get 和 set 这两个核心操作都分析完了，我们最后再来看一下 remove 操作吧。

![image-20250613234612985](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234612985.png)

很简单对吧，把数组里的 value 给覆盖了，然后再到  set  里把对应的 FastThreadLocal 对象给删了。

不过看到这里，可能有人会发出疑惑，内存泄漏相关的点呢？

其实吧，可以看到 FastThreadLocal 就没用弱引用，所以它把无用 FastThreadLocal 的清理就寄托到规范使用上，即没用了就主动调用 remove 方法。

但是它曲线救国了一下，我们来看一下 FastThreadLocalRunnable 这个类：

![image-20250613234627396](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234627396.png)

我已经把重点画出来了，可以看到这个 Runnable 执行完毕之后，会主动调用 FastThreadLocal.removeAll() 来清理所有的 FastThreadLocal，这就是我说的曲线救国，怕你完了调用 remove ，没事我帮你封装一下，就是这么贴心。

当然，这个前提是你不能用 Runnable 而是用 FastThreadLocalRunnable。不过这里 Netty 也是做了封装的。

Netty 实现了一个 DefaultThreadFactory 工厂类来创建线程。

![image-20250613234639716](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234639716.png)

你看，你传入 Runnable 是吧，没事，我把它包成 FastThreadLocalRunnable，并且我 new 回去的线程是 FastThreadLocalThread 类型，这样就能在很大程度上避免使用的错误，也减少了使用的难度。

这也是工厂方法这个[设计模式](https://www.zhihu.com/search?q=%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)的好处之一啦。所以工程上如果怕对方没用对，我们就封装了再给别人使用，这样也屏蔽了一些细节，他好你也好。

### **FastThreadLocal VS ThreadLocal**

到此，我们已经充分了解了两者之间的不同，但是 Fast 到底有多 Fast 呢？

我们用实验说话，Netty 源码里面已经有 benchmark 了，我们直接跑就行了

里面有两个实验：

FastPath 对应的是使用 FastThreadLocalThread 线程对象。

SlowPath 对应的是使用 Thread 线程对象。

![image-20250613234654117](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234654117.png)

两个实验都是分别定义了 ThreadLocal 和 FastThreadLocal ：

![image-20250613234706513](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234706513.png)

我们来看一下执行的结果：

FastPath:

![image-20250613234718107](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234718107.png)

SlowPath:

![image-20250613234728224](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234728224.png)

可以看到搭配 FastThreadLocalThread 来使用 FastThreadLocal 吞吐确实比使用 ThreadLocal 大。

### 总结

- FastThreadLocal 通过分配下标直接定位 value ，不会有 hash 冲突，效率较高。

  - ![image-20250613234738634](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234738634.png)

    可以看到有个叫 variablesToRemoveIndex 的类成员，并且用 final 修饰的，所以等于每个 FastThreadLocal 都有个共同的不可变 int 值。

    然后看到这个 index 没，在 FastThreadLocal 构造的时候就被赋值了，且也被 final 修饰，所以也不可变，这个 index 就是我上面说的给每个新 FastThreadLocal 都发个唯一的下标，这样每个 index 就都知道自己的位置了。
- FastThreadLocal 采用空间换时间的方式来提高效率。
- FastThreadLocal 需要配套 FastThreadLocalThread 使用，不然还不如原生 ThreadLocal。
- FastThreadLocal 使用最好配套 FastThreadLocalRunnable，这样执行完任务后会主动调用 removeAll 来移除所有 FastThreadLocal ，防止内存泄漏。
- FastThreadLocal 的使用也是推荐用完之后，主动调用 remove。

## AQS

### 设计思想

- AQS 的主要使用方式是 `继承`，子类通过继承同步器，并实现它的 `抽象方法` 来管理同步状态
- AQS 使用一个 `volatile`修饰的`int` 类型的成员变量 `state` 来**表示同步状态**：

  - 当 `state > 0` 时，表示已经获取了锁。
  - 当 `state = 0` 时，表示释放了锁。
- 资源共享方式

  - 独占 `Exclusive`（排它锁模式）
  - 共享 `Share`（共享锁模式）
- AQS 中的 `CLH `等待队列

  - 通过内部类 `Node` （线程封装体）构建 FIFO(先进先出)的 `双向链表`
  - 通过 Head、Tail 头尾两个节点来组成队列结构，通过 `volatile` 修饰保证可见性
  - `Head` 指向节点为已获得锁的节点，是一个 `虚拟节点`，节点本身不持有具体线程
  - 获取不到同步状态，会将节点进行 `自旋获取锁`，自旋一定次数失败后会将线程 `阻塞`，相对于 CLH 队列性能较好

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234755042.png" alt="image-20250613234755042" style="zoom:60%;" />

- Condition 队列（可能存在多个）

  - 使用内部类 ConditionObject 用来构建等待队列
  - 当 Condition 调用 await()方法后加入的队列

![image-20250613234822749](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234822749.png)

- waitStatus 节点状态

  - 默认为 0，表示初始状态。
  - `Node.CANCELLED(1)`：表示当前结点已取消调度。当 tmeout 或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。
  - `Node.SIGNAL(-1)`：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为 SIGNAL。
  - `Node.CONDITION-2)`：表示结点等待在 Condition 上，当其他线程调用了 Condition 的 signal() 方法后，CONDITION 状态的结点将从等待队列转移到同步队列中，等待获取同步锁。
  - `Node.PROPAGATE(-3)`：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。

### AQS 结构

首先我们看下 AQS 的 **继承关系图**，如下：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234838044.png" alt="image-20250613234838044" style="zoom:40%;" />

**AQS中相当重要的三个成员变量（头/尾节点+state）：**

```java
//头节点（独占锁模式下，持有资源的永远都是头节点！这个要知道哦）
private transient volatile Node head;
//尾节点
private transient volatile Node tail;
//锁资源（无锁状态是0，每次加锁成功后，通过cas进行+1，在重入场景下，重入几次就是几）
private volatile int state;
```

**AQS中的两个内部类：****`ConditionObject`****和****`Node`** **：**

```java
static final class Node {
    //当前节点处于共享模式的标记
    static final Node SHARED = new Node();

    //当前节点处于独占模式的标记
    static final Node EXCLUSIVE = null;

    //线程被取消
    static final int CANCELLED =  1;
    //head持有锁线程释放资源后需唤醒后继节点
    static final int SIGNAL    = -1;
    //等待condition唤醒
    static final int CONDITION = -2;
    //工作于共享锁状态，需要向后传播，
    static final int PROPAGATE = -3;

    //等待状态，有1,0,-1,-2,-3五个值。分别对应上面的值
    volatile int waitStatus;

    //前驱节点
    volatile Node prev;

    //后继节点
    volatile Node next;

    //等待锁的线程
    volatile Thread thread;

    //等待条件的下一个节点，ConditonObject中用到
    Node nextWaiter;
}
```

**AQS留给子类的钩子方法（由子类来定义锁的释放和获取逻辑）：**

```java
// 尝试获取排他锁
protected boolean tryAcquire(int arg) {
    throw new UnsupportedOperationException();
}
//尝试释放排他锁
protected boolean tryRelease(int arg) {
    throw new UnsupportedOperationException();
}
//尝试获取共享锁
protected int tryAcquireShared(int arg) {
    throw new UnsupportedOperationException();
}
//尝试释放共享锁
protected boolean tryReleaseShared(int arg) {
    throw new UnsupportedOperationException();
}
//判定当前线程获得的资源是否是排他资源
protected boolean isHeldExclusively() {
    throw new UnsupportedOperationException();
}
```

### 排他锁（**ReentrantLock**）

```java
public static void main(String[] args) throws InterruptedException {
    ReentrantLock lock = new ReentrantLock(true); // 使用公平锁
    Runnable runnable = new Runnable() {
        @Override
        public void run() {
            lock.lock();
            log.info("我抢到锁了 哈哈我是 ：{}", Thread.currentThread().getName());
        }
    };
    Thread threadA = new Thread(runnable, "Thread A");
    Thread threadB = new Thread(runnable, "Thread B");

    threadA.start();
    Thread.sleep(5);
    threadB.start();
    log.info("线程A状态:{}", threadA.getState());
    log.info("线程B状态:{},线程A不释放 没办法 我只能死等了 ", threadB.getState());
}
```

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234907554.png" alt="image-20250613234907554" style="zoom:80%;" />

#### 加排他锁（公平锁方式）

##### **ReentrantLock.lock()**

我们**使用ReentrantLock**的**lock方法** 进行`加锁`，其内部是这么调用的，先讲公平锁方式：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234922320.png" alt="image-20250613234922320" style="zoom:40%;" />

而`sync.acquire(1);`的调用其实就是AQS的这个acquire方法

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234944958.png" alt="image-20250613234944958" style="zoom:40%;" />

接下来我们就从 AQS的这个acquire方法 来分析加锁逻辑：

```java
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
```

1. **调用tryAcquire尝试获取锁state：** （实现在子类）来获取锁

    - 尝试获取资源 如果成功 直接返回

2. **调用addWaiter加入等待队列：** （这里指定Node为排他锁，因为acquire方法的模式就是排他）

    - 如果tail不是空则通过`CAS`添加当前node到队列尾部，如果是空则初始化等待队列,该方法返回当前Node(也即当前获取资源失败的Node对象)。

3. **调用acquireQueued：** (自旋阻塞等待获取资源，如果中断返回true)

    - for (;;) "死循环"，自旋，要么获取锁，要么中断
    - 找到当前节点的前驱节点，如果`是头节点`则**再次尝试**获取锁，成功的话将当前节点置为头节点并将老head节点置为null帮助GC回收
    - 如果前驱节点`不是头节点`，那就要通过 `shouldParkAfterFailedAcquire`来判断是否需要将当前节点对应的的线程 `park`（挂起） ，如需要挂起，则调用`LockSupport.park(this)`将当前线程挂起，并检测中断标志之后返回。

4. **调用selfInterrupt：** （中断）

    - 如果加锁失败且acquireQueued返回中断标识为true，则调用selfInterrupt进行真正的中断操作，至此加锁流程完毕。

*下边我们来一波源码，对上边几个方法进行详细分析*

**以下是：****`ReentrantLock -> FairSync -> tryAcquire(int acquires)`** **方法的实现逻辑**

##### **1. tryAcquire**

```java
protected final boolean tryAcquire(int acquires) {
    //获取当前的线程
    final Thread current = Thread.currentThread();
    //获取当前的加锁状态 在ReentrantLock中，state=0的时候是没有加锁，state=1的时候是加锁状态
    int c = getState();
    if (c == 0) {
        // 没有人占用锁的时候，因为是公平锁，所以优先判断队列中是否存在排队的
        // 如果没有排队的，直接使用CAS进行加锁，将0 替换为 1，
        if (!hasQueuedPredecessors() &&
            compareAndSetState(0, acquires)) {
            // 将当前线程设置到exclusiveOwnerThread变量，表示这个线程持有锁
            setExclusiveOwnerThread(current);
            //返回加锁成功
            return true;
        }
    }
    //我们在前面讲过，ReentrantLock是可重入锁，当前面逻辑加锁失败，则判断是不是当前线程持有的锁，如果是当前线程持有锁，则符合可重入规则
    else if (current == getExclusiveOwnerThread()) {
        //将state 累加  由 1  变成 2
        int nextc = c + acquires;
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    //如果存在排队任务，或者CAS变换state的值失败，则证明当前不能加锁，直接返回false加锁失败
    return false;
}
```

- 首先进行加锁的时候，因为公平锁的原因，会先判断等待队列中是否存在任务。如果存在，就不能去加锁，需要去排队！如果没有排队的任务，那么就开始使用 CAS 进行加锁，此时可能会出现其他线程也在加锁，如果其他线程加锁成功，那么此时 CAS 就会返回 false。
- 假设上面的加锁条件全部满足，就能够加锁成功，它会将 state 变为 1，将当前线程设置到一个变量中去，并且为了保证重入锁的特性，将当前线程保存到变量中，表示这个线程持有这把锁。
- 如果上面的加锁条件不满足，不会第一时间就返回加锁失败，因为 ReentrantLock 是可重入锁，所以在加锁失败后，会判断当前持有锁的线程和所需要加锁的线程是不是一个，如果是一个就附和可重入锁的特性，那么就把加锁数量 +1，同时返回加锁成功。
- 如果全部都不满足，则直接返回 false，加锁失败。

我们使用一个图来理解这个流程：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235015347.png" alt="image-20250613235015347" style="zoom:70%;" />

可以看到，其实所谓的加锁其实就是操作 State 变量的值！

##### **2. addWaiter**

线程加锁失败后，会开始进行入队操作，也就是 **addWaiter** 方法。AQS 的队列与传统队列不同，AQS 的队列是一个双向链表，排队的线程都是用 next 指向下一个节点任务。

```java
private Node addWaiter(Node mode) {
    //创建一个node节点 排它锁的mode = null
    Node node = new Node(Thread.currentThread(), mode);
    // 获取当前的尾节点
    Node pred = tail;
    if (pred != null) {
        //将当前节点的上一个节点设置为尾节点
        node.prev = pred;
        // cas替换 将当前节点设置为tail节点
        if (compareAndSetTail(pred, node)) {
            //将当前的尾节点的下一节点设为当前追加的节点
            pred.next = node;
            return node;
        }
    }
    //针对第一个任务初始化head节点操作
    enq(node);
    return node;
}
```

上述代码的操作就是一个任务追加的全过程，当一个任务想要追加的时候，需要先获取当前队列中的 tail 节点，然后将当前需要追加的节点的上一节点指针设置为 tail 节点，将 tail 节点的下一节点指针设置为当前节点，然后将当前追加的节点设置为 tail 节点，至此完成双向链表的追加操作。

至于空 head 节点的初始化，这里需要介绍一下，不然后续实现中你不知道 head 哪里来的。我们需要关注 addWaiter 方法中的 `enq(node);`，因为第一次节点入队，因为 tail 为 null ，实际的入队操作是由 enq 方法来做的。

```java
  private Node enq(final Node node) {
      for (;;) {
          //获取尾节点
          Node t = tail;
          //当尾节点为空（第一次设置）
          //第一次的话，因为还没有追加过节点，所以tail肯定为空
          if (t == null) {
              //使用cas创建一个线程数据为空的node，放到head中
              if (compareAndSetHead(new Node()))
                  //因为此时只有一个节点，所以这个空节点即是头也是尾
                  tail = head;
          } else {
              //后续就和addWaiter方法一样了，主要是吧当前节点追加到这个空的head节点后面。
              node.prev = t;
              if (compareAndSetTail(t, node)) {
                  t.next = node;
                  return t;
              }
          }
      }
  }
```

当第一个等待线程进入到队列的时候，实际的入队操作是由 enq 方法来做的，enq 方法初始化了 head 节点 、tail 节点，并将当前节点追加到 tail 节点后面。

##### **3. acquireQueued**

当入队操作完成之后，我们就要将当前线程挂起了，具体就是在 **acquireQueued** 中来做的。

```java
  final boolean acquireQueued(final Node node, int arg) {
      boolean failed = true;
      try {
          boolean interrupted = false;
          for (;;) {
              // 获取当前节点的前置节点
              final Node p = node.predecessor();
              // 如果当前节点的前置节点是head节点的时候，当前节点就排在第一个，所以这里会去尝试获取一次锁，万一锁被释放了，
              // 这里直接就获取到了，不需要调用系统级的阻塞。
              if (p == head && tryAcquire(arg)) {
                  //如果获取到了锁，则将当前的节点设置为头节点
                  setHead(node);
                  //将原先的头节点的后置节点设置为null ，为了jvm gc考虑的，保证原先的头节点能够被及时回收
                  p.next = null;
                  failed = false;
                  return interrupted;
              }
              // 如果没有拿到锁，则开始检查并更新获取失败节点的状态。如果线程阻塞，返回true
              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())
                  //检查是否被中断，如果被中断则返回true， 由selfInterrupt()方法进行当前线程的中断操作
                  interrupted = true;
          }
      } finally {
          if (failed)
              cancelAcquire(node);
      }
  }
```

它的功能很简单，主要就是如果自己排在 head 节点之后，就尝试获取下锁做一次二次检查，检查上一个节点是否已经释放了锁，万一不需要阻塞就可以直接获取到锁，就可以节省一部分性能。

我们需要再来分析一下 `shouldParkAfterFailedAcquire` 和 `parkAndCheckInterrupt`，这样整个加锁的动作就被我们分析完了。

###### **`shouldParkAfterFailedAcquire`** **方法**

```java
  private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
      //获取前置节点状态
      int ws = pred.waitStatus;
      //当前置节点状态为等待信号唤醒的时候
      if (ws == Node.SIGNAL)
          //直接放心大胆的阻塞，因为明显前置节点还在执行任务或者阻塞的状态
          return true;
      if (ws > 0) {
          do { 
              //开始遍历整条链路，将取消的任务全部剔除掉，保证队列的连续性
              node.prev = pred = pred.prev;
          } while (pred.waitStatus > 0);
          pred.next = node;
      } else {
          //初始化前面的节点为 Node.SIGNAL 等待唤醒的状态
          compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
      }
      return false;
  }
```

这里针对节点状态（waitStatus）做出一个说明。

> - 默认为 0，表示初始状态。
> - `Node.CANCELLED(1)`：表示当前结点已取消调度。当 tmeout 或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。
> - `Node.SIGNAL(-1)`：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为 SIGNAL。
> - `Node.CONDITION-2)`：表示结点等待在 Condition 上，当其他线程调用了 Condition 的 signal() 方法后，CONDITION 状态的结点将从等待队列转移到同步队列中，等待获取同步锁。
> - `Node.PROPAGATE(-3)`：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。

了解了这些状态之后，**shouldParkAfterFailedAcquire** 方法总共做了三件事。

- 当发现前置节点是等待信号的状态的时候，证明前置节点还在执行任务或者阻塞的状态，此时可以放心返回，让程序阻塞，因为自己无论如何也执行不了。
- 当前置节点的状态大于 0 的时候，也就是 `Node.CANCELLED` 的时候，证明前置节点被取消等待锁了，此时开始遍历整条双向列表，重置链路状态，将已经取消的全部删除掉。
- 当前置节点状态为 0 的时候，初始化前置节点的状态为等待唤醒的状态（`Node.SIGNAL`）。

###### **`parkAndCheckInterrupt`** **方法**

当 **shouldParkAfterFailedAcquire** 方法返回 true 的时候，证明此时加锁条件不满足，可以阻塞了。于是，开始调用系统内核进行阻塞：

```java
  private final boolean parkAndCheckInterrupt() {
      LockSupport.park(this);
      return Thread.interrupted();
  }
```

逻辑十分简单，`LockSupport.park(this);` 的源码不做具体分析，已经涉及到了操作系统，该方法的具体作用如下：

- **阻塞当前线程：**  调用 `park` 方法将导致当前线程进入等待状态，暂停执行。线程会在这里等待，直到被显式地唤醒。
- **与对象关联：**  `park` 方法可以关联一个对象。在这里，`this` 参数表示将当前线程与当前对象关联起来。这意味着，如果其他线程调用 `LockSupport.unpark(this)` 方法并传入相同的对象，那么被关联的线程将被唤醒。
- **与 unpark 搭配使用：**  `LockSupport` 类还提供了 `unpark` 方法，可以用于显式地唤醒被 `park` 阻塞的线程。通过关联对象，可以选择性地唤醒具体的线程。

`LockSupport.park(this)` 是用于阻塞当前线程的方法，它通常与 `LockSupport.unpark` 配合使用，实现线程之间的协同操作。这种方式相比于传统的 `wait` 和 `notify` 机制更加灵活，因为`LockSupport`可以直接与线程关联，而不用处于同一个对象监视器（对象监视器类似 `synchronized(o)` 里面那个 o，就是对象监视器的对象）。

> 总的来说，**acquireQueued 主要任务就是将等待的队列调用系统阻塞方法进行阻塞，等待唤醒。**

此时阻塞之后，for 循环被阻塞，等待解锁成功后，循环继续，就会重新进入到判断前置节点是否是 head 节点，如果是就尝试获取锁的逻辑中。

##### 加锁全过程图解

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235047727.png" alt="image-20250613235047727" style="zoom:50%;" />

#### 解排他锁

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235114215.png" alt="image-20250613235114215" style="zoom:40%;" />

##### release()

```java
//AbstractQueuedSynchronizer # release方法
public final boolean release(int arg) {
    if (tryRelease(arg)) { // 尝试释放锁，当为可重入锁的时候，不将锁全部释放为0 会返回false
        Node h = head; // 释放锁成功后 获取头节点
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h); // 唤醒head节点后的节点
        return true; // 返回释放锁成功
    }
    return false;
}
```

可以看到逻辑很清晰，即：如果`tryRelease`（释放锁）成功，并且头节点的waitStatus!=0，那么将调用`unparkSuccessor(head)`方法唤醒`头节点之后那个节点`。**注意：**  排他模式下，`唤醒操作` 只且只能发生在`头节点`与`后继节点`之间（因为 **排他模式下持有锁的节点只能是头节点head！** ）。

接下来我们就看下tryRelease方法，注意这个和tryAcquire()方法一样，都是AQS类留给子类实现的钩子方法，所以我们需要去 `ReentrantLock`的内部类`Sync`的`tryRelease`方法中一寻究竟。源码如下：

###### `tryRelease()`

```java
// 方法作用：释放锁（通过对state -1）
@ReservedStackAccess
protected final boolean tryRelease(int releases) {
    //获取到AQS的资源变量 state 并减一（注意 加锁和减锁的方法入参  永远是 1 ）
    int c = getState() - releases;
    //如果当前线程不是持有锁的线程（直接抛异常，你都没锁 你释放个嘚儿啊 哈哈）
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    //如果state=0了 则说明锁已经真正的释放了，则释放标志位true并且将占有线程置位null
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    //将释放锁之后的state（变量c）赋值给state
    setState(c);
    return free;
}
```

###### `unparkSuccessor()`

释放锁成功的话返回true且头节点不是空并且waitStatus!=0，则进入`unparkSuccessor`方法，开始唤醒`头节点的后继节点对应的线程`，看下源码：

```java
// 方法作用：唤醒头节点（head）的后继节点对应的线程
private void unparkSuccessor(Node node) {
    //获取当前线程的等待状态
    int ws = node.waitStatus;
    //如果node节点的等待状态是负数比如（SIGNAL状态），那尝试将waitStatus置为0
    if (ws < 0)
        node.compareAndSetWaitStatus(ws, 0);

    //获取当前节点的后继节点
    Node s = node.next;
    //如果当前节点的后继节点是null或者当前节点的后继节点是>0，(大于0只能是CANCELLED状态)，
    //那么将从尾节点tail开始，一直向前找距离当前节点最近的那个需要被唤醒的节点，并赋值给变量s
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node p = tail; p != node && p != null; p = p.prev)
            if (p.waitStatus <= 0)
                s = p;
    }
    //如果找到了当前节点的第一个需要被唤醒的后继节点，则唤醒他！
    if (s != null)
        //唤醒操作，唤醒当前节点后继节点对应的线程。
        LockSupport.unpark(s.thread);
}
```

##### 如何串联到加锁的阻塞

整个release方法概括就是，释放锁（state-1）并且唤醒头节点之后 waitStatus不是CANCELLED的那个后继节点，但是唤醒后就没了？不是吧，唤醒后，他需要去竞争锁呀！这时候，我们前边分析的那个加锁时候acquireQueued方法的自旋逻辑 就派上用场了，我们简单回顾下：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235149673.png" alt="image-20250613235149673" style="zoom:50%;" />

为了方便理解我们这里举个例子，假设在（独占锁且是公平锁模式下）

1. t1时刻，`线程a获取了锁资源`，线程b也尝试获取锁，但是被线程a占用，所以`线程b被搞到了等待队列`中（此时线程b的前驱节点就是头节点也即线程a），`线程b`会在acquireQueued的for(;;)中 **`不断自旋！`** 
2. 如果t2时刻，线程a释放了锁资源，在unparkSuccessor逻辑中将线程a的后继节点也即线程b`唤醒`
3. 紧接着t3时刻，线程b在自旋到`if(p==head && tryAcquire(arg))`这个条件时，不出意外将会获取到锁 (因为线程b的前驱节点确实是线程a对应的head节点，且在公平模式下tryAcquire不出意外会获取到锁)，那么将线程b设置为head节点，此时线程b占有锁（至此完成了一次线程a释放，线程b上位的锁获取逻辑）。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235208179.png" alt="image-20250613235208179" style="zoom:60%;" />

#### 公平锁与非公平锁

公平锁与非公平锁的唯一区别，公平锁调用 `hasQueuedPredecessors()`，而非公平锁没有调用 `hasQueuedPredecessors` 是公平锁加锁时判断等待队列中是否存在有效节点的方法

**导致公平锁和非公平锁的差异如下：**

- **公平锁**：公平锁讲究先来先到，线程在获取锁时，如果这个锁的等待队列中已经有线程在等待，那么当前线程就会进入等待队列中;

- **非公平锁**：不管是否有等待队列，如果可以获取锁，则立刻占有锁对象。也就是说队列的第一个排队线程在 unpark()，之后还是需要竞争锁（存在线程竞争的情况下)

##### 非公平锁的加锁

非公平锁的加锁逻辑在`java.util.concurrent.locks.ReentrantLock.NonfairSync#lock`。

```java
final void lock() {、
    //尝试使用CAS修改state的值，修改成功后就加锁成功
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        //开始加锁
        acquire(1);
}
```

非公平锁一进来就会直接尝试获取一次锁，不会进行太多的判断，这也符合非公平锁的定义，使用 CAS 修改如果成功了，就加锁成功，否则会执行 `acquire` 的加锁逻辑。

最后会走到 `nonfairTryAcquire` 的逻辑：

```java
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        //直接尝试CAS加锁
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    //可重入锁
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

在这里可以看到，它的加锁逻辑与公平锁很相似，但是与公平锁不同的是：

- **公平锁当发现 state =**  **0 也就是没有任务占有锁的情况下，会判断队列中是存在等待任务，如果存在就会加锁失败，然后执行入队操作。**
- **而非公平锁发现 state =**  **0 也就是没有任务占有锁的情况下，会直接进行 CAS 加锁，只要 CAS 加锁成功了，就会直接返回加锁成功而不会进行入队操作。**

#### 整体流程

我们简单举个例子，在排他锁模式下流程如下：

1. **假设t1时刻，有线程a持有资源state（****`持有资源的线程一定是在head节点这个我们一定要清楚`** **）**
2. **t1时刻，线程b试图调用获取锁的方法来获取锁资源，发现获取锁失败，则将线程b的相关数据封装为Node并插入CLH队列的队尾。**
3. **挂起线程b，并告知线程a(通过将head节点的waitStatus设置为SIGNAL)，资源释放了记得通知我啊！**
4. **t2时刻，线程a释放资源（并将对应Node赋值为null，利于GC）state后通知线程b**
5. **t3时刻 线程b 尝试获取锁（此时如果是公平锁则大概率可以获取成功，如果是非公平，则不一定）**

### 共享锁（`Semaphore`）

下边我们就以`Semaphore`为例，来切入AQS`共享锁`的`加锁`和`解锁`逻辑！

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235241588.png" alt="image-20250613235241588" style="zoom:40%;" />

Semaphore说白了就是：**令牌机制**，比如说有3个令牌，在某一时刻。最多只允许3个线程去执行被令牌保护的逻辑(没拿到的线程就等待)，每次执行完逻辑后，把令牌归还，好让其他线程去获取并执行（有点一夫当关万夫莫开的意思哈哈！）。

> **共享模式下的state说明：**  有个点我们要很清楚，共享模式下的资源state是提前申请的，在获取共享锁后是对AQS的 state -1，而不是排他锁那样获取锁后state+1

###### 加共享锁

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235306596.png" alt="image-20250613235306596" style="zoom:50%;" />

继续跟进发现AQS中的代码长如下这样：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235306596.png" style="zoom:50%;" />

如果 tryAcquireShared 返回大于等于0，代表获取共享锁成功，但不用立即唤醒后继节点，小于 0 则表示获取失败，如果获取共享资源失败即tryAcquireShared<0成立，就要进入等待队列了（即`doAcquireSharedInterruptibly`内部的逻辑）。

```java
public class Semaphore implements java.io.Serializable {
...

    abstract static class Sync extends AbstractQueuedSynchronizer {
    ...

    static final class NonfairSync extends Sync {
        private static final long serialVersionUID = -2694183684443567898L;

        NonfairSync(int permits) {
            super(permits); // 有几个令牌，初始化的时候就设几个
        }

        protected int tryAcquireShared(int acquires) {
            return nonfairTryAcquireShared(acquires);
        }
    }

    //此处真正实现了AQS的tryAcquireShared钩子方法。
    final int nonfairTryAcquireShared(int acquires) {
        for (;;) {
            //获取到AQS的资源 state
            int available = getState();
            //获取锁时，将可用值state减一（注意这里可不是排他锁时候的+1）
            int remaining = available - acquires;
            //如果剩余可用资源<0说明已经没有资源可用，直接返回负数，如果cas成功则说明还有资源可用，返回剩余资源数量remaining
            if (remaining < 0 ||
                compareAndSetState(available, remaining))
                return remaining;
        }
    }
}
```

当`if (tryAcquireShared(arg) < 0)`成立时（**此时也代表没有资源可用了，也即获取锁失败**）则会进入等待队列，具体细节在`doAcquireSharedInterruptibly`()方法中，我们看下源码：

```java
private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException {
    //和排他锁加锁 acquire()方法的逻辑差不多
    final Node node = addWaiter(Node.SHARED);
    try {
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r >= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                throw new InterruptedException();
        }
    } catch (Throwable t) {
        cancelAcquire(node);
        throw t;
    }
}
```

- 通过`addWaiter`方法（注意传入的锁模式是共享模式）添加当前线程对应`Node`（共享类型的Node）到等待队列,(addWaiter方法我们在排他锁说过了此处不过多啰嗦)
- 自旋，找当前节点的前驱节点，如果前驱是head则尝试再次获取共享锁，如果返回的值>0则说明获取锁成功（`有剩余可用资源`），调用`setHeadAndPropagate`方法，咦？这个方法好像第一次见，排他锁加锁没有见过，是啥玩意？一会说
- `shouldParkAfterFailedAcquire`这个方法是老朋友了，排他锁加锁分析中我们唠叨过，不再分析。

>  `doAcquireSharedInterruptibly()`方法实现上和排他锁的加锁方法`acquire()`方法差不多，就是多判断了是否还有剩余资源(`r其实就是state-1的值`)，通过`setHeadAndPropagate()`唤醒后继节点，为啥要唤醒后继节点？
>
> 排他锁模式下线程a抢锁成功后可没有唤醒后继节点的操作啊？那是因为：**既然一个线程刚获得了共享锁，那么很有可能还有剩余的共享锁，可供排队在后面的线程获得，所以需要唤醒后面的线程，让他们也来试试！**

![image-20250613235345776](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235345776.png)

###### 解共享锁

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235421398.png" alt="image-20250613235421398" style="zoom:40%;" />

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235446036.png" alt="image-20250613235446036" style="zoom:50%;" />

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235517723.png" alt="image-20250613235517723" style="zoom:50%;" />

`tryReleaseShared`源码如下（主要逻辑就是归还state，也即对state+1 并CAS赋值给AQS state）：

```java
protected final boolean tryReleaseShared(int releases) {
    for (;;) {
        int current = getState();
        int next = current + releases;
        if (next < current) // overflow
            throw new Error("Maximum permit count exceeded");
        if (compareAndSetState(current, next))
            return true;
    }
}
```

而对于`doReleaseShared`这个方法，我们上边再说共享锁加锁后，唤醒后继等待的那些共享节点时，已经分析过了，这里不在啰嗦重复。

可以看到最终解锁就是两个逻辑

1. `tryReleaseShared`：对state进行+1 ，即释放1个资源，让给其他等待的共享节点
2. `doReleaseShared`：唤醒当前节点的后继节点通过unpark操作

唤醒后的主动抢锁逻辑，就依靠共享锁加锁那里的自旋来实现了，即这个逻辑：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235547114.png" alt="image-20250613235547114" style="zoom:50%;" />

从而形成了一个 释放锁->唤醒后继节点->后继节点通过自旋抢锁的闭环操作（排他锁也是这个主逻辑，我们上边也说过）。

### ConditionObject的原理分析

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235611171.png" alt="image-20250613235611171" style="zoom:50%;" />

```
几个注意的点：
```

1. **在下文中：只要提到****`等待队列`** **，就是CLH队列，也就是存放 （****`获取锁失败后/或者被signal唤醒后从条件等待队列移到等待队列`** **）的node队列，而一提到****`条件等待队列`** **，就是在说（****`调用await后存放`** **）Node的队列！** ，这俩队列一定要搞清楚，否则就很迷了。
2. **条件等待队列可能存在多个**，而CLH等待队列只能是一个。这一点我们要清楚。多个条件等待队列也是ReentrantLock实现细粒度唤醒的一个基本原因。
3. **AQS中的await和signal 只能是排他锁使用**，共享锁绝对不会存在 等待/唤醒机制这么一说。
4. **条件等待队列** 中的线程，**想要获取锁**，**必然** 需要通过**signal方法**`移动到等待队列中去`，`才有机会`。
5. **条件等待队列** 和CLH一样也是FIFO，但是是单向链表结构这个要知道，另外signal唤醒的总是条件等待队列的头节点，**await后插入的Node总是从条件等待队列的尾部进行插入。**

由于jdk中基于ConditionObject实现的条件等待机制也就是ReentrantLock和读写锁，而ReentrantLock用的多一些。所以我们以ReentrantLock为例，做一个生产/消费的小案例，来切身体会一下也方便源码分析时的切入和debug。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235635481.png" alt="image-20250613235635481" style="zoom:40%;" />

**生产/消费 案例完整源码如下：**

```java
/**
 * @Auther: Huangzhuangzhuang
 * @Date: 2023/10/20 07:02
 * @Description:
 */
@Slf4j
public class AwaitSignalDemo {

   private static volatile int shoeCount = 0;
   private static ThreadPoolExecutor producerThread = new ThreadPoolExecutor(1, 1, 1000 * 60, TimeUnit.MILLISECONDS, SemaphoreTest.asyncSenderThreadPoolQueue = new LinkedBlockingQueue<Runnable>(500), new ThreadFactory() {
      private final AtomicInteger threadIndex = new AtomicInteger(0);
      @Override
      public Thread newThread(Runnable r) {
         return new Thread(r, "生产线程_" + this.threadIndex.incrementAndGet());
      }
   });
   private static ThreadPoolExecutor consumerThread = new ThreadPoolExecutor(1, 1, 1000 * 60, TimeUnit.MILLISECONDS, SemaphoreTest.asyncSenderThreadPoolQueue = new LinkedBlockingQueue<Runnable>(500), new ThreadFactory() {
      private final AtomicInteger threadIndex = new AtomicInteger(0);
      @Override
      public Thread newThread(Runnable r) {
         return new Thread(r, "消费线程_" + this.threadIndex.incrementAndGet());
      }
   });

   public static void main(String[] args) {
      Lock lock = new ReentrantLock();
      Condition producerCondition = lock.newCondition();
      Condition consumerCondition = lock.newCondition();
      //不停生产鞋，攒够5双了就唤醒消费线程
      producerThread.execute(() -> {
         while (true) {
            lock.lock(); // 获取锁资源
            try {
               if (shoeCount > 5) { //如果生产够5双， 则阻塞等待生产线程，待消费线程消费完后再生产
                  System.out.println(Thread.currentThread().getName() + "_生产鞋完成" + (shoeCount - 1) + "双");
                  consumerCondition.signal();//唤醒消费鞋子的线程
                  producerCondition.await();//挂起生产鞋的线程
               } else {
                  shoeCount++;//生产鞋子
               }
            } catch (Exception e) {
               e.printStackTrace();
            } finally {
               lock.unlock();//释放锁资源
            }
         }
      });
      //不停消费鞋，把鞋消费完了就唤醒生产线程然他继续造
      consumerThread.execute(() -> {
         while (true) {
            lock.lock();//获取锁资源
            try {
               if (shoeCount == 0) {//如果消费完了
                  System.out.println(Thread.currentThread().getName() + "_鞋子全部消费完了");
                  System.out.println();
                  producerCondition.signal(); //消费完鞋子之后，唤醒生产鞋子的线程
                  consumerCondition.await(); //挂起消费鞋子的线程，等待生产完后唤醒当前挂起线程
               } else {
                  shoeCount--;//消费鞋子
               }
            } catch (Exception e) {
               e.printStackTrace();
            } finally {
               lock.unlock();//释放锁资源
            }
         }
      });
   }
}
```

#### 等待(await)机制源码分析

ReentrantLock的等待机制最终是依赖AQS的ConditionObject类的await方法实现的，所以我们直接来到AQS#ConditionObject的await方法一探究竟，源码如下：

```java
public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    //将当前线程加入到 条件等待的链表最后，并返回该节点（内部会创建 Node.CONDITION=-2 类型的 Node）
    Node node = addConditionWaiter();
    //释放当前线程获取的锁（通过操作 state 的值,一直减到state==0）释放了锁就会被阻塞挂起,
    //fullyRelease内部就是调用的我们在AQS独占锁释放时候的tryRelease方法
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    //判断 node节点是否在 AQS 等待队列中（注意该方法中如果node是head的话是返回false的，也就是会执行park逻辑）
    while (!isOnSyncQueue(node)) {
        //如果是head或者当前节点在队列则挂起当前线程
        LockSupport.park(this);
        //如果上边挂起线程后，紧接着又有其他线程中断/唤醒了当前线程（这种情况理论可能比较少但是并发情况下也不一定😄），那么则跳出循环，
        //下边（循环外的）acquireQueued将 node移至AQS等待队列，让其继续抢锁
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    //acquireQueued将 node移至AQS等待队列，让其再次抢锁
    //注意此处是 ： 采用排他模式的资源竞争方法 acquireQueued
    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        //清除取消的线程
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}


//将当前线程包装成 CONDITION 节点，排入该 Condition 对象内的（条件等待队列）的队尾
private Node addConditionWaiter() {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node t = lastWaiter;
    //遍历 Condition 队列，踢出 Cancelled 节点
    if (t != null && t.waitStatus != Node.CONDITION) {
        unlinkCancelledWaiters();
        t = lastWaiter;
    }
    //将当前线程包装成 CONDITION 节点，排入该 Condition 对象内的条件等待队列的队尾
    Node node = new Node(Node.CONDITION);
    if (t == null)
        firstWaiter = node;
    else
        t.nextWaiter = node;
    lastWaiter = node;
    return node;
}
//检测是否有中断
private int checkInterruptWhileWaiting(Node node) {
    return Thread.interrupted() ?
        (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :
        0;
}

final boolean transferAfterCancelledWait(Node node) {
    //将node 状态由 CONDITION 设置为 0，如果设置成功，则说明当前线程抢占到了安排 node 进入 AQS 等待队列的权利，证明了 interrupt 操作先于 signal 操作
    if (node.compareAndSetWaitStatus(Node.CONDITION, 0)) {
        //加到等待队列
        enq(node);
        return true;
    }
    //如果 CAS 操作失败，说明其他线程调用 signal 先行处理了 node 节点。
    //当前线程没竞争到 node 节点的唤醒权，要在 node 节点进入 AQS 队列前一直自旋，同时要执行 yield 让出 CPU
    while (!isOnSyncQueue(node))
        Thread.yield();
    return false;
}
```

![image-20250613235712256](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235712256.png)

#### 唤醒(signal)机制源码分析与图解

```java
public final void signal() {
    //如果当前线程未持有资源state，则抛出异常
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        doSignal(first);
}

//唤醒
private void doSignal(Node first) {
    do {
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null;
    } while (!transferForSignal(first) &&
             (first = firstWaiter) != null);
}

//将node 节点从 条件等待队列转移到 等待队列中去
final boolean transferForSignal(Node node) {
    //尝试将节点状态由 CONDITION 改为 0
    if (!node.compareAndSetWaitStatus(Node.CONDITION, 0))
        return false;

    //end方法将 node 节点插入 AQS 等待队列 队尾，返回 node 节点的前驱节点
    Node p = enq(node);
    int ws = p.waitStatus;
    //如果当前node的前置节点状态为 CANCELLED（大于0只有取消一种），或者设置前置节点状态为 SIGNAL失败，则将 node 节点持有的线程唤醒
    if (ws > 0 || !p.compareAndSetWaitStatus(ws, Node.SIGNAL))
        LockSupport.unpark(node.thread);
    return true;
}
```

![image-20250613235807911](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235807911.png)

#### 总结

说完了 Condition 的使用和底层运行机制，我们再来总结下它跟普通 wait/notify 的比较，一般这也是问的比较多的，Condition 大概有以下两点优势：

- Condition 需要结合 Lock 进行控制，使用的时候要注意一定要对应的 unlock()，可以对多个不同条件进行控制，只要 new 多个 Condition 对象就可以为多个线程控制通信，wait/notify 只能和 synchronized 关键字一起使用，并且只能唤醒一个或者全部的等待队列；
- Condition 有类似于 await 的机制，因此不会产生加锁方式而产生的死锁出现，同时底层实现的是 park/unpark 的机制，因此也不会产生先唤醒再挂起的死锁，一句话就是不会产生死锁，但是 wait/notify 会产生先唤醒再挂起的死锁。

### ReentrantReadWriteLock

**ReentrantReadWriteLock 有五个内部类**，五个内部类之间也是相互关联的。内部类的关系如下图所示。

![image-20250613235831767](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235831767.png)

#### 内部类 - Sync类

```java
abstract static class Sync extends AbstractQueuedSynchronizer {
    // 版本序列号
    private static final long serialVersionUID = 6317671515068378041L;
    // 高16位为读锁，低16位为写锁
    static final int SHARED_SHIFT   = 16;
    // 读锁单位  2^16
    static final int SHARED_UNIT    = (1 << SHARED_SHIFT);
    // 读锁最大数量 2^16 - 1
    static final int MAX_COUNT      = (1 << SHARED_SHIFT) - 1;
    // 写锁最大数量 2^16 - 1
    static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;
    // 本地线程计数器
    private transient ThreadLocalHoldCounter readHolds;
    // 缓存的计数器
    private transient HoldCounter cachedHoldCounter;
    // 第一个读线程
    private transient Thread firstReader = null;
    // 第一个读线程的计数
    private transient int firstReaderHoldCount;
}
```

#### Lock类

WriteLock和ReadLock两个静态内部类。

```java
public static class ReadLock implements Lock, java.io.Serializable {
    public void lock() {
        sync.acquireShared(1); //共享
    }

    public void unlock() {
        sync.releaseShared(1); //共享
    }
}

public static class WriteLock implements Lock, java.io.Serializable {
    public void lock() {
        sync.acquire(1); //独占
    }

    public void unlock() {
        sync.release(1); //独占
    }
}

abstract static class Sync extends AbstractQueuedSynchronizer {}
```

这里发现了ReentrantReadWriteLock和ReentrantLock的一个相同点和不同点：

- 相同的是使用了同一个关键实现AbstractQueuedSynchronizer
- 不同的是ReentrantReadWriteLock使用了两个锁分别实现了AQS，而且WriteLock和ReentrantLock一样，使用了独占锁。而ReadLock和Semaphore一样，使用了共享锁。

#### ReadLock和WriteLock共享变量

是怎么做到读写分离的呢？来看看下面这段代码：

```java
static final int SHARED_SHIFT   = 16; // 高16位为读锁，低16位为写锁
static final int SHARED_UNIT    = (1 << SHARED_SHIFT); // 读锁单位  2^16
static final int MAX_COUNT      = (1 << SHARED_SHIFT) - 1; // 读锁最大数量 2^16 - 1
static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1; // 写锁最大数量 2^16 - 1

/** 共享锁的数量  */
static int sharedCount(int c)    { return c >>> SHARED_SHIFT; }
/** 独占锁的数量  */
static int exclusiveCount(int c) { return c & EXCLUSIVE_MASK; }
```

这段代码在Sync静态内部类中，这里有两个关键方法`sharedCount`和`exclusiveCount`，通过名字可以看出`sharedCount`是共享锁的数量，`exclusiveCount`是独占锁的数量。

共享锁通过对 c >>> 16位获得，独占锁通过和16位的1与运算获得。

> 举个例子，当获取读锁的线程有3个，写锁的线程有1个（当然这是不可能同时有的），state就表示为0000 0000 0000 0011 0000 0000 0000 0001，高16位代表读锁，通过向右位移16位（c >>> SHARED_SHIFT）得倒10进制的3，通过和0000 0000 0000 0000 1111 1111 1111 1111与运算（c & EXCLUSIVE_MASK），获得10进制的1。

由于16位最大全1表示为65535，所以读锁和写锁最多可以获取65535个。

#### WriteLock和ReentrantLock获取锁的区别

WriteLock也是独占锁，那么他和ReentrantLock有什么区别呢？

最大的区别就在获取锁时WriteLock不仅需要考虑是否有其他写锁占用，同时还要考虑是否有其他读锁，而ReentrantLock只需要考虑自身是否被占用就行了。

```java
public void lock() {
    sync.acquire(1);
}

public final void acquire(int arg) {
    if (!tryAcquire(arg) && //尝试获取独占锁
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //获取失败后排队
        selfInterrupt();
}

protected final boolean tryAcquire(int acquires) {

    Thread current = Thread.currentThread();
    int c = getState();  //获取共享变量state
    int w = exclusiveCount(c); //获取写锁数量
    if (c != 0) { //有读锁或者写锁
        // (Note: if c != 0 and w == 0 then shared count != 0)
        if (w == 0 || current != getExclusiveOwnerThread()) //写锁为0（证明有读锁），或者持有写锁的线程不为当前线程
            return false;
        if (w + exclusiveCount(acquires) > MAX_COUNT)
            throw new Error("Maximum lock count exceeded");
        // Reentrant acquire
        setState(c + acquires);  //当前线程持有写锁，为重入锁，+acquires即可
        return true;
    }
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires)) //CAS操作失败，多线程情况下被抢占，获取锁失败。CAS成功则获取锁成功
        return false;
    setExclusiveOwnerThread(current);
    return true;
}
```

这段代码是不是很熟悉？和ReentrantLock中获取锁的代码很相似，差别在于其中调用了`exclusiveCount`方法来获取是否存在写锁，然后通过`c != 0`和`w == 0`判断了是否存在读锁。

#### ReadLock和Semaphore获取锁的区别

```java
protected final int tryAcquireShared(int unused) {

    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &&
       getExclusiveOwnerThread() != current) //写锁不等于0的情况下，验证是否是当前写锁尝试获取读锁
       return -1;
    int r = sharedCount(c);  //获取读锁数量
    if (!readerShouldBlock() && //读锁不需要阻塞
       r < MAX_COUNT &&  //读锁小于最大读锁数量
       compareAndSetState(c, c + SHARED_UNIT)) { //CAS操作尝试设置获取读锁 也就是高位加1
       if (r == 0) {  //当前线程第一个并且第一次获取读锁，
          firstReader = current;
          firstReaderHoldCount = 1;
       } else if (firstReader == current) { //当前线程是第一次获取读锁的线程
          firstReaderHoldCount++;
       } else { // 当前线程不是第一个获取读锁的线程，放入线程本地变量
          HoldCounter rh = cachedHoldCounter;
          if (rh == null || rh.tid != getThreadId(current))
             cachedHoldCounter = rh = readHolds.get();
          else if (rh.count == 0)
             readHolds.set(rh);
          rh.count++;
       }
       return 1;
    }
    return fullTryAcquireShared(current);
}
```

在上面的代码中尝试获取读锁的过程和获取写锁的过程也很相似，不同在于读锁`只要没有写锁`占用并且`不超过最大获取数量`都可以尝试获取读锁，而写锁不仅需要考虑读锁是否占用，也要考虑写锁是否占用。

上面的代码中firstReader，firstReaderHoldCount以及cachedHoldCounter都是为readHolds（ThreadLocalHoldCounter）服务的，用来记录每个读锁获取线程的获取次数，方便获取当前线程持有锁的次数信息。在ThreadLocal基础上添加了一个Int变量来统计次数。

#### 锁降级

锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。

```
锁降级是指把持住(当前拥有的)写锁，再获取到读锁，随后释放(先前拥有的)写锁的过程。
// update变量使用volatile修饰
public void processData() {
    readLock.lock();
    if (!update) {
        // 必须先释放读锁
        readLock.unlock();
        // 锁降级从写锁获取到开始
        writeLock.lock();
        try {
            if (!update) {
                // 准备数据的流程(略)
                update = true;
            }
            readLock.lock();
        } finally {
            writeLock.unlock();
        }
        // 锁降级完成，写锁降级为读锁
    }
    try {
        // 使用数据的流程(略)
    } finally {
        readLock.unlock();
    }
}
```

上述示例中，当数据发生变更后，update变量(布尔类型且volatile修饰)被设置为false，此时所有访问 processData() 方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。

锁降级中读锁的获取是否必要呢? 答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程(记作线程T)获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。

```
RentrantReadWriteLock不支持锁升级(把持读锁、获取写锁，最后释放读锁的过程)。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。
```

## FutureTask

FutureTask 为 Future 提供了基础实现，如获取任务执行结果(get)和取消任务(cancel)等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消(除非使用runAndReset执行计算)。

FutureTask 常用来封装 Callable 和 Runnable，也可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，此类也提供了一些功能性函数供我们创建自定义 task 类使用。

FutureTask 的线程安全由CAS来保证。  

![image-20250613235927944](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235927944.png)

### 源码解析

#### Callable接口

对比Runnable接口，Runnable不会返回数据也不能抛出异常。

```java
public interface Callable<V> {
    /**
     * Computes a result, or throws an exception if unable to do so.
     *
     * @return computed result
     * @throws Exception if unable to compute a result
     */
    V call() throws Exception;
}
```

#### Future接口

Future接口代表异步计算的结果，通过Future接口提供的方法可以查看异步计算是否执行完成，或者等待执行结果并获取执行结果，同时还可以取消执行。

```java
public interface Future<V> {
    boolean cancel(boolean mayInterruptIfRunning);
    boolean isCancelled();
    boolean isDone();
    V get() throws InterruptedException, ExecutionException;
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}
```

#### 核心属性

```java
// 内部持有的callable任务，运行完毕后置空
private Callable<V> callable;

// 从get()中返回的结果或抛出的异常
private Object outcome; // non-volatile, protected by state reads/writes

// 运行 callable 的线程
private volatile Thread runner;

// 使用Treiber栈保存等待线程
private volatile WaitNode waiters;

//任务状态
private volatile int state;
private static final int NEW          = 0; // 表示是个新的任务或者还没被执行完的任务。这是初始状态。
private static final int COMPLETING   = 1; // 任务已经执行完成或者执行任务的时候发生异常
private static final int NORMAL       = 2; // 任务已经执行完成并且任务执行结果已经保存到outcome字段
private static final int EXCEPTIONAL  = 3; // 任务执行发生异常并且异常原因已经保存到outcome字段中后
private static final int CANCELLED    = 4; // 任务还没开始执行或者已经开始执行但是还没有执行完成时候
private static final int INTERRUPTING = 5; // 任务还没开始执行或者已经执行但是还没有执行完成的时候
private static final int INTERRUPTED  = 6; // 调用interrupt()中断任务执行线程之后
```

**其中需要注意的是state是volatile类型的，也就是说只要有任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值**。

各个状态之间的可能转换关系如下图所示:

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613235943024.png" alt="image-20250613235943024" style="zoom:80%;" />

#### 构造函数

```java
public FutureTask(Callable<V> callable) {
    if (callable == null)
        throw new NullPointerException();
    this.callable = callable;
    this.state = NEW;       // ensure visibility of callable
}

public FutureTask(Runnable runnable, V result) {
    this.callable = Executors.callable(runnable, result);
    this.state = NEW;       // ensure visibility of callable
}
```

#### 核心方法 - run()

```java
public void run() {
    //新建任务，CAS替换runner为当前线程
    if (state != NEW ||
        !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                     null, Thread.currentThread()))
        return;
    try {
        Callable<V> c = callable;
        if (c != null && state == NEW) {
            V result;
            boolean ran;
            try {
                result = c.call();
                ran = true;
            } catch (Throwable ex) {
                result = null;
                ran = false;
                setException(ex);
            }
            if (ran)
                set(result);//设置执行结果
        }
    } finally {
        // runner must be non-null until state is settled to
        // prevent concurrent calls to run()
        runner = null;
        // state must be re-read after nulling runner to prevent
        // leaked interrupts
        int s = state;
        if (s >= INTERRUPTING)
            handlePossibleCancellationInterrupt(s);//处理中断逻辑
    }
}
```

- 运行任务，如果任务状态为NEW状态，则利用CAS修改为当前线程。**执行完毕调用set(result)方法设置执行结果**。

  - set(result)源码如下：

```java
protected void set(V v) {
    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {
        outcome = v;
        UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state
        finishCompletion();//执行完毕，唤醒等待线程
    }
}
```

首先利用cas修改state状态为 COMPLETING，设置返回结果，然后使用 **lazySet(UNSAFE.putOrderedInt) 的方式** 设置state状态为NORMAL。结果设置完毕后，调用`finishCompletion()`方法唤醒等待线程

```java
private void finishCompletion() {
    // assert state > COMPLETING;
    for (WaitNode q; (q = waiters) != null;) {
        if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {//移除等待线程
            for (;;) {//自旋遍历等待线程
                Thread t = q.thread;
                if (t != null) {
                    q.thread = null;
                    LockSupport.unpark(t);//唤醒等待线程
                }
                WaitNode next = q.next;
                if (next == null)
                    break;
                q.next = null; // unlink to help gc
                q = next;
            }
            break;
        }
    }
    // 任务完成后调用函数，自定义扩展
    done();
    callable = null;        // to reduce footprint
}
```

- 回到run方法，如果在 run 期间被中断，此时需要调用 `handlePossibleCancellationInterrupt` 方法来处理中断逻辑，确保任何中断(例如cancel(true)) 只停留在当前run或 runAndReset 的任务中

```java
private void handlePossibleCancellationInterrupt(int s) {
    //在中断者中断线程之前可能会延迟，所以我们只需要让出CPU时间片自旋等待
    if (s == INTERRUPTING)
        while (state == INTERRUPTING)
            Thread.yield(); // wait out pending interrupt
}
```

#### 核心方法 - get()

```java
//获取执行结果
public V get() throws InterruptedException, ExecutionException {
    int s = state;
    if (s <= COMPLETING)
        s = awaitDone(false, 0L);
    return report(s);
}
```

FutureTask 通过 get() 方法获取任务执行结果。如果任务处于未完成的状态(`state <= COMPLETING`)，就调用 awaitDone方法等待任务完成。**任务完成后，通过report方法获取执行结果或抛出执行期间的异常**。

report源码如下：

```java
//返回执行结果或抛出异常
private V report(int s) throws ExecutionException {
    Object x = outcome;
    if (s == NORMAL)
        return (V)x;
    if (s >= CANCELLED)
        throw new CancellationException();
    throw new ExecutionException((Throwable)x);
}
```

- 如果状态是`NORMAL`，正常结束的话，则把`outcome`变量返回；
- 如果是取消或者中断状态的，则抛出取消异常；
- 如果是`EXCEPTION`，则把`outcome`当作异常抛出（之前`setException()`保存的类型就是`Throwable`）。从而整个`get()`会有一个异常抛出。

#### 核心方法 - awaitDone(boolean timed, long nanos)

```java
private int awaitDone (boolean timed, long nanos) throws InterruptedException {
    final long deadline = timed ? System.nanoTime() + nanos : 0L;
    WaitNode q = null;
    boolean queued = false;
    for (;;) {//自旋
        if (Thread.interrupted()) {//获取并清除中断状态
            removeWaiter(q);//移除等待WaitNode
            throw new InterruptedException();
        }

        int s = state;
        if (s > COMPLETING) {
            if (q != null)
                q.thread = null;//置空等待节点的线程
            return s;
        }
        else if (s == COMPLETING) // cannot time out yet
            Thread.yield();
        else if (q == null)
            q = new WaitNode();
        else if (!queued)
            // CAS修改waiter
            queued = UNSAFE.compareAndSwapObject(this, waitersOffset,
                                                 q.next = waiters, q);
        else if (timed) {
            nanos = deadline - System.nanoTime();
            if (nanos <= 0L) {
                removeWaiter(q);//超时，移除等待节点
                return state;
            }
            LockSupport.parkNanos(this, nanos);//阻塞当前线程
        }
        else
            LockSupport.park(this);//阻塞当前线程
    }
}
```

**awaitDone用于等待任务完成，或任务因为中断或超时而终止**。返回任务的完成状态。

在自旋的for()循环中，

- 先判断是否线程被中断，中断的话抛异常退出。
- 然后开始判断运行的`state`值，如果`state`大于`COMPLETING`，证明计算已经是终态了，此时返回终态变量。
- 若`state`等于`COMPLETING`，证明已经开始计算，并且还在计算中。此时为了避免过多的CPU时间放在这个for循环的自旋上，程序执行`Thread.yield()`，把线程从运行态降为就绪态，让出CPU时间。
- 若以上状态都不是，则证明`state`为`NEW`，还没开始执行。那么程序在当前循环现在会新增一个`WaitNode`，在下一个循环里面调用`LockSupport.park()`把当前线程阻塞。当`run()`方法结束的时候，会再次唤醒此线程，避免自旋消耗CPU时间。
- 如果选用了超时功能，在阻塞和自旋过程中超时了，则会返回当前超时的状态。

#### 核心方法 - cancel(boolean mayInterruptIfRunning)

```java
public boolean cancel(boolean mayInterruptIfRunning) {
    //如果当前Future状态为NEW，根据参数修改 Future状态为 INTERRUPTING 或 CANCELLED
    if (!(state == NEW &&
          UNSAFE.compareAndSwapInt(this, stateOffset, NEW,
              mayInterruptIfRunning ? INTERRUPTING : CANCELLED)))
        return false;
    try {    // in case call to interrupt throws exception
        if (mayInterruptIfRunning) {//可以在运行时中断
            try {
                Thread t = runner;
                if (t != null)
                    t.interrupt();
            } finally { // final state
                UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);
            }
        }
    } finally {
        finishCompletion();//移除并唤醒所有等待线程
    }
    return true;
}
```

尝试取消任务。如果任务已经完成或已经被取消，此操作会失败。

- 如果当前Future状态为NEW，根据参数修改Future状态为 INTERRUPTING 或 CANCELLED。
- 如果当前状态不为NEW，则根据参数 mayInterruptIfRunning 决定是否在任务运行中也可以中断。中断操作完成后，调用finishCompletion 移除并唤醒所有等待线程。

### 总结

- `Executor.sumbit()`方法异步执行一个任务，并且返回一个Future结果。
- `submit()`的原理是利用`Callable`创建一个`FutureTask`对象，然后执行对象的`run()`方法，把结果保存在`outcome`中。
- 调用`get()`获取`outcome`时，如果任务未完成，会阻塞线程，等待执行完毕。
- 异常和正常结果都放在`outcome`中，调用`get()`获取结果或抛出异常。

## CompletableFuture

### 背景

```java
public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {}
```

我们可以看到 `CompletableFuture` 实现了 `Future` 和 `CompletionStage` 接口，使用 `Future` 获得异步执行结果时，要么调用阻塞方法 `get()`，要么轮询看 `isDone()` 是否为 true，这两种方法都不是很好，因为主线程也会被迫等待。

从 Java 8 开始引入了 `CompletableFuture`，它针对 `Future` 做了改进，可以传入回调对象，当异步任务完成或者发生异常时，自动调用回调对象的回调方法。当任务执行完之后，会通知调用线程来执行回调方法。而在调用回调方法之前，调用线程可以执行其他任务，是非阻塞的。

> `CompletableFuture` 是 JDK 1.8 里面引入的一个基于事件驱动的一个异步回调类，简单来说就是说当前使用异步线程去执行一个任务的时候，我们希望在这个任务结束以后触发一个后续的动作，而 `CompletableFuture` 就可以实现这样一个功能。
>
> `CompletableFuture` 对 `Future`进行了扩展，可以通过设置回调的方式处理计算结果，同时也支持组合操作，支持进一步的编排，同时一定程度解决了回调地狱的问题。
>
> 提供了五种不同的方式
>
> - thenCombine 把两个任务组合在一起，当两个任务都执行结束以后，触发某个事件的回调
> - thenCompose 第一个任务执行结束以后自动去触发执行第二个任务
> - thenAccept 它是第一个任务执行结束以后触发第二个任务，并且第一个任务的执行结果作为第二个任务的一个参数，无返回值
> - thenApply 同thenAccept，有返回值的一个方法
> - thenRun 任务执行完成以后，触发执行一个实现了 Runnable 接口的一个任务

```java
public static void main(String[] args) throws InterruptedException {
    CompletableFuture
    //委托师傅做蛋糕
    .supplyAsync(()-> {
        try {
            System.out.println("师傅准备做蛋糕");
            TimeUnit.SECONDS.sleep(1);
            System.out.println("师傅做蛋糕做好了");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return "cake";
    })
    //做好了告诉我一声
    .thenAccept(cake->{
        System.out.println("我吃蛋糕:" + cake);
    });
    System.out.println("我先去喝杯牛奶");
    Thread.currentThread().join();
}
```

### CompletableFuture解决的问题

CompletableFuture 是由Java 8引入的，在Java8之前我们一般通过Future实现异步。

- Future用于表示异步计算的结果，只能通过阻塞或者轮询的方式获取结果，而且不支持设置回调方法，Java 8之前若要设置回调一般会使用guava的 ListenableFuture，回调的引入又会导致臭名昭著的回调地狱（下面的例子会通过ListenableFuture 的使用来具体进行展示）。
- **CompletableFuture 对 Future进行了扩展，可以通过设置回调的方式处理计算结果，同时也支持组合操作，支持进一步的编排，同时一定程度解决了回调地狱的问题**。

举例来说明，我们通过 ListenableFuture、CompletableFuture 来实现异步的差异。假设有三个操作step1、step2、step3存在依赖关系，其中step3的执行依赖step1和step2的结果。

**Future(ListenableFuture)的实现（回调地狱）如下：**

```java
ExecutorService executor = Executors.newFixedThreadPool(5);
ListeningExecutorService guavaExecutor = MoreExecutors.listeningDecorator(executor);
ListenableFuture<String> future1 = guavaExecutor.submit(() -> {
    //step 1
    System.out.println("执行step 1");
    return "step1 result";
});
ListenableFuture<String> future2 = guavaExecutor.submit(() -> {
    //step 2
    System.out.println("执行step 2");
    return "step2 result";
});
ListenableFuture<List<String>> future1And2 = Futures.allAsList(future1, future2);
Futures.addCallback(future1And2, new FutureCallback<List<String>>() {
    @Override
    public void onSuccess(List<String> result) {
        System.out.println(result);
        ListenableFuture<String> future3 = guavaExecutor.submit(() -> {
            System.out.println("执行step 3");
            return "step3 result";
        });
        Futures.addCallback(future3, new FutureCallback<String>() {
            @Override
            public void onSuccess(String result) {
                System.out.println(result);
            }  
            @Override
            public void onFailure(Throwable t) {
            }
        }, guavaExecutor);
    }

    @Override
    public void onFailure(Throwable t) {
    }}, guavaExecutor);
```

**CompletableFuture 的实现如下：**

```java
ExecutorService executor = Executors.newFixedThreadPool(5);
// supplyAsync 表示执行一个异步方法
CompletableFuture<String> cf1 = CompletableFuture.supplyAsync(() -> {
    System.out.println("执行step 1");
    return "step1 result";
}, executor);

CompletableFuture<String> cf2 = CompletableFuture.supplyAsync(() -> {
    System.out.println("执行step 2");
    return "step2 result";
});
cf1.thenCombine(cf2, (result1, result2) -> {
    System.out.println(result1 + " , " + result2);
    System.out.println("执行step 3");
    return "step3 result";
// thenAccept 表示执行成功后再串联另外一个异步方法
}).thenAccept(result3 -> System.out.println(result3));
```

显然，CompletableFuture 的实现更为简洁，可读性更好。

### `CompletableStage接口`

常用的几个方法：

- thenApply 将上一个 stage 的结果转化成新的类型或值
- thenAccept 将上一个 stage 的结果进行消耗，无返回值
- thenRun 在上一个 stage 有结果后，执行一段新的操作
- thenCombine 结合两个 CompletableStage 的结果，转化成新的类型或值
- thenCompose 返回一个新的 CompletableStage，并将上一个 stage 的结果作为新的 stage 的 supplier
- exceptionally 当运算过程中遇到异常时的一个补偿处理
- handle 统一了对正常结果和异常结果的处理

### 关键组件

#### 操作的分类

`CompletableFuture` 可以对执行链上的各个操作进行组合编排，其实在 `CompletableFuture` 内部实现中所有操作都只分为了以下两大类

> - 依赖操作：  
>   单依赖操作只依赖一个前置操作，只要前置操作完成了就可以执行
> - 双依赖操作  
>   与单依赖操作的定义类似，双依赖操作依赖的前置操作为两个，双依赖操作的执行需要根据其两个前置操作的执行情况来确定

![image-20250614000031321](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000031321.png)

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000041448.png" alt="image-20250614000041448" style="zoom:50%;" />

### 核心源码解读

#### 成员

```java
public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {

    volatile Object result;       // Either the result or boxed AltResult
    volatile Completion stack;    // TopS of Treiber stack of dependent actions
}
```

- `result` 代表着 `CompletableFuture` 对象的执行结果。
- `Completion` 类型的 `stack` 字段代表着需要回调的后续任务栈。

  - 这是一个 CAS 实现的无锁并发栈，每个链式调用的任务会被压入这个栈。
  - `Completion` 对象内部维护着一个 `next` 指针，可以指向下一个需要被回调的对象，所有需要被回调的对象组成了一个单向链表。
  - `Completion`对象是用来驱动某一个`CompletableFuture`对象，所谓的驱动，就是使得这个`CompletableFuture`对象的`result`成员变为非null。

##### Completion内部类

```java
abstract static class Completion extends ForkJoinTask<Void>
    implements Runnable, AsynchronousCompletionTask {
    volatile Completion next;      // 无锁并发栈

    /**
     * 钩子方法，有三种模式，postComplete()方法里面使用的是NESTED模式，
     * 避免过深的递归调用 SYNC, ASYNC, or NESTED
     */
    abstract CompletableFuture<?> tryFire(int mode); // run()和exec()都调用了这个钩子方法

    /** Returns true if possibly still triggerable. Used by cleanStack. */
    abstract boolean isLive(); // cleanStack()方法里有用到

    public final void run()                { tryFire(ASYNC); }
    public final boolean exec()            { tryFire(ASYNC); return true; }
    public final Void getRawResult()       { return null; }
    public final void setRawResult(Void v) {}
}
```

`Completion` 中的 `next` 保存了栈中下一个元素的引用，而 `CompletableFuture` 中的 `stack` 永远指向栈顶。

多个线程对同一个 `CompletableFuture` 对象 `complete` 时，只有一个会成功，所以 `CompletableFuture` 是线程安全且高效的。

##### Signaller内部类

```JAVA
static final class Signaller extends Completion implements ForkJoinPool.ManagedBlocker {
    long nanos;                    // wait time if timed
    final long deadline;           // non-zero if timed
    volatile int interruptControl; // > 0: 可中断的, < 0: 已经被中断了
    volatile Thread thread;

    Signaller(boolean interruptible, long nanos, long deadline) {
        this.thread = Thread.currentThread();
        this.interruptControl = interruptible ? 1 : 0;  // 0代表不支持中断
        this.nanos = nanos;
        this.deadline = deadline;
    }
    final CompletableFuture<?> tryFire(int ignore) {
        Thread w; // no need to atomically claim
        if ((w = thread) != null) {
            thread = null;
            LockSupport.unpark(w); // tryFire唤醒即可
        }
        return null;
    }
    // 返回true代表当前线程不需要阻塞了
    public boolean isReleasable() {
        if (thread == null)
            return true;
        if (Thread.interrupted()) {
            int i = interruptControl;
            interruptControl = -1; // 只要被中断，不管之前的值是什么，都置为-1
            if (i > 0) // 如果支持中断，既然支持中断，那么不需要阻塞了
                return true;
        }
        // 虽然发现中断，但此对象不支持中断，那么也需要阻塞。这意味着会一直等到依赖stage执行完成

        if (deadline != 0L &&
            (nanos <= 0L || (nanos = deadline - System.nanoTime()) <= 0L)) {
            thread = null;
            //如果已经超时
            return true;
        }
        // 如果还没有超时，则需要阻塞

        return false;
    }
    public boolean block() {
        if (isReleasable()) // 如果发现不需要阻塞了，那么直接返回
            return true;
        else if (deadline == 0L) // 如果不是超时版本，那么无限阻塞
            LockSupport.park(this);
        else if (nanos > 0L) // 如果是超时版本，那么限时阻塞
            LockSupport.parkNanos(this, nanos);
        // 唤醒后判断是否需要阻塞
        return isReleasable();
    }
    final boolean isLive() { return thread != null; }
}
```

配合`get`或者`join`使用的，实现对 想获取执行结果的线程 的 **阻塞** 和 **唤醒** 的功能。

#### `supplyAsync` 创建异步任务

以 `supplyAsync` 为例来说明 `CompletableFuture` 如何创建一个异步任务并运行；

```java
public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier) {
    // asyncPool, ForkJoinPool.commonPool()或者ThreadPerTaskExecutor(实现了Executor接口，里面的内容是{new Thread(r).start();})
    return asyncSupplyStage(asyncPool, supplier);
}

public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier, Executor executor) {
    return asyncSupplyStage(screenExecutor(executor), supplier);
}
```

##### `asyncSupplyStage`

`asyncSupplyStage` 提交任务的过程可以分为三步：

1. 首先，创建了一个代表当前任务执行阶段的 `CompletableFuture` 对象并最终返回；
2. 其次，将代表当前阶段的 `CompletableFuture` 对象与 `Supplier` 接口封装到 `AsyncSupply`；
3. 最终，将 `AsyncSupply` 对象提交到线程池中执行

```java
static <U> CompletableFuture<U> asyncSupplyStage(Executor e,Supplier<U> f) {
    if (f == null) throw new NullPointerException();
    // 构建一个新的CompletableFuture, 以此构建AsyncSupply作为Executor的执行参数
    CompletableFuture<U> d = new CompletableFuture<U>(); 
    // AsyncSupply继承了ForkJoinTask, 实现了Runnable
    e.execute(new AsyncSupply<U>(d, f)); // 封装Supplier接口并提交到线程池中
    return d;
}
```

##### `AsyncSupply`

```java
// CompletableFuture的静态内部类，作为一个ForkJoinTask
static final class AsyncSupply<T> extends ForkJoinTask<Void> implements Runnable, AsynchronousCompletionTask {
    CompletableFuture<T> dep; // AsyncSupply作为一个依赖Task，dep作为这个Task的Future
    Supplier<T> fn; // fn作为这个Task的具体执行逻辑，函数式编程

    AsyncSupply(CompletableFuture<T> dep, Supplier<T> fn) {
        this.dep = dep;
        this.fn = fn;
    }

    public final Void getRawResult() {
        return null;
    }

    public final void setRawResult(Void v) {
    }

    public final boolean exec() {
        run();
        return true;
    }

    public void run() {
        CompletableFuture<T> d;
        Supplier<T> f;
        if ((d = dep) != null && (f = fn) != null) { // 非空判断
          // 为了防止内存泄漏，方便GC.同时dep为null也是一种代表当前Completion对象的关联stage已完成的标志
            dep = null;
            fn = null;
            if (d.result == null) { // 查看任务是否结束，如果已经结束(result != null)，直接调用postComplete()方法
                try {
                    d.completeValue(f.get()); // 等待任务结束，并设置结果
                } catch (Throwable ex) {
                    d.completeThrowable(ex); // 异常
                }
            }
            d.postComplete(); // 任务结束后，会执行所有依赖此任务的其他任务，这些任务以一个无锁并发栈的形式存在
        }
    }
}
postComplete()
final void postComplete() {
    CompletableFuture<?> f = this; // 当前CompletableFuture
    Completion h; // 无锁并发栈，(Completion next), 保存的是依靠当前的CompletableFuture一串任务，完成即触发（回调）
    while ((h = f.stack) != null || (f != this && (h = (f = this).stack) != null)) { // 当f的stack为空时，使f重新指向当前的CompletableFuture，继续后面的结点
        CompletableFuture<?> d;
        Completion t;
        if (f.casStack(h, t = h.next)) { // 从头遍历stack，并更新头元素
            if (t != null) {
                if (f != this) { // 如果f不是当前CompletableFuture，则将它的头结点压入到当前CompletableFuture的stack中，使树形结构变成链表结构，避免递归层次过深
                    pushStack(h);
                    continue; // 继续下一个结点，批量压入到当前栈中
                }
                h.next = null; // 如果是当前CompletableFuture, 解除头节点与栈的联系
            }
            f = (d = h.tryFire(NESTED)) == null ? this : d; // 调用头节点的tryFire()方法，该方法可看作Completion的钩子方法，执行完逻辑后，会向后传播的
        }
    }
}
```

以上就是一个 `CompletableFuture` 异步任务的创建与执行过程。那么，如果需要在当前的异步任务完成时执行其他逻辑，`CompletableFuture` 时如何实现的呢？

#### `thenApply`创建回调任务

```java
public <U> CompletableFuture<U> thenApply(Function<? super T, ? extends U> fn) {
    return uniApplyStage(null, fn);
}

public <U> CompletableFuture<U> thenApplyAsync(Function<? super T, ? extends U> fn) {
    return uniApplyStage(asyncPool, fn);
}
```

##### `uniApplyStage`

```java
private <V> CompletableFuture<V> uniApplyStage(
    Executor e, Function<? super T,? extends V> f) {
    if (f == null) throw new NullPointerException();
    CompletableFuture<V> d =  new CompletableFuture<V>();
    // 如果e不为null，说明当前stage是无论如何都需要被异步执行的。所以短路后面的d.uniApply。
    // 如果e为null，说明当前stage是可以允许被同步执行的。所以需要尝试一下d.uniApply。
    // d.uniApply 可以理解为依赖的前任任务是否已经执行完成
    if (e != null || !d.uniApply(this, f, null)) {  // 判断线程池是否为空，为空则直接尝试执行
        // 进入此分支有两种情况：
        // 1. 要么e不为null，前一个stage不一定执行完毕。就算前一个stage已经执行完毕，还可以用e来执行当前stage
        // 2. 要么e为null，但前一个stage还没执行完毕。所以只能入栈等待
        UniApply<T,V> c = new UniApply<T,V>(e, d, this, f);// 新建对象，封装代表执行逻辑的函数式接口对象f,代表当前阶段的CP对象d，还有前置任务this，以及线程池e；
        push(c); // UniApply继承UniCompletion继承Completion，c其实就是Completion对象，被push到栈中
        //（考虑e为null）入栈后需要避免，入栈后刚好前一个stage已经执行完毕的情况。这种特殊情况，如果不执行c.tryFire(SYNC)，当前stage永远不会完成。
        //（考虑e不为null）入栈后需要避免，入栈前 前一个stage已经执行完毕的情况。
       c.tryFire(SYNC); // 防止push过程中前置任务变更完成状态，漏掉当前阶段的任务。尝试执行一次。
    }
    return d;
}
```

##### **tryFire**

`tryFire` 方法的作用就是尝试执行 `stack` 中的任务。此处的 `tryFire` 方法，通过刚刚创建的 `UniApply` 对象调用，并执行封装在其中的任务逻辑。

此处调用是为了避免任务完成入栈后，前置 `CompletableFuture` 已经执行完成，从而错过了回调的时机，导致当前的任务无法被触发的情况。

```java
final CompletableFuture<V> tryFire(int mode) {
    CompletableFuture<V> d; CompletableFuture<T> a;
    // 1. 如果dep为null，说明当前stage已经被执行过了
    // 2. 如果uniApply返回false，说明当前线程无法执行当前stage。返回false有可能是因为
    //     2.1 前一个stage没执行完呢
    //     2.2 前一个stage执行完了，但当前stage已经被别的线程执行了。如果提供了线程池，那么肯定属于被别的线程执行了。   
    // 如果uniApply执行成功，则会进到下面的postFire调用，否则return null，也就是tryFire失败了，就要等待以后的主动complete来再次触发
    if ((d = dep) == null ||
        !d.uniApply(a = src, fn, mode > 0 ? null : this))//执行任务逻辑
        return null;
    dep = null; src = null; fn = null; // tryFire成功后，会把以下几个属性设为null，代表此Completion已经完成任务，变成dead状态
    return d.postFire(a, mode);
}
```

通过源码也可以再次确认，`tyrFire` 方法其中的主要逻辑之一就是尝试执行封装的任务逻辑。

##### **postFire**

`postFire` 主要用来处理任务执行完成的后续工作。如清理 `stack` 中的无效节点，嵌套调用时返回当前 `CompletableFuture` 对象或在非嵌套调用时执行 `postComplete` 方法，用来激发后续任务。

```java
final CompletableFuture<T> postFire(CompletableFuture<?> a, int mode) {
    if (a != null && a.stack != null) { // 前一个stage的后续任务还没做完
       // 1. mode为NESTED。说明就是postComplete调用过来的，那么只清理一下栈中无效节点即可。
        // 2. mode为SYNC或ASYNC，但前一个stage还没执行完。不知道何时发生，因为调用postFire的前提就是前一个stage已经执行完
        if (mode < 0 || a.result == null)
            a.cleanStack(); // 清理stack中的无效节点
        else
            a.postComplete(); // 使用当前线程帮助前置任务执行stack
    }
    if (result != null && stack != null) { // 当前stage的后续任务还没做完
        if (mode < 0)
            return this; // 嵌套调用，stack不为空，返回当前阶段。
        else
            postComplete(); // 非嵌套调用，stack不为空，处理当前阶段的stack
    }
    return null;
}
```

##### **UniApply**

`UniApply` 的作用就是判断任务是否满足执行条件，然后执行封装的函数式接口。这个过程大概可以分为四个部分：

1. 判断前置任务是否完成；
2. 判断前置任务是否有异常；
3. 判断当前任务是否已经被其他线程声明了执行权限；
4. 调用函数式接口中的方法，执行任务逻辑，并封装结果。

```java
final <S> boolean uniApply(CompletableFuture<S> a,
                           Function<? super S,? extends T> f,
                           UniApply<S,T> c) { // a前置CP,f当前阶段函数，c封装当前阶段逻辑的Completion对象
    Object r; Throwable x;
    // 前后两个条件只是优雅的避免空指针异常，实际不可能发生。
    // 如果 前一个stage的result为null，说明前一个stage还没执行完毕
    if (a == null || (r = a.result) == null || f == null)
        return false; // 前置任务未完成或其他异常情况
    // 执行到这里，说明前一个stage执行完毕
    // 如果this即当前stage的result为null，说当前stage还没执行。
    tryComplete: if (result == null) { // 当前CP的结果为空，一定程度防止了竞争
        if (r instanceof AltResult) { // 如果前一个stage的执行结果为null或者抛出异常
            if ((x = ((AltResult)r).ex) != null) {
             // 如果前一个stage抛出异常，那么直接让当前stage的执行结果也为这个异常，都不用执行Function了
                completeThrowable(x, r);
                break tryComplete;
            }
          // 如果前一个stage的执行结果为null
            r = null; // 那么让r变成null
        }
        try {
          // 1. c为null，这说明c还没有入栈，没有线程竞争。直接执行当前stage即f.apply(s)
            // 2. c不为null，这说明c已经入栈了，有线程竞争执行当前stage。
            if (c != null && !c.claim()) // claim判断任务是否被执行过；
                return false;
            @SuppressWarnings("unchecked") S s = (S) r; // 转换前置任务的结果类型
            completeValue(f.apply(s)); // 调用function函数的apply方法，并将结果封装到CompletableFuture对象中。
        } catch (Throwable ex) {
            completeThrowable(ex);
        }
    }
    // 如果this即当前stage的result不为null，说当前stage已经执行完毕，那么直接返回true
    return true;
}
```

##### 汇总

所以，被封装了回调任务的 `CompletableFuture` 对象应该长这个样子。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000121904.png" alt="image-20250614000121904" style="zoom:50%;" />

`Completion` 对象里面封装的是需要被回调的任务逻辑。但是代表当前阶段的任务又在哪里？

其实，`CompletableFuture` 并不知道当前阶段的任务在哪里，而是返过来通过任务指向代表当前阶段的对象。

`Completion` 对象通过 `dep` 字段，持有代表当前任务阶段的 `CompletableFuture对象`。

所以，完成的调用链可能长这个样子：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000140649.png" alt="image-20250614000140649" style="zoom:50%;" />

#### 如何触发回调任务

前面说过，`Completion` 对象通过 `dep` 指向代表当前阶段的 `CompletableFuture` 对象。但是没有说的是，这个 `CompletableFuture` 对象也可能会有自己的回调链（`stack` 指向的单项链表）。因此，完整的回调结构可能长这个样子的。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000201974.png" alt="image-20250614000201974" style="zoom:50%;" />

我们来看回调是如何被触发的。

`supplyAsync` 的源码中，执行了这样一个方法 `d.postComplete();`，该方法就是触发后续任务的关键。

##### postComplete

```java
final void postComplete() {
    /*
     * f-->当前CP对象，h-->CP对象的stack，t-->stack的next节点
     */
    CompletableFuture<?> f = this; Completion h;
    // 1. 如果当前f的stack不为null，那么短路后面
    // 2. 如果当前f的stack为null，且f是this（f != this不成立），说明整个树形结构已经被遍历完毕，退出循环
    // 3. 如果当前f的stack为null，且f不是this，那么让f恢复为this，再查看this的stack是否为null
    while ((h = f.stack) != null ||
           (f != this && (h = (f = this).stack) != null)) {
        CompletableFuture<?> d; Completion t;
        if (f.casStack(h, t = h.next)) { // 保证postComplete被并发调用时，同一个任务只能被一个线程拿到
            if (t != null) {
                if (f != this) { // 下一阶段CP对象的stack不为空，将stack压入当前CP对象的stack中。防止递归调用过深。
                    pushStack(h);
                    continue;
                }
                h.next = null; // 如果h是有后继的，需要断开h的next指针
            }
          // d-->tryFire的返回值；d不为空时，f被指向d。即h任务所在阶段的CompletableFuture对象
            f = (d = h.tryFire(NESTED)) == null ? this : d;
        }
    }
}
```

触发的过程可以分为一下几部

1. **取下 stack 中的首节点**：首先从当前 `CompletableFuture` 对象(this)中，获取到回调链 `stack`。如果 `stack` 不为空，先获取首节点的引用，然后将 `stack` 通过 CAS 指向 `next`。如果 CAS 更新成功，获取了头结点的执行权限，可以进行下一步。否则重复上述过程，直到成功取下一个节点或没有任务需要执行。
2. **执行节点的任务逻辑**：第一次取得头结点后 `if (f != this)` 显然是不成立的，先不考虑里面包含的逻辑。关注这行代码 ` h.tryFire(NESTED)`。tryFire 方法与前面说的一致，就是执行 Completion 中封装的任务逻辑。如果一切顺利，那么第一个需要被回调的任务就开始执行了。
3. **重新赋值 f**:tryFire 在嵌套调用时，如果 Completion 指向的 CompletableFuture 对象也有需要被回调的任务，那么 tryFire 方法会返回该 CompletableFuture 对象，否则返回 null。因此，`f = (d = h.tryFire(NESTED)) == null ? this : d;` 这句话的作用就是:如果有后续任务，依赖于当前执行的阶段，那么返回代表这个阶段的 CompletableFuture 对象，赋值给 f。否则，f 仍然指向 this。
4. **将递归调用转为循环调用**：当 f 指向了下一阶段的 CompletableFuture 对象后，`if (f != this)` 条件成立，执行 pushStack 方法。该方法把上一步 tryFire 返回的 CompletableFuture 对象的回调任务压入到了自己的 stack 栈中。通过 while 循环，直到所有的任务都被压入后，`f.stack` 的值变为 null。此时，f 被重新指向 this 继续回调后续的任务，直到所有的任务都被触发。这样做是为了将递归调用改为循环调用，防止递归过深。

举个例子：base 的 stack（对象 2、1、0）和它下面那些 dep 中的 stack 执行上顺序正好是相反的，暂且称 base 的 stack 为主 stack 吧，我们来画一张更通用的关系来重点看下 stack：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000224305.png" alt="image-20250614000224305" style="zoom:50%;" />

先执行 base 的栈顶 Completion 2，成功后出栈。然后会检查 Completion 2 中 dep 的 stack，只要没到栈底，则会取出栈顶压入 base 的 stack 中，该图则把 Completion 8、7 分别压到 base 的 stack 中，然后执行栈底的 Completion 6

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000241587.png" alt="image-20250614000241587" style="zoom:50%;" />

重复这个过程，执行 base 的栈顶 Completion 7，由于 Completion 7 的 dep 的 stack 为空，则直接出栈即可。接着 Completion 8 会被执行。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000300041.png" alt="image-20250614000300041" style="zoom:50%;" />

接下来处理 Completion 1 的过程和之前类似。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000318026.png" alt="image-20250614000318026" style="zoom:50%;" />

#### get相关方法

##### get()

对于任何`CompletableFuture`对象，我们都可以调用`get`函数来阻塞获得它的输出。

```java
public T get() throws InterruptedException, ExecutionException {
    Object r;
    // 如果this对象已经执行完成，直接reportGet
    return reportGet((r = result) == null ? waitingGet(true) : r);
}
```

如果`this对象`还没执行完成，则调用`waitingGet`，先自旋，再阻塞。当依赖的stage完成时，再将当前线程唤醒。

###### `waitingGet`

```java
private Object waitingGet(boolean interruptible) {
    Signaller q = null;
    boolean queued = false;
    int spins = -1;
    Object r;
    while ((r = result) == null) {
        if (spins < 0) // 开始自旋
            spins = (Runtime.getRuntime().availableProcessors() > 1) ?
            1 << 8 : 0; // Use brief spin-wait on multiprocessors
        else if (spins > 0) {  // 每次自旋
            if (ThreadLocalRandom.nextSecondarySeed() >= 0)    // 不一定每次自旋都会
                --spins;
        }
        // 如果自旋次数为0
        else if (q == null) // 但还没有生成Signaller
            q = new Signaller(interruptible, 0L, 0L);
        else if (!queued) // 生成了但还没入栈
            queued = tryPushStack(q);
            // 已经入栈了
        else if (interruptible && q.interruptControl < 0) { // 如果支持中断，且当前线程已经被中断
            q.thread = null; // 那么不能再等了，直接返回null
            cleanStack(); // 帮忙依赖的stage，清理stack
            return null;
        }
        else if (q.thread != null && result == null) {
            try {
                ForkJoinPool.managedBlock(q); // 进行阻塞，这里面是也是循环阻塞的过程
            } catch (InterruptedException ie) {
                q.interruptControl = -1;
            }
        }
    }
    // 执行到这里，说明阻塞已唤醒。可能是正常等到了依赖stage执行完，也可能是被中断了
    if (q != null) {
        q.thread = null;
        if (q.interruptControl < 0) { // 被中断了
            if (interruptible) // 如果本次调用支持被中断，那么返回null
                r = null; // report interruption
            else // 如果本次调用不支持被中断，那么只是自我中断一下
                Thread.currentThread().interrupt();
        }
    }
    postComplete(); // 帮忙处理后续任务
    return r;
}
```

###### `managedBlock`

主要通过`ForkJoinPool.managedBlock(q)`进行的阻塞等待。

```java
public static void managedBlock(ManagedBlocker blocker) throws InterruptedException {
    ForkJoinPool p;
    ForkJoinWorkerThread wt;
    Thread t = Thread.currentThread();
    if ((t instanceof ForkJoinWorkerThread) &&
        (p = (wt = (ForkJoinWorkerThread)t).pool) != null) {
        ...
    }
    else { // 只会执行到这里
        do {} while (!blocker.isReleasable() && // 其实block也是在调用 isReleasable
                     !blocker.block());
    }
}
```

可以看到整个执行过程是`while (!blocker.isReleasable() && !blocker.block())`。

```java
static final class Signaller extends Completion implements ForkJoinPool.ManagedBlocker {
    long nanos;                    // wait time if timed
    final long deadline;           // non-zero if timed
    volatile int interruptControl; // > 0: 可中断的, < 0: 已经被中断了
    volatile Thread thread;

    Signaller(boolean interruptible, long nanos, long deadline) {
        this.thread = Thread.currentThread();
        this.interruptControl = interruptible ? 1 : 0;  // 0代表不支持中断
        this.nanos = nanos;
        this.deadline = deadline;
    }
    final CompletableFuture<?> tryFire(int ignore) {
        Thread w; // no need to atomically claim
        if ((w = thread) != null) {
            thread = null;
            LockSupport.unpark(w); // tryFire唤醒即可
        }
        return null;
    }
    // 返回true代表当前线程不需要阻塞了
    public boolean isReleasable() {
        if (thread == null)
            return true;
        if (Thread.interrupted()) {
            int i = interruptControl;
            interruptControl = -1; // 只要被中断，不管之前的值是什么，都置为-1
            if (i > 0) // 如果支持中断，既然支持中断，那么不需要阻塞了
                return true;
        }
        // 虽然发现中断，但此对象不支持中断，那么也需要阻塞。这意味着会一直等到依赖stage执行完成

        if (deadline != 0L &&
            (nanos <= 0L || (nanos = deadline - System.nanoTime()) <= 0L)) {
            thread = null;
            //如果已经超时
            return true;
        }
        // 如果还没有超时，则需要阻塞

        return false;
    }
    public boolean block() {
        if (isReleasable()) // 如果发现不需要阻塞了，那么直接返回
            return true;
        else if (deadline == 0L) // 如果不是超时版本，那么无限阻塞
            LockSupport.park(this);
        else if (nanos > 0L) // 如果是超时版本，那么限时阻塞
            LockSupport.parkNanos(this, nanos);
        // 唤醒后判断是否需要阻塞
        return isReleasable();
    }
    final boolean isLive() { return thread != null; }
}
```

那什么时候唤醒这个线程呢？

完成任务的时候，会走到 `postComplete` 方法：

![image-20250614000353903](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000353903.png)

![image-20250614000405277](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000405277.png)

![image-20250614000417534](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000417534.png)

###### 汇总

- `waitingGet`函数的参数`interruptible`代表获得执行结果的当前线程，可以因为中断而终止阻塞。
- `get`函数返回null有两种情况：

  - 依赖的stage正常执行完，且执行结果为null。
  - 依赖的stage还没执行完，但当前线程被中断了。

##### join()

```java
public T get() throws InterruptedException, ExecutionException {
    Object r;
    return reportGet((r = result) == null ? waitingGet(true) : r);
}
```

`join`方法与get的唯一区别是，`join`不支持中断，所以当前线程唤醒的唯一希望就是依赖的stage执行完毕。

##### 超时get

```java
public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
    Object r;
    long nanos = unit.toNanos(timeout);
    return reportGet((r = result) == null ? timedGet(nanos) : r);
}
```

调用的是`timedGet`，整个过程类似。我们只需要知道，超时版本是自带支持中断的功能。

```java
private Object timedGet(long nanos) throws TimeoutException {
    if (Thread.interrupted()) // 超时版本自带被中断的功能
        return null;
    if (nanos <= 0L)  // 不能给无意义的超时时间
        throw new TimeoutException();
    long d = System.nanoTime() + nanos;
    Signaller q = new Signaller(true, nanos, d == 0L ? 1L : d); // 注意第一个参数为true，因为超时版本必定可以中断
    boolean queued = false;
    Object r;
    // 这里没有像waitingGet一样进行自旋，因为限时中断就相当于自旋了
    while ((r = result) == null) {
        if (!queued)
            queued = tryPushStack(q);
            // 1. q已经被中断了 
            // 2. q已经超时了
        else if (q.interruptControl < 0 || q.nanos <= 0L) {
            q.thread = null;
            cleanStack();
            if (q.interruptControl < 0) // 被中断
                return null;
            throw new TimeoutException(); // 已经超时
        }
        else if (q.thread != null && result == null) {
            try {
                ForkJoinPool.managedBlock(q);
            } catch (InterruptedException ie) {
                q.interruptControl = -1;
            }
        }
    }
    if (q.interruptControl < 0) // 被中断了，就返回null
        r = null;
    q.thread = null;
    postComplete();
    return r;
}
```

### 调用与内部执行步骤拆解

常见的链式调用对象关系如下：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000435696.png" alt="image-20250614000435696" style="zoom:50%;" />

其实每次调用都会 `new` 一个 `Completion` 对象，并压入上一个 `CompletableFuture` 的 `stack` 中。所以，通常的 `base.thenApply(..).thenApply(..)`，每次调用产生的 `Completion` 并不在同一个 `stack` 中哦。

来个复杂一些的：

```java
CompletableFuture<String> base = new CompletableFuture<>();
CompletableFuture<String> future =
    base.thenApply(
        s -> {
            log.info("2");
            return s + " 2";
        });
base.thenAccept(s -> log.info(s+"a")).thenAccept(aVoid -> log.info("b"));
base.thenAccept(s -> log.info(s+"c")).thenAccept(aVoid -> log.info("d"));
base.complete("1");
log.info("base result: {}", base.get());
log.info("future result: {}", future.get());
```

执行到第 7 行后，对象关系如下图：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000454253.png" alt="image-20250614000454253" style="zoom:50%;" />

第 8 行后：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000511038.png" alt="image-20250614000511038" style="zoom:50%;" />

第 9 行后：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000528232.png" alt="image-20250614000528232" style="zoom:50%;" />

至此，整个对象关系如同一个执行计划，等待着 base 的 complete 那一刻。

我们再来分解下第 10 行的执行步骤：

1. base.complete("1")后 base 里的 result 属性会变成 1
2. 取 base 中 stack（对象 1）执行，出栈
3. 取对象 1 中 dep 属性的 stack（对象 2）执行，出栈
4. 取 base 中 stack（对象 3）执行，出栈
5. 取对象 3 中 dep 属性的 stack（对象 4）执行，出栈
6. 取 base 中 stack（对象 5）执行，出栈

### 实践总结

#### 线程阻塞问题

代码执行在哪个线程上？

CompletableFuture实现了CompletionStage接口，通过丰富的回调方法，支持各种组合操作，每种组合场景都有同步和异步两种方法。

- 同步方法（即不带Async后缀的方法）有两种情况。

  - 如果注册时被依赖的操作已经执行完成，则直接由当前线程执行。
  - 如果注册时被依赖的操作还未执行完，则由回调线程执行。

- 异步方法（即带Async后缀的方法）

  - 可以选择是否传递线程池参数Executor运行在指定线程池中；
  - 当不传递Executor时，会使用ForkJoinPool中的共用线程池CommonPool（CommonPool的大小是CPU核数-1，如果是IO密集的应用，线程数可能成为瓶颈）。

```java
ExecutorService threadPool1 = new ThreadPoolExecutor(10, 10, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue<>(100));
CompletableFuture<String> future1 = CompletableFuture.supplyAsync(() -> {
    System.out.println("supplyAsync 执行线程：" + Thread.currentThread().getName());
    //业务操作
    return "";
}, threadPool1);
//此时，如果future1中的业务操作已经执行完毕并返回，则该thenApply直接由当前main线程执行；否则，将会由执行以上业务操作的threadPool1中的线程执行。
future1.thenApply(value -> {
    System.out.println("thenApply 执行线程：" + Thread.currentThread().getName());
    return value + "1";
});
//使用ForkJoinPool中的共用线程池CommonPool
future1.thenApplyAsync(value -> {
//do something
  return value + "1";
});
//使用指定线程池
future1.thenApplyAsync(value -> {
//do something
  return value + "1";
}, threadPool1);
```

#### 线程池须知

##### 异步回调要传线程池

前面提到，异步回调方法可以选择是否传递线程池参数Executor，这里我们建议**强制传线程池，且根据实际情况做线程池隔离**。

当不传递线程池时，会使用ForkJoinPool中的公共线程池CommonPool，这里所有调用将共用该线程池，核心线程数=处理器数量-1（单核核心线程数为1），所有异步回调都会共用该CommonPool，核心与非核心业务都竞争同一个池中的线程，很容易成为系统瓶颈。手动传递线程池参数可以更方便的调节参数，并且可以给不同的业务分配不同的线程池，以求资源隔离，减少不同业务之间的相互干扰。

##### 线程池循环引用会导致死锁

```java
public Object doGet() {
  ExecutorService threadPool1 = new ThreadPoolExecutor(10, 10, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue<>(100));
  CompletableFuture cf1 = CompletableFuture.supplyAsync(() -> {
  //do sth
    return CompletableFuture.supplyAsync(() -> {
        System.out.println("child");
        return "child";
      }, threadPool1).join();//子任务
    }, threadPool1);
  return cf1.join();
}
```

如上代码块所示，doGet方法第三行通过supplyAsync向threadPool1请求线程，并且内部子任务又向threadPool1请求线程。threadPool1大小为10，当同一时刻有10个请求到达，则threadPool1被打满，子任务请求线程时进入阻塞队列排队，但是父任务的完成又依赖于子任务，这时由于子任务得不到线程，父任务无法完成。主线程执行cf1.join()进入阻塞状态，并且永远无法恢复。

> 为了修复该问题，需要将父任务与子任务做线程池隔离，两个任务请求不同的线程池，避免循环依赖导致的阻塞。

##### 异步RPC调用注意不要阻塞IO线程池

服务异步化后很多步骤都会依赖于异步RPC调用的结果，这时需要特别注意一点，如果是使用基于NIO（比如Netty）的异步RPC，则返回结果是由IO线程负责设置的，即回调方法由IO线程触发，CompletableFuture同步回调（如thenApply、thenAccept等无Async后缀的方法）如果依赖的异步RPC调用的返回结果，那么这些同步回调将运行在IO线程上，而整个服务只有一个IO线程池，这时需要保证同步回调中不能有阻塞等耗时过长的逻辑，否则在这些逻辑执行完成前，IO线程将一直被占用，影响整个服务的响应。

## 线程调度实现

### 抢占式调度

- 每条线程执行的时间、线程的切换都由系统控制
- 一个线程的堵塞不会导致整个进程堵塞
- 有的线程可能永远抢不到
- `JVM实现的是抢占式调度`

### 协同式调度

- 某一线程执行完后主动通知系统切换到另一线程上执行
- 像接力赛一样
- 如果一个线程编写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃

## 线程的调度策略

线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行:

1. 线程体中调用了 yield 方法让出了对 cpu 的占用权利
2. 线程体中调用了 sleep 方法使线程进入睡眠状态
3. 线程由于 IO 操作受到阻塞
4. 另外一个更高优先级线程出现
5. 在支持时间片的系统中，该线程的时间片用完

## 进程调度算法

### 优先调度算法

- 先来先服务调度算法(FCFS)

  - 每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。
- 短作业(进程)优先调度算法

  - 从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。

‍

### 高优先权优先调度算法

当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程。

### 高响应比优先调度算法

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000559767.png" alt="image-20250614000559767" style="zoom:50%;" />

- 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。
- 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。

> 简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。

### 基于时间片的轮转调度算法

- 系统将所有的就绪进程按先来先服务的原则排成一个队列
- 每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片
- 由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾

### 多级反馈队列调度算法

- 设置多个就绪队列，并为各个队列赋予不同的优先级

  - 第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低
  - 在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小
- 当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度
- 当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统
- 如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行