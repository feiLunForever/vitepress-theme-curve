# 并发

## 并发基础

### 三大特性

众所周知，CPU、内存、I/O 设备的速度是有极大差异的（可以参考这篇文章：[性能第二讲：性能优化-每个程序员都应该知道的数字](https://blog.csdn.net/qq_28959087/article/details/127471432)），为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:

- CPU 增加了缓存，以均衡与内存的速度差异；// 导致 `可见性`问题
- 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 `原子性`问题
- 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 `有序性`问题

**1、原子性**：原子性指的是一个操作是不可分割、不可中断的，要么全部执行并且执行的过程不会被任何因素打断，要么就全都不执行。

**2、可见性**：可见性指的是一个线程修改了某一个共享变量的值时，其它线程能够立即知道这个修改。

**3、有序性**：有序性指的是对于一个线程的执行代码，从前往后依次执行，单线程下可以认为程序是有序的，但是并发时有可能会发生指令重排。

### 并行和并发

从操作系统的角度来看，线程是 CPU 分配的最小单位。

> 1. 并行就是同一时刻，两个线程都在执行。要求有两个 CPU 去分别执行两个线程。

2. 并发就是同一时刻，只有一个执行，但是一个时间段内，两个线程都执行了。并发的实现依赖于 CPU 切换线程，因为切换的时间特别短，所以基本对于用户是无感知的。(单位时间内不一定同时执行)

### LockSupport

- LockSupport 是用来创建锁和共他同步类的基本线程阻塞原语。
- **LockSuport 是一个线程阻塞工具类，所有的方法都是静态方法**，可以让线程在任意位置阻塞，阻塞之后也有对应的唤醒方法。归根结底，LockSupport 调用的 **Unsafe 中的 native** 代码。
- LockSupport 提供 park() 和 unpark() 方法实现 **阻塞线程** 和 **解除线程阻塞** 的过程
- LockSupport 和每个使用它的线程都有一个许可(<span data-type="text" style="color: var(--b3-font-color13);">permit</span>)关联。

  - permit相当于1，0的开关，默认是0，
  - 调用一次unpark就加1变成1，
  - 调用一次park会消费permit，也就是将1变成0，同时park立即返回。
  - 如再次调用 park 会变成阻塞 (因为 permit 为零了会阻塞在这里，一直到 permit 变为1)，这时调用unpark会把permit置为1。每个线程都有一个相关的permit，permit最多只有一个，重复调用 unpark 也不会积累凭证。

### 线程、程序与进程

- 进程

  - 进程是代码在数据集合上的一次运行活动，是 `操作系统` 进行 `资源分配` 和 `调度` 的基本单位
- 线程

  - 线程是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程的资源，`线程` 是处理器 `任务调度` 和 `执行` 的基本单位。
- 程序

  - 含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。

### sleep() 和 wait()

- `Thread.sleep()` 方法自会 `让出` CPU，但 `没有` 释放锁；`Object.wait()` 方法不仅 `让出` CPU，并 `释放` 了锁
- 两者都可以 `暂停线程` 的执行
- `wait() ` 通常被用于 `线程间交互/通信`，`sleep() ` 通常被用于 `暂停执行`
- `wait()` 方法被调用后，线程 `不会自动苏醒`，需要别的线程调用同一个对象上的 `notify()` 或者 `notifyAll()` 方法。`sleep()` 方法执行完成后，线程会 `自动苏醒`。或者可以使用 wait(long timeout) 超时后线程会自动苏醒

### Object.wait()和Condition.await()的区别

`Object.wait()` 和`Condition.await()` 的原理是基本一致的，不同的是**Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的**。

- `Object.wait()`是Java对象监视器（Object Monitor）的一部分，用于线程同步。
- `Condition.await()`是`Condition`接口的一部分，它提供了更灵活的线程同步和等待机制。

### Thread.sleep()和LockSupport.park()的区别

- 从功能上来说，`Thread.sleep()`和`LockSupport.park()`方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源；
- `Thread.sleep()`没法从外部唤醒，只能自己醒过来；
- `LockSupport.park()`方法可以被另一个线程调用`LockSupport.unpark()`方法唤醒；
- `Thread.sleep()`方法声明上抛出了`InterruptedException`中断异常，所以调用者需要捕获这个异常或者再抛出；
- `LockSupport.park()`方法不需要捕获中断异常；
- `Thread.sleep()` 本身就是一个native方法；
- `LockSupport.park()` 底层是调用的Unsafe的native方法；

### Object.wait()和LockSupport.park()的区别

- `Object.wait()` 方法需要在`synchronized`块中执行；
- `LockSupport.park()` 可以在任意地方执行；
- `Object.wait()` 方法声明抛出了中断异常，调用者需要捕获或者再抛出；
- `LockSupport.park()` 不需要捕获中断异常；
- `Object.wait()` 不带超时的，需要另一个线程执行`notify()`来唤醒，但不一定继续执行后续内容；
- `LockSupport.park()` 不带超时的，需要另一个线程执行`unpark()`来唤醒，一定会继续执行后续内容；

`park()`/`unpark()` 底层的原理是“二元信号量”，你可以把它想象成只有一个许可证的`Semaphore`，只不过这个信号量在重复执行`unpark()`的时候也不会再增加许可证，最多只有一个许可证。

### LockSupport.park()会释放锁资源吗?

不会，它只负责阻塞当前线程，释放锁资源实际上是在`Condition`的`await()`方法中实现的。

### 守护线程

Java 中的线程分为两类，分别为 `daemon 线程（守护线程）` 和 `user 线程（用户线程）`。

> 在 JVM 启动时会调用 main 函数，main 函数所在的线程就是一个用户线程。
>
> 其实在 JVM 内部同时还启动了很多守护线程， 如：垃圾回收线程，当我们的程序中不再有任何运行的 Thread，程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是 JVM 上仅剩的线程时，垃圾回收线程会自动离开。

- 有的时候应用中需要一个 `长期驻留的服务程序`，但是 `不希望其影响应用退出`，就可以将其设置为守护线程，如果 JVM 发现只有守护线程存在时，将结束进程
- 守护线程的优先级比较 `低`，用于为系统中的其它对象和线程提供服务
- 通过 `setDaemon(true)` 来设置线程为“守护线程”
- 在 Daemon 线程中产生的新线程也是 Daemon 的

### 线程的状态

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233355843.png" alt="image-20250613233355843" style="zoom:50%;" />

#### `NEW`：新建状态，线程被创建但未启动的状态

> 创建线程有三种⽅式，分别为继承 Thread 类、实现 Runnable 接口、实现 Callable 接口。
>
> 1. 继承 `Thread` 类，重写 run()方法，调用 start()方法启动线程
> 2. 实现 `Runnable` 接口，重写 run()方法，最后通过 Thread 包装并启动 new Thread(task).start();
> 3. 实现 `Callable` 接口，重写 call()方法，这种方式可以通过 FutureTask 获取任务执行的返回值

#### `RUNNABLE`（就绪状态）：调⽤ start 之后运⾏之前的状态

- JVM 执行 `start()`，会先创建一条线程，由创建出来的新线程去执行 thread 的 `run()`，这才起到多线程的效果。
- 如果直接调用 Thread 的 `run()` 方法，那么 run 方法还是运行在主线程中，相当于 `顺序执行`，就起不到多线程的效果。

#### `RUNNING`（运⾏状态）：线程正在运⾏

#### `BLOCKED`（阻塞状态）：进⼊以下状态，有以下⼏种情况

- BLOCKED

  - 阻塞状态（同步阻塞）：锁被其他线程占⽤，如等待进⼊`synchronized`⽅法或者代码块
- WAITING

  - 等待状态（主动阻塞）：执⾏`Object.wait()`，`Thread.join()` 等
- TIME_WAITING

  - (等待阻塞）：执⾏`Object.wait(long)`，`Thread.sleep(long)` 等，该状态不同于 `WAITIND`，它是可以在指定的时间自行返回的

#### `TERMINATED`（终⽌状态）：线程执⾏完毕

### 终止线程

#### 使用 `interrupt()`

- 1. **线程处于阻塞状态：**

     - 例如使用了 sleep，同步锁 wait，sleep 方法，socket 的 receiver、accept 等方法时，会使得线程处于阻塞状态。
     - 当调用线程的 `interrupt` 方法时，会抛出 `InterruptException` 异常。一定要先 `捕获` `InterruptedException` 异常之后通过 break 来跳出循环
  2. **线程未处于阻塞状态：** 需要使用 `interrupted()` 判断线程的中断标识来退出循环。

     - 当使用 `interrupt()` 方法时，中断标志会置位 true，**此时使用自定义标志来控制循环是一样的道理。**

#### 直接使用 `thread.stop()`

- 创建子线程的线程就会抛出 `ThreadDeatherror` 的错误
- 会释放子线程所持有的所有锁(不可控制)
- 不推荐

### 上下文切换

使用多线程的目的是为了充分利用 CPU，但是我们知道，并发其实是一个 CPU 来处理多个线程。
为了让用户感觉多个线程是在同时执行的， CPU 资源的分配采用了时间片轮转也就是给每个线程分配一个时间片，线程在时间片内占用 CPU 执行任务。当线程使用完时间片后，就会处于就绪状态并让出 CPU 让其他线程占用，这就是上下文切换。

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233425362.png" alt="image-20250613233425362" style="zoom:80%;" />

> - 上下文
>
>   - 是指某一时间点 CPU 寄存器和程序计数器的内容。
> - 寄存器
>
>   - 是 CPU 内部的数量较少但是速度很快的内存(与之对应的是 CPU 外部相对较慢的 RAM 主内存)。
>   - 寄存器通过对常用值(通常是运算的中间值)的快速访问来提高计算机程序运行的速度。
> - 程序计数器
>
>   - 是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置，具体依赖于特定的系统。
> - PCB-“切换桢”
>
>   - 上下文切换可以认为是内核(操作系统的核心)在 CPU 上对于进程(包括线程)进行切换，上下文切换过程中的信息是保存在进程控制块(PCB, process control block)中的。
>   - PCB 还经常被称作“切换桢” (switchframe)。信息会一直保存到 CPU 的内存中，直到他们被再次使用。

#### 上下文切换的活动

- 挂起一个进程，将这个进程的 `上下文` 信息存储在 cpu 的内存中
- 在内存中检索下一个进程的 `上下文` 并将其在 CPU 的 `寄存器` 中恢复
- 跳转到 `程序计数器` 所指向的位置(即跳转到进程被中断时的代码行)，以恢复该进程在程序中

#### 引起线程上下文切换的原因

1. 当前执行任务的时间片用完之后，系统 CPU 正常调度下一个任务;
2. 当前执行任务碰到 IO 阻塞，调度器将此任务挂起，继续下一任务;
3. 多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务;
4. 用户代码挂起当前任务，让出 CPU 时间;
5. 硬件中断;

### CAS

> CAS(V,E,N)
>
> - V：需要操作的共享变量
> - E：预期值
> - N：新值

在调用 `compareAndSwap` 函数的时候会判断，是否当前变量的数值和 E 是相同的，如果相同则进行修改，否则就说明当前有其他线程修改该值，从而放弃本次修改操作。

通常 CAS 操作会结合一个循环一起使用，当尝试执行 cas 操作却修改失败之后，就会重新将 V 值读出来赋予给 E，然后接着再执行修改操作，直达最终修改成功为止。这个不断尝试修改的过程，我们一般称之为**自旋操作**。所以常见的 cas 结合循环重试的整体流程如下图所示：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233440349.png" alt="image-20250613233440349" style="zoom:80%;" />

#### 存在的问题

- **自旋导致 CPU 消耗升高**

  - 当一个原子类在进行 CAS 操作过多的时候，会导致 CPU 一直被占用，一直消耗资源。通常这种情况发生在高并发场景下会比较多。
- **只能保证一个共享变量原子操作**
- **ABA** 问题

  - > CAS 需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是 A，后来变成了 B，然后又变成了 A，那么 CAS 进行检查时会发现值没有发生变化，但是实际上是有变化的。
    >
  - ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A。
  - 从Java 1.5开始，JDK的Atomic包里提供了一个类`AtomicStampedReference`来解决ABA问题。
  - `AtomicStampedReference` 对象包含两个值：一个对象引用和一个版本号。在 CAS 操作中，它不仅比较对象的引用，还比较版本号。如果对象的引用和版本号都匹配，则更新操作成功；如果只有对象的引用匹配，但版本号不匹配，则更新操作失败，表明变量已经被其他线程更新过。

### 死锁

#### 互斥

- 在一段时间内某资源只能由一个执行实体使用

#### 不可剥夺

- 不能被剥夺，只能使用完自己释放
- 破坏不可剥夺，如果获取不到下一步资源，主动释放之前获取的资源

#### 请求与保持

- 一次性分配所有的资源
- 超时释放资源

#### 环路等待

- 控制资源的请求顺序，尽量防止出现环路等待

### 程序计数器为什么是私有的

程序计数器主要有下面两个作用：

> 1. 节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理
> 2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来时能够知道该线程上次运行到哪儿了

所以，程序计数器私有主要是为了**`线程切换后能恢复到正确的执行位置`**。

### 虚拟机栈和本地方法栈为什么是私有的

> - **虚拟机栈**：每个 Java 方法在执行的同时会创建一个 `栈帧` 用于存储 `局部变量表`、`操作数栈`、`常量池引用` 等信息。从方法调用直至执行完成的过程，就对应着一个 `栈帧` 在 Java 虚拟机栈中 `入栈` 和 `出栈` 的过程。
> - **本地方法栈**：和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 `Native` 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

为了**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的。

### 安全点是什么，如果一段代码怎么走到安全点会怎样？

安全点是程序执行的一个点，在该点上，所有的内存引用都已经稳定，这意味着在该点之后，程序不会修改任何内存引用。安全点通常用于操作系统和数据库管理系统中的检查点操作，以确保数据的一致性和持久性。

在多线程环境中，线程可能会同时访问和修改内存中的数据。为了确保数据的一致性，操作系统和数据库管理系统需要定期将内存中的数据写入磁盘，这个过程称为检查点操作。在进行检查点操作时，需要保证所有线程都已经稳定，即它们不会在检查点操作期间修改内存中的数据。安全点就是这样一个稳定点，所有线程都已经完成了它们的操作，不会影响检查点操作的结果。

如果一段代码进入不了安全点，可能会导致以下问题：

1. **数据不一致**：如果检查点操作在代码不稳定时执行，可能会导致数据不一致，因为线程可能在检查点操作期间修改了内存中的数据。
2. **检查点失败**：如果检查点操作在代码不稳定时执行，可能会导致检查点操作失败，因为无法保证所有线程都已经稳定。
3. **性能问题**：如果检查点操作频繁执行，可能会导致性能问题，因为线程需要在每次检查点操作前稳定。

为了确保安全点，操作系统和数据库管理系统通常会提供机制来检测和等待所有线程稳定。例如，在某些数据库管理系统中，系统会在安全点之前等待所有线程完成它们的操作，确保在检查点操作期间不会发生数据不一致的问题。

## 三大特性以及 JMM 如何解决

### JMM java 内存模型

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233459722.png" alt="image-20250613233459722" style="zoom:50%;" />

> - java 虚拟机定义的一种规范，屏蔽硬件与操作系统的内存访问差异，实现各个平台统一的访问效果
> - 规定所有的变量都是存在 `主内存` 当中，每个线程都有自己的 `工作内存`
> - 线程的 `工作内存` 保存了被该线程使用的变量的 `主内存副本`，线程对变量的所有操作都必须在 `工作内存` 中进行，而不能直接操作操作 `主内存`。并且每个线程不能访问其他线程的 `工作内存`

### 三大特性

#### 原子性（分时复用引起）

> 一组操作，要么全部执行成功，要么全部失败

举个简单的例子，看下面这段代码：

```java
int i = 1;

// 线程1执行
i += 1;

// 线程2执行
i += 1;
```

这里需要注意的是：`i += 1`需要三条 CPU 指令

1. 将变量 i 从内存读取到 CPU寄存器；
2. 在CPU寄存器中执行 i + 1 操作；
3. 将最后的结果i写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。

由于CPU分时复用（线程切换）的存在，线程1执行了第一条指令后，就切换到线程2执行，假如线程2执行了这三条指令后，再切换会线程1执行后续两条指令，将造成最后写到内存中的i值是2而不是3。

#### 可见性（JMM工作内存引起）

> 可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值
>
> - 在多线程中，由于线程对 `共享变量` 的操作都是线程拷贝到各自的 `工作内存` 进行操作后才写回到 `主内存` 中的
>
>   - 这就可能存在一个 `线程A` 修改了共享变量 `i` 的值，还未写回 `主内存` 时，另外一个 `线程B` 又对主内存中同一个共享变量 `i` 进行操作
>   - 但此时 `A` 线程 `工作内存` 中共享变量 ` i` 对线程 `B` 来说并不可见，这种 `工作内存` 与 `主内存` 同步延迟现象就造成了可见性问题。
> - 另外 `指令重排` 以及 `编译器优化` 也可能导致可见性问题

#### 有序性（重排序引起）

> - 有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，这样的理解如果是放在单线程环境下没有问题，毕竟对于单线程而言确实如此，代码由编码的顺序从上往下执行，就算发生指令重排序，由于所有硬件优化的前提都是必须遵守 as-if-serial 语义，所以不管怎么排序，都不会且不能影响单线程程序的执行结果，我们将这称之为有序执行。
> - 反之，对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象，重排后的指令与原指令的顺序未必一致。要明白的是，在 Java 程序中，倘若在本线程内，所有操作都视为有序行为，如果是多线程环境下，一个线程中观察另外一个线程，所有操作都是无序的，前半句指的是单线程内保证串行语义执行的一致性，后半句则指指令重排现象和工作内存与主内存同步延迟现象。

##### 编译器优化指令重排

```java
int a = 0;
int b = 0;

//线程A                   线程B
代码1：int x = a;         代码3：int y = b;
代码2：b = 1;             代码4：a = 2;
```

两个线程同时执行，从程序的执行上来看由于并行执行的原因最终的结果 x = 0;y=0; 本质上是不会出现 x = 2;y = 1; 这种结果，但是实际上来说这种情况是有概率出现的，因为编译器一般会对一些代码前后不影响、耦合度为 0 的代码行进行编译器优化的指令重排，假设此时编译器对这段代码指令重排优化之后，可能会出现如下情况：

```java
//线程A                   线程B
代码2：b = 1;         代码4：a = 2;
代码1：int x = a;     代码3：int y = b;         
```

这种情况下再结合之前的线程安全问题一起理解，那么就可能出现 x = 2;y = 1; 这种结果，这也就说明在多线程环境下，由于编译器会对代码做指令重排的优化的操作（因为一般代码都是由上往下执行，指令重排是 OS 对单线程运行的优化），最终导致在多线程环境下时多个线程使用变量能否保证一致性是无法确定的。

> PS：编译器重排的基础是代码不存在依赖性时才会进行的，而依赖性可分为两种：
>
> - 数据依赖
>
>   - `int a = 1;int b = a;`
> - 控制依赖
>
>   - `boolean f = ture; if(f){sout("123");}`

##### 处理器指令重排

**对于** **`单线程`** **而已指令重排几乎不会带来任何影响，毕竟重排的前提是保证** **`串行语义执行的一致性`** **，但对于多线程环境而已，指令重排就可能导致严重的程序轮序执行问题。**

```java
public class Singleton {
    private static Singleton singleton;
    private Singleton() {

    }
    public static Singleton getInstance() {
        if (singleton == null) {//1
            synchronized {//2
                if (singleton == null) {//3
                    singleton = new Singleton();//4             
                }
            }
        }
    }
}
```

> 这样实现的单例其实是不安全的，执行语句 4 时，实际包含 3 个步骤：
>
> - **给 singleton 分配内存**
> - **在内存中初始化 singleton 对象**
> - 将内存地址赋给 singleton 变量（这时 singleton 变量就不为 null 了）

因为编译器会进行 `指令重排`，如果指令重排之后第 `c` 步先于第 `b` 步执行，那可能会发生如下的错误：

1. `线程1` 执行语句 4，这时 `线程1` 的 `工作内存` 的 `singleton` 变量不为 `null`，可能会立即写回到主存中，也可能迟点再写回到主存中
2. 然后这时线程的时间分片又刚好用完了，就会切换到 `线程2`，如果 `线程1` 的 `singleton` 已经写回到主存中，那么这时 `线程2` 执行语句 1 就为 false，然后返回 `single` 对象，但实际上第 2 步还没执行，即 `对象还没初始化`，使用该对象会导致程序报错。

### JMM 如何解决

JMM本质上可以理解为，**Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法**。具体来说，这些方法包括：

- **volatile、synchronized 和 final 三个关键字**
- **Happens-Before 规则**

#### JMM 中的 happens-before 原则

> 假如在多线程开发过程中我们都需要通过加锁或者 volatile 来解决这些问题的话那么编写程序的时候会非常麻烦，而且加锁其实本质上是让多线程的并行执行变为了串行执行，这样会大大的影响程序的性能，那么其实真的需要嘛？
>
> 不一定需要，因为在 JMM 中还为我们提供了 happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据。
>
> 它真正要表达的是：**前面一个操作的结果对后续操作是可见的**。

happens-before 原则内容如下：

##### 1. 单一线程原则

这条规则是指在 `一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作`。

简单来说就是：一个线程中的每个操作，都`happens-before`该线程中的任意后续操作。

##### 2. 管程中锁的规则

这条规则是指 `对一个锁的解锁 Happens-Before 于后续对这个锁的加锁`。

要理解这个规则，就首先要了解“管程指的是什么”。**管程**是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。

管程中的锁在 Java 里是隐式实现的，例如下面的代码，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。

```java
synchronized (this) { // 此处自动加锁
  // x 是共享变量, 初始值 =10
  if (this.x < 12) {
    this.x = 12; 
  }  
} // 此处自动解锁
```

可以这样理解：假设 x 的初始值是 10，线程 A 执行完代码块后 x 的值会变成 12（执行完自动释放锁），线程 B 进入代码块时，能够看到线程 A 对 x 的写操作，也就是线程 B 能够看到 x==12。这个也是符合我们直觉的，应该不难理解。

##### 3. volatile 变量规则

这条规则是指 `对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作`。

简单的理解就是，**volatile 变量在每次被线程访问时，都强迫从主内存中读该变量的值，而当该变量发生变化时，又会强迫将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值**。

##### 4. 传递性

这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。

我们将规则 4 的传递性应用到我们的例子中，会发生什么呢？可以看下面这幅图：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233526997.png" alt="image-20250613233526997" style="zoom:40%;" />

从图中，我们可以看到：

> 1. “x=42” Happens-Before 写变量 “v=true” ，这是规则 1 的内容；
> 2. 写变量“v=true” Happens-Before 读变量 “v=true”，这是规则 2 的内容 。

再根据这个传递性规则，我们得到结果：“x=42” Happens-Before 读变量“v=true”。这意味着什么呢？

如果线程 B 读到了“v=true”，那么线程 A 设置的“x=42”对线程 B 是可见的。也就是说，线程 B 能看到 “x == 42” ，有没有一种恍然大悟的感觉？这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大，1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性的，这个在后面的内容中会详细介绍。

##### 5. 线程 start() 规则

这条是关于线程启动的。它是指 `主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作`。

换句话说就是，如果线程 A 调用线程 B 的 start() 方法（即在线程 A 中启动线程 B），那么该 start() 操作 Happens-Before 于线程 B 中的任意操作。具体可参考下面示例代码。

```java
Thread B = new Thread(()->{
  // 主线程调用 B.start() 之前
  // 所有对共享变量的修改，此处皆可见
  // 此例中，var==77
});
// 此处对共享变量 var 修改
var = 77;
// 主线程启动子线程
B.start();
```

##### 6. 线程 join() 规则

这条是关于线程等待的。它是指 `主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作`。当然所谓的“看到”，指的是对**共享变量**的操作。

换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。具体可参考下面示例代码。

```java
Thread B = new Thread(()->{
  // 此处对共享变量 var 修改
  var = 66;
});
// 例如此处对共享变量修改，
// 则这个修改结果对线程 B 可见
// 主线程启动子线程
B.start();
B.join()
// 子线程所有对共享变量的修改
// 在主线程调用 B.join() 之后皆可见
// 此例中，var==66
```

##### 7. 线程中断规则

对 `线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生`，可以通过 Thread.interrupted()方法检测线程是否中断。

##### 8. 对象终结规则

`对象的构造函数执行，结束先于finalize()方法`。

happens-before 原则无需添加任何手段来保证，这是由 JMM 规定的，Java 程序默认遵守如上八条原则。

> 下面我们再通过之前的案例重新认识这八条原则是如何判断线程是否会出现安全问题：

```java
int a = 0;
boolean f = false;
public void methodA(){
    a = 1;
    f = true;
}
public void methodB(){
    if(f) int i = a + 1；
}
```

同样的道理，存在两条线程 A 和 B，线程 A 调用实例对象的 methodA()方法，而线程 B 调用实例对象的 methodB()方法，线程 A 先启动而线程 B 后启动，那么线程 B 读取到的 i 值是多少呢？

现在依据 8 条原则，由于存在两条线程同时调用，因此程序次序原则不合适。methodA()方法和 methodB()方法都没有使用同步手段，锁规则也不合适。没有使用 volatile 关键字，volatile 变量原则不适应。线程启动规则、线程终止规则、线程中断规则、对象终结规则、传递性和本次测试案例也不合适。线程 A 和线程 B 的启动时间虽然有先后，但线程 B 执行结果却是不确定，也是说上述代码没有适合 8 条原则中的任意一条，也没有使用任何同步手段，所以上述的操作是线程不安全的，因此线程 B 读取的值自然也是不确定的。

修复这个问题的方式很简单，要么给 methodA()方法和 methodB()方法添加同步手段（加锁）或者给共享变量添加 volatile 关键字修饰，保证该变量在被一个线程修改后总对其他线程可见。

## 线程间协作（同步）

### join() 稍等，等我结束你再开始

> 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。

对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。

```java
public class JoinExample {

    private class A extends Thread {
        @Override
        public void run() {
            System.out.println("A");
        }
    }

    private class B extends Thread {

        private A a;

        B(A a) {
            this.a = a;
        }

        @Override
        public void run() {
            try {
                a.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("B");
        }
    }

    public void test() {
        A a = new A();
        B b = new B(a);
        b.start();
        a.start();
    }
}
public static void main(String[] args) {
    JoinExample example = new JoinExample();
    example.test();
}
A
B
```

### Object的wait()/notify()/notifyAll()

> - 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。
> - 它们都属于 Object 的一部分，而不属于 Thread。
> - 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。

### Condition的await()/signal()/signalAll()

> java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。

```java
public class AwaitSignalExample {
    private Lock lock = new ReentrantLock();
    private Condition condition = lock.newCondition();

    public void before() {
        lock.lock();
        try {
            System.out.println("before");
            condition.signalAll();
        } finally {
            lock.unlock();
        }
    }

    public void after() {
        lock.lock();
        try {
            condition.await();
            System.out.println("after");
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }
}
public static void main(String[] args) {
    ExecutorService executorService = Executors.newCachedThreadPool();
    AwaitSignalExample example = new AwaitSignalExample();
    executorService.execute(() -> example.after());
    executorService.execute(() -> example.before());
}
before
after
```

### LockSupport 的park()/unpark()

```java
class MyThread extends Thread {
    private Object object;

    public MyThread(Object object) {
        this.object = object;
    }

    public void run() {
        System.out.println("before unpark");
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 获取blocker
        System.out.println("Blocker info " + LockSupport.getBlocker((Thread) object));
        // 释放许可
        LockSupport.unpark((Thread) object);
        // 休眠500ms，保证先执行park中的setBlocker(t, null);
        try {
            Thread.sleep(500);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 再次获取blocker
        System.out.println("Blocker info " + LockSupport.getBlocker((Thread) object));

        System.out.println("after unpark");
    }
}

public class test {
    public static void main(String[] args) {
        MyThread myThread = new MyThread(Thread.currentThread());
        myThread.start();
        System.out.println("before park");
        // 获取许可
        LockSupport.park("ParkAndUnparkDemo");
        System.out.println("after park");
    }
}
```

1. wait():使一个线程处于等待(阻塞)状态，并且释放所持有的对象的锁;
2. sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 InterruptedException 异常;
3. notify():唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一 个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关;
4. notityAll():唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态;

## 线程安全的实现方法

### 阻塞同步

`synchronized` 和 `ReentrantLock` 。

> 互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。
>
> 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。

### 非阻塞同步

**CAS 和 AtomicInteger**

> 随着硬件指令集的发展，我们可以使用**基于冲突检测的乐观并发策略**: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，**否则采取补偿措施(不断地重试，直到成功为止)** 。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。

### 无同步方案

>  要保证线程安全，并不是一定就要进行同步。如果一个方法**本来就不涉及共享数据**，那它自然就无须任何同步措施去保证正确性。

#### **栈封闭**

多个线程访问同一个**方法的局部变量**时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。

```java
public class StackClosedExample {
    public void add100() {
        int cnt = 0;
        for (int i = 0; i < 100; i++) {
            cnt++;
        }
        System.out.println(cnt);
    }
}
public static void main(String[] args) {
    StackClosedExample example = new StackClosedExample();
    ExecutorService executorService = Executors.newCachedThreadPool();
    executorService.execute(() -> example.add100());
    executorService.execute(() -> example.add100());
    executorService.shutdown();
}
```

#### **线程本地存储(Thread Local Storage)**

#### **可重入代码(Reentrant Code)**

> 这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。
>
> 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。

## 线程池

### **使用线程池的好处**

> - **降低资源消耗**
>
>   - 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
> - **提高响应速度**
>
>   - 当任务到达时，任务可以不需要的等到线程创建就能立即执行。
> - **提高线程的可管理性**
>
>   - 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 创建线程池

#### JDK 提供的原生线程池 Executors 类

##### newSingleThreadExecutor

###### 特点

- 核心线程数为 1
- 最大线程数也为 1
- 阻塞队列是无界队列 `LinkedBlockingQueue`，可能会导致 OOM

###### **工作流程：**

- 提交任务
- 线程池是否有一个线程在，如果没有，新建线程执行任务
- 如果有，将任务加到阻塞队列
- 当前的唯一线程，从队列取任务，执行完一个，再继续取，一个线程执行任务

##### newFixedThreadPool

###### 特点

- 核心线程数和最大线程数大小一样
- 没有所谓的非空闲时间，即 keepAliveTime 为 0
- 阻塞队列为无界队列 `LinkedBlockingQueue`，可能会导致 OOM

###### **工作流程：**

- 提交任务
- 如果线程数少于核心线程，创建核心线程执行任务
- 如果线程数等于核心线程，把任务添加到 `LinkedBlockingQueue` 阻塞队列
- 如果线程执行完任务，去阻塞队列取任务，继续执行。

##### newCachedThreadPool

###### 特点

- 核心线程数为 0
- 最大线程数为 `Integer.MAX_VALUE`，即无限大，可能会因为无限创建线程，导致 OOM
- 阻塞队列是 `SynchronousQueue`
- 非核心线程空闲存活时间为 60 秒
- 当提交任务的速度大于处理任务的速度时，每次提交一个任务，就必然会创建一个线程。极端情况下会创建过多的线程，耗尽 CPU 和内存资源。由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。
- **适用于执行大量的短时任务，‌并且SynchronousQueue的特性能够有效地支持这种使用场景**
- `SynchronousQueue`的内部容量为0，‌这意味着它不存储任何数据，‌每个put操作必须等待一个对应的take操作，‌反之亦然。‌这种机制确保了线程之间的直接交互，‌避免了数据的中间存储环节，‌从而减少了线程间的竞争和等待时间。‌

###### **工作流程：**

- 提交任务
- 因为没有核心线程，所以任务直接加到 `SynchronousQueue` 队列。
- 判断是否有空闲线程，如果有，就去取出任务执行。
- 如果没有空闲线程，就新建一个线程执行。
- 执行完任务的线程，还可以存活 60 秒，如果在这期间，接到任务，可以继续活下去；否则，被销毁。

##### newScheduledThreadPool

###### 特点

- 最大线程数为 `Integer.MAX_VALUE`，也有 OOM 的风险
- 阻塞队列是 `DelayedWorkQueue`
- keepAliveTime 为 0
- scheduleAtFixedRate() ：按某种速率周期执行
- scheduleWithFixedDelay()：在某个延迟后执行

###### 工作流程：

- 线程从 DelayQueue 中获取已到期的 ScheduledFutureTask（DelayQueue.take()）。到期任务是指 ScheduledFutureTask 的 time 大于等于当前时间。
- 线程执行这个 ScheduledFutureTask。
- 线程修改 ScheduledFutureTask 的 time 变量为下次将要被执行的时间。
- 线程把这个修改 time 之后的 ScheduledFutureTask 放回 DelayQueue 中（DelayQueue.add()）。

#### ThreadPoolExecutor 类创建

##### 核心参数

- corePoolSize

  - 核心线程池的大小
  - 如果核心线程池有空闲位置，这时新的任务就会被核心线程池新建一个线程执行
- maximumPoolSize

  - 线程池能创建最大的线程数量
- keepAliveTime

  - 非核心线程能够空闲的最长时间，超过时间，线程终止
- unit
- workQueue 阻塞队列

  - `ArrayBlockingQueue`：基于数组的先进先出队列，此队列创建时必须指定大小；
  - `LinkedBlockingQueue`：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为 Integer.MAX_VALUE；
  - `SynchronousQueue`：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。
- threadFactory

  - 线程工厂，用来创建线程
- handler

  - 任务拒绝策略，线程数量 `大于` 最大线程数就会采用拒绝处理策略
  - AbortPolicy

    - 丢弃任务并抛出 RejectedExecutionException 异常
  - DiscardPolicy

    - 丢弃任务，但是不抛出异常
  - DiscardOldestPolicy

    - 丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
  - CallerRunsPolicy

    - 由调用线程处理该任务

##### 线程池参数合理配置

- CPU 密集型

  - cpu 核心数 + 1
- IO 密集型

  - CPU 核心数 * 2
- 混合型

### 原理

#### `execute(Runnable command)`

```java
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();
    // 获取当前的工作线程数量是否小于核心线程数
    if (workerCountOf(c) < corePoolSize) {
        // 创建核心线程
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 如果当前线程数大于核心数且线程是运行中并且能够放入队列（未满）
    if (isRunning(c) && workQueue.offer(command)) {
        //二次检查
        int recheck = ctl.get();
        // 如果二次检查时线程不是运行状态则从队列删除任务，将任务执行拒绝策略
        if (! isRunning(recheck) && remove(command))
            reject(command);
        // 如果是运行状态，则检查当前运行的线程数，是否因为异常或其他原因到只数量为0，此时直接将任务执行，发布为非核心线程
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    else if (!addWorker(command, false))
        reject(command);
}
```

#### `addWorker(Runnable firstTask, boolean core)`

我们重点关注`addWorker`这个方法，这个方法主要就是创建了一个`Worker`对象，并将`Worker`对象中的线程启动起来，这个对象是一个 Runnable 的子类。

```java
private final class Worker extends AbstractQueuedSynchronizer implements Runnable {}
```

Worker 对象本身是一个 Runnable 的子类，在创建 Worker 的时候会调用我们传递的线程工厂（ThreadFactory），创建一个新的线程对象，并将本身传递到线程工厂中。ThreadFactory 会根据传递的 Runable 创建一个线程，保存到变量中，Worker 的构造函数如下：

```java
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c); // 拿到线程池的状态

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN && // 如果当前线程状态不是RUNNING，再次做后续判断，查看当前任务是否可以不处理
            ! (rs == SHUTDOWN && // 线程池状态为SHUTDOWN，并且任务为空，并且工作队列不为空
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            int wc = workerCountOf(c); // 获取当前工作线程数
            if (wc >= CAPACITY || // 判断工作线程是否大于最大值
                wc >= (core ? corePoolSize : maximumPoolSize)) //  如果是核心线程,是否大于设置的corePoolSize
                return false;
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs) // 基于新获取的ctl拿到线程池状态,判断和之前的rs状态是否一致
                continue retry; // 说明并发操作导致线程池状态变化,需要重新判断状态
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        w = new Worker(firstTask); // new Worker构建工作线程，将任务扔到了Worker中
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock(); // 加锁
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get()); // 拿到线程池的状态

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) { // 如果线程池状态为SHUTDOWN并且传入的任务为null
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    workers.add(w); // 将构建好的worker对象添加到workers
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) { // 只要添加工作线程成功，启动线程
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w); // 如果启动工作线程失败，做的补救操作
    }
    return workerStarted;
}
```

1. 获取当前线程池的状态，如果是STOP，TIDYING,TERMINATED状态的话，则会返回false，如果现在状态是SHUTDOWN，但是firstTask不为空或者workQueue为空的话，那么直接返回false。
2. 通过自旋的方式，判断要添加的Worker是否是corePool，如果是的话，那么则判断当前的workerCount是否大于corePoolsize，否则则判断是否大于maximumPoolSize，如果满足的话，说明workerCount超出了线程池大小，直接返回false。如果小于的话，那么判断是否成功将WorkerCount通过CAS操作增加1，如果增加成功的话。则进行到第3步，否则则判断当前线程池的状态，如果现在获取到的状态与进入自旋的状态不一致的话，那么则通过`continue retry`重新进行状态的判断。
3. 如果满足了的话，那么则创建一个新的Worker对象，然后获取线程池的重入锁后，判断当前线程池的状态，如果当前线程池状态为STOP,TIDYING,TERMINATED的话，那么调用decrementWorkerCount将workerCount减一，然后调用tryTerminate停止线程池，并且返回false。
4. 如果状态满足的话，那么则在workers中将新创建的worker添加，并且重新计算largestPoolSize，然后启动Worker中的线程开始执行任务。
5. 重新Check一次当前线程池的状态，如果处于STOP状态的话，那么就调用interrupt方法中断线程执行。

#### `runWorker(Worker w)`

在 worker 的 run 方法中重点调用了`runWorker`方法。我们重点分析`runWorker`方法的源码逻辑：

```java
final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    //获取提交的任务
    Runnable task = w.firstTask;
    try {
        //死循环  如果提交的任务不为空 或者从阻塞队列中取值，没有任务就阻塞等待任务
        while (task != null || (task = getTask()) != null) {
            w.lock();
            try {
                //任务开始前，调用beforeExecute钩子函数
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    //开始执行任务  直接调用提交任务的run方法
                    task.run();
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    //任务执行后 调用钩子函数afterExecute
                    afterExecute(task, thrown);
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
```

### 线程池中非核心线程是如何回收的

```java
final void runWorker(Worker w) {
    Runnable task = w.firstTask; // 获取提交的任务
    w.firstTask = null;
    try {
        // 死循环  如果提交的任务不为空 或者从阻塞队列中取值，没有任务就阻塞等待任务
        // 获取任务的第一个方式,就是执行execute submit时,传入的任务直接处理
        // 获取任务的第二个方式,就是从工作队列中获取任务执行
        while (task != null || (task = getTask()) != null) {
            ......
        }
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}

```

里面是一个while循环，循环判断任务是否为空，若不为空，执行任务；若取不到任务，或发生异常，退出循环，执行`processWorkerExit(w, completedAbruptly);` 在这个方法里把工作线程移除掉。

取任务的来源有两个，一个是`firstTask`，这个是工作线程第一次跑的时候执行的任务，最多只能执行一次，后面得从`getTask()`方法里取任务。

看来，`getTask()`是关键，在不考虑异常的场景下，返回null，就表示退出循环，结束线程。下一步，就得看看，什么情况下`getTask()`会返回null。

#### getTask() 返回null

```java
private Runnable getTask() {
    boolean timedOut = false; // 表示当前线程获取任务是否超时； 默认 false, 未超时

    for (;;) { // 自旋
        int c = ctl.get();
        int rs = runStateOf(c);  // 获取线程池当前运行状态

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) { // 线程池的状态已经是`STOP`，`TIDYING`, `TERMINATED`，或者是`SHUTDOWN`且工作队列为空
            decrementWorkerCount();
            return null;
        }

        int wc = workerCountOf(c); // 获取线程池中的线程数量

        /**
             * true: 表示当前这个线程 获取 task 时 是支持超时机制的
             * false: 表示当前线程不支持超时机制。 核心线程数量内的线程会使用 queue.take();
             * allowCoreThreadTimeOut == ture 表示核心线程数量内的线程，可以被回收； false不可以被回收
             * wc > corePoolSize :  当前线程池中的数量时大于核心线程数的。
             */
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

        /**
             * 条件1:(wc > maximumPoolSize || (timed && timedOut)： 为ture 不代表线程一定返回null
             *    1.1 wc > maximumPoolSize ： 可能外部线程将线程池最大线程数设置为比初始化时的要小
             *    1.2  timed && timedOut ：当前线程使用poll方式获取task。 上一次循环时， 使用 pool方式获取任务时，超时了。
             * 条件二:   (wc > 1 || workQueue.isEmpty())
             *    2.1: wc > 1： 说明当前线程池中，还有其他线程；当前线程可以直接回收，返回null。
             *    2.2: 说明当前任务队列已经为null。 最后一个线程也可以放心退出
             */
        if ((wc > maximumPoolSize || (timed && timedOut))
            && (wc > 1 || workQueue.isEmpty())) {
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue; // CAS失败，就继续；再次自旋时，timed可能为 false
        }

        try {
            Runnable r = timed ?
            workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
            workQueue.take(); // 获取任务的逻辑
            if (r != null)
                return r;
            timedOut = true; // 说明当前线程超时了。
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}
```

##### 总结

`ThreadPoolExecutor`回收工作线程，一旦线程`getTask()`返回null，就会跳出`while`循环，执行`processWorkerExit(w, completedAbruptly)`被回收。

分两种场景。

1. 未调用`shutdown()` ，RUNNING状态下全部任务执行完成的场景

    1. 线程数量大于`corePoolSize`，线程超时阻塞，超时唤醒后`CAS`减少工作线程数，如果`CAS`成功，返回null，线程回收。否则进入下一次循环。当工作者线程数量小于等于`corePoolSize`，就可以一直阻塞了。

2. 调用`shutdown()` ，全部任务执行完成的场景

    `shutdown()` 会向所有线程发出`中断信号`，这时有两种可能。

    1. 所有线程都在阻塞

        1. `中断唤醒`，进入循环，都符合第一个if判断条件，都返回null，所有线程回收。
    2. 任务还没有完全执行完

        1. 至少会有一条线程被回收。在`processWorkerExit(Worker w, boolean completedAbruptly)`方法里会调用`tryTerminate()`，向任意空闲线程发出中断信号。所有被阻塞的线程，最终都会被一个个唤醒，回收。

### 获取任务的时候，线程是如何阻塞的

其实现在阻塞主要是通过`ArrayBlockingQueue`实现的

```java
/** 提供独占锁机制，来保护竞争的资源 */
final ReentrantLock lock;

/** 表示"锁的非空条件"。当某线程想从队列中获取数据的时候，而此时队列中的数据为空，
则该线程通过notEmpty.await()方法进行等待；当其他线程向队列中插入元素之后，
就调用notEmpty.signal()方法进行唤醒之前等待的线程 */
private final Condition notEmpty;

/** 表示“锁满的条件“。当某个线程向队列中插入元素，而此时队列已满时，该线程等待，
即阻塞通过notFull.wait()方法；其他线程从队列中取出元素之后，就唤醒该等待的线程，
这个线程调用notFull.signal()方法 */
private final Condition notFull;
```

详见 ArrayBlockingQueue

### **提交到线程池里的任务，是如何知道直接结束，如何能拿到任务结果的？**

详见 futureTask

## volatile

### 作用

- 保证可见性
- 禁止指令重排序

### 原理

- 对 `volatile` 修饰的变量

  - 写操作 `之后`，编译器会插入一个 `写屏障`
  - 读操作 `之前`，编译器会插入一个 `读屏障`
- happens-before 原则，重排序时不能把后面的指令重排序到 `内存屏障` 之前的位置
- 写入动作也会引起别的 CPU 或者别的内核无效化其 Cache，相当于让新写入的值对别的线程可见

### volatile 和 synchronized

synchronized 关键字和 volatile 关键字是两个 `互补` 的存在，而不是对立的存在！

- `volatile` 只能修饰变量，`synchronized` 还可以修饰方法以及代码块
- `volatile` 只能保证数据的可见性，不能保证原子性，`synchronized` 关键字两者都能保证
- `volatile` 关键字是线程同步的 `轻量级` 实现，所以 volatile `性能` 肯定比 synchronized 关键字要好
- `volatile` 关键字主要用于解决变量在多个线程之间的 `可见性`，而 `synchronized` 关键字解决的是多个线程之间 `访问资源` 的同步性

### 适用场景

- 一次性安全发布

  - 双重检查锁定
- 读多写少

  - `volatile` 修饰变量，读时无锁，写时加 `synchronized`

## synchronized

### 使用方式

- 修饰实例方法

  - `synchronized void method() {}`
  - **对象实例锁**
- 修饰静态方法

  - `synchronized void staic method() {}`
  - **class 锁**
- 修饰代码块

  - `synchronized(this) {}`
  - **对象实例锁**

### 底层原理

#### monitorenter、monitorexit、ACC_SYNCHRONIZED

##### 同步代码块

- 代码块前形成 `monitorenter` 字节码指令
- 代码块后形成 `monitorexit` 字节码指令
- 执行 `monitorenter` 指令时，首先尝试获取对象的锁，如果这个锁没有被锁定或者当前线程已经拥有了那个对象的锁，锁的计数器就 +1
- 执行 `monitorexit` 指令时会将锁的计数器减 1，当减为 0 的时候就释放锁
- 如果获取对象锁一直失败，那当前线程就要阻塞等待，直到对象锁被另一个线程释放为止

##### 同步方法

- JVM 可以从方法常量池的方法表结构中的 `ACC_SYNCHRONIZED` 访问标志得知一个方法是否声明为同步方法
- 当方法调用的时，调用指令会检查方法的 `ACC_SYNCHRONIZED` 访问标志是否被设置
- 如果设置了，执行线程就要求先持有 `monitor` 对象，然后才能执行方法
- 最后当方法执行完（无论是正常完成还是非正常完成）时释放 `monitor` 对象

#### monitor监视器

monitor是什么呢？操作系统的管程（monitors）是概念原理，ObjectMonitor是它的原理实现。

在Java虚拟机（HotSpot）中，Monitor（管程）是由ObjectMonitor实现的，其主要数据结构如下：

```c++
 ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 记录个数
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL;  // 处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ;  // 处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
  }
```

ObjectMonitor中几个关键字段的含义如图所示：

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233626349.png" alt="image-20250613233626349" style="zoom:80%;" />

#### Java Monitor 的工作机理

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233639304.png" alt="image-20250613233639304" style="zoom:70%;" />

- 想要获取monitor的线程,首先会进入_EntryList队列。
- 当某个线程获取到对象的monitor后,进入Owner区域，设置为当前线程,同时计数器count加1。
- 如果线程调用了wait()方法，则会进入WaitSet队列。它会释放monitor锁，即将owner赋值为null,count自减1,进入WaitSet队列阻塞等待。
- 如果其他线程调用 notify() / notifyAll() ，会唤醒WaitSet中的某个线程，该线程再次尝试获取monitor锁，成功即进入Owner区域。
- 同步方法执行完毕了，线程退出临界区，会将monitor的owner设为null，并释放监视锁。

#### 对象与monitor关联

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233658847.png" alt="image-20250613233658847" style="zoom:70%;" />

- 在HotSpot虚拟机中,对象在内存中存储的布局可以分为3块区域：对象头（Header），实例数据（Instance Data）和对象填充（Padding）。
- 对象头主要包括两部分数据：Mark Word（标记字段）、Class Pointer（类型指针）。
- Mark Word 是用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等。
- 重量级锁，指向互斥量的指针。其实synchronized是重量级锁，也就是说Synchronized的对象锁，Mark Word锁标识位为10，其中指针指向的是Monitor对象的起始地址。

### 锁膨胀

#### 无锁态

- 延迟 4s，偏向锁

  - 当我们在 Java 程序中 new 一个对象时，会默认启动匿名偏向锁，但是值得注意的是有个小细节，偏向锁的启动有个延时，默认是 4 秒
  - JVM 启动四秒之后再开启匿名偏向锁，在 JVM 启动时前四秒内 new 的对象不会启动匿名偏向锁
  - JVM 虚拟机自己有一些默认启动的线程，里面有好多 sync 代码，这些 sync 代码启动时就知道肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作，效率较低
- `markword` 中的 `threadId` 为空，相当于无锁

#### 偏向锁

##### 引入目的

- 在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得
- 因此为了减少同一线程获取锁(会涉及到一些 CAS 操作,耗时)的代价而引入偏向锁

##### 核心思想

- 如果一个线程获得了锁，那么锁就进入偏向模式，此时 `Mark Word` 的结构也变为偏向锁结构
- 当这个线程再次请求锁时，无需再做任何同步操作，这样就省去了大量有关锁申请的操作，从而也就提升程序的性能

##### 执行流程

- `线程1` 获取锁对象时，会在 java `对象头` 中记录 `threadId`（偏向锁不会主动释放）
- 以后 `线程1` 再获取锁时，比较 `当前线程id` 与 java `对象头` 的 `threadId` 是否一致（无需 CAS 和加锁）
- 如果不一致，查看 java `对象头` 中的 `线程1` 是否 `存活`，如果不存话，重置为无锁状态，`重新竞争`
- 如果存活，查找 `线程1` 的 `栈帧` 信息，看看是否还需要持有这个锁对象，如果需要，`升级` 轻量级锁

#### 轻量级锁

##### 引入目的

- 竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景。
- 因为阻塞线程需要 CPU 从 `用户态` 转到 `内核态`，代价较大，如果刚刚阻塞不久这个锁就被释放了，那这个代价就有点得不偿失了
- 因此这个时候就干脆不阻塞这个线程，让它 `自旋` 这等待锁释放

自旋次数有 `限制`，会升级重量级锁

###### 自适应自旋锁

线程空循环等待的自旋次数并非是固定的，而是会动态着根据实际情况来改变自旋等待的次数。

#### 重量级锁

**`锁可以升级不可以降级，但是偏向锁状态可以被重置为无锁状态`** **。**

### thread 等待唤醒机制

- `notify`/`notifyAll` 和 `wait` 方法必须在 `synchronized` 代码块或者方法中

  - 调用方法前，必须拿到 `monitor` 对象
  - `monitor` 存在对象头 `MarkWord`(monitor 引用指针)
  - `synchronized` 可以获取 `monitor`，所以必须在 `synchronized` 中

**注意**

- `sleep()` 只是线程休眠，不释放锁
- `notify` 不会立马释放 `monitor` 锁，而是等到 `synchronized` 执行结束

### Synchronized 与 ReentrantLock

#### 为什么重复造轮子

##### 能够响应中断

- `synchronized` 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。
- 但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。这样就破坏了 `不可抢占条件` 了

##### 支持超时

- 如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。这样也能破坏 `不可抢占条件`

##### 非阻塞地获取锁

- 如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。这样也能破坏 `不可抢占条件`

#### 区别

- `ReentrantLock` 实现了 Lock 接口，`synchronized` 是系统关键字
- `ReentrantLock` 需要手动指定锁范围，`synchronized` 支持同步块、同步方法
- 都具有可重入性
- 默认都是 `非公平` 锁，`ReentrantLock` 还支持公平模式，但性能会急剧下降
- `ReentrantLock` 需要显示的获取锁、释放锁
- `ReentrantLock` 可以同时绑定多个 `Condition` 条件对象

### JVM锁的优化

- 锁的粗化
- 锁消除

  - 局部变量，并且不会被其他线程所使用

> 通过运行时**JIT编译器的逃逸分析**来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配 (同时还可以减少Heap上的垃圾收集开销)

- 自适应自旋锁

## atomic

所谓原子类说简单点就是具有原子/原子操作特征的类。

### 原理

> - CAS + volatile 保证原子性

AtomicInteger 类的部分源码：

```java
public class AtomicInteger extends Number implements java.io.Serializable {
    private static final long serialVersionUID = 6214790243416807050 L;
    // setup to use Unsafe.compareAndSwapInt for updates
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;
    static {
        try {
            valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));
        } catch(Exception ex) {
            throw new Error(ex);
        }
    }
    private volatile int value;
    public native long objectFieldOffset(Field var1);
}
```

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

## LongAdder

LongAdder 是 Striped64 的子类，Striped64 是 Number 子类

```java
public class LongAdder extends Striped64 {}
abstract class Striped64 extends Number {}

base: 类似于AtomicLong中全局的value值。在没有竞争情况下数据直接累加到base上，或者cells扩容时,也需要将数据写入到base上
collide: 表示扩容意向，false一定不会扩容，true可能会扩容
cellsBusy: 初始化cells或者扩容cells需要获取锁，0表示无锁状态，1表示其他线程已经持有了锁
casCellsBusy: 通过CAS操作修改cellsBusy的值， CAS成功代表获取锁，返回true
NCPU: 当前计算机CPU数量，Cell数组扩容时会使用到
getProbe(): 获取当前线程的hash值
advanceProbe(): 重置当前线程的hash值

==============================================================
abstract class Striped64 extends Number {

    // CPU数量，即Cells数组的最大长度
    static final int NCPU = Runtime.getRuntime().availableProcessors();

    // 存放Cell的hash表，大小为2的幂
    // 这里的Cell是Striped64的静态内部类，懒惰初始化
    transient volatile Cell[] cells;

    /*
    1.在开始没有竞争的情况下，将累加值累加到base；
    2.在cells初始化的过程中，cells处于不可用的状态，这时候也会尝试将通过cas操作值累加到base
    */
    transient volatile long base;

    /*
    cellsBusy，它有两个值0或1，它的作用是当要修改cells数组时加锁,
    防止多线程同时修改cells数组(也称cells表)，0为无锁，1位加锁，加锁的状况有三种:
    (1)cells数组初始化的时候；
    (2)cells数组扩容的时候；
    (3)如果cells数组中某个元素为null，给这个位置创建新的Cell对象的时候；
    */
    transient volatile int cellsBusy;
}
```

### LongAdder为什么快？

- LongAdder基本思路就是分散热点，将value分散到一个Cell数组中，不同线程会命中数组的不同槽位中，各个线程只对自己槽位的value进行CAS操作，这样热点就被分散了，冲突概率小了
- sum()会将所有Cell数组中的value和base累加作为返回值，核心思想就是将之前AtomicLong一个value的更新压力分散到多个value中去，从而降级更新热点
- 内部有一个base+一个Cell[ ]数组

  - base变量：低并发，直接累加到该变量上
  - Cell[ ]数组：高并发，累加到各个线程自己的槽Cell[i]中

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233729105.png" alt="image-20250613233729105" style="zoom:70%;" />

- LongAdder在无竞争的情况下，跟AtomicLong一样， 对同一个base进行操作
- 当出现竞争时，则采用化整为零分散热点的做法，用空间换时间，用一个数组cells，将一个value拆分进这个数组cells
- 多个线程需要同时对value进行操作的时候，可以对线程id进行hash得到hash值，再根据hash值映射到这个数组cells的某个下标，再对该下标所对应的值进行自增操作
- 当所有线程操作完毕，将数组cells的所有值和base都加起来作为最终结果

### LongAdder之缓存行伪共享

#### Striped64中静态内部类Cell源码

```java
abstract class Striped64 extends Number {
    // 防止缓存行伪共享 注解
    @sun.misc.Contended
    static final class Cell { // Cell 即为累加单元
        // 保存累加结果
        volatile long value;
        // 构造方法为value赋初始值
        Cell(long x) { value = x; }
        
        // 最重要的方法, 用来 cas 方式进行累加, prev 表示旧值, next 表示新值
        final boolean cas(long prev, long next) {
          return UNSAFE.compareAndSwapLong(this, valueOffset, prev, next);
        }
        // 省略其他代码
    }
}
```

#### CPU缓存结构

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233753026.png" alt="image-20250613233753026" style="zoom:60%;" />

#### **分析**

```java
static final class Cell { // 对象头16字节
    volatile long value; // long 8字节
 }
```

因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 对象为 24 字节（16 字节的对象头和 8 字节的 long 类型的 value），缓存行一般存64字节，所以可以存下 2 个 Cell 对象（Cell[0]、Cell[1]）。

这样问题来了，假设：

- Core-0 要修改 Cell[0]
- Core-1 要修改 Cell[1]

1. 无论谁修改成功，都会导致对方 Core 的缓存行失效

    1. 比如 Core-0 中 Cell[0]=6000, Cell[1]=8000 只累加Cell[0]，累加后Core-0 中 Cell[0]=6001, Cell[1]=8000
    2. 虽然Core-0 中 Cell[1]=8000没累加，但是 Cell[0]、 Cell[1]是在同一个缓存行里，所以Core-1的缓存行需要整行失效，重新从头读取Cell[0]=6001，Cell[1]=8000，这就出现了伪共享问题，从而影响效率

2. @sun.misc.Contended 就是用来解决伪共享，它的原理是在使用此注解的对象或字段的前后各增加 128 字节大小的padding（空白，用来占位），从而让 CPU 将对象预读至缓存时，占用不同的缓存行（例如：让Cell[0]、Cell[1]占用不同的缓存行，占用Cell[0]变了不会影响Cell[1]），这样，不会造成对方缓存行的失效

伪共享（False Sharing）是指多个线程同时读写同一个缓存行的不同变量时，导致 CPU缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，引发性能下降。

### LongAdder 源码

#### add方法

```java
LongAdder adder = new LongAdder();
adder.increment();
long x: 累加值
Cell[] as: 累加单元数组cells的引用
long b: 获取的base值
long v: 期望值（当前cell存储的值）
int m: cells数组的长度
Cell a: 当前线程命中的cell单元格
boolean uncontended: 表示cell是否没有竞争
========================================================================
public class LongAdder extends Striped64 implements Serializable {

    public void increment() {
        add(1L);
    }

    public void add(long x) {
        Cell[] as; long b, v; int m; Cell a;
        // 进入 if 的两个条件
       // 条件1：as 有值, 表示已经发生过竞争, 进入 if
       // 条件2：cas 给 base 累加时失败了, 表示 base 发生了竞争, 进入 if
       // 由于 cells 是懒惰初始化，刚开始是null，会先进行casBase操作
        if ((as = cells) != null || !casBase(b = base, b + x)) {    
            boolean uncontended = true;
            /*
          条件1: cells为空，说明正在出现竞争，上面是从条件2过来的，说明!casBase(b = base, b + x))=true
               会通过调用longAccumulate(x, null, uncontended)新建一个数组，默认长度是2
          条件2: 默认会新建一个数组长度为2的数组，m = as.length - 1 < 0 应该不会出现
          条件3: 当前线程所在的cell为空，说明当前线程还没有更新过cell，uncontended为true，应初始化一个cell
          条件4: 更新当前线程所在的cell失败，说明竞争很激烈，多个线程hash到同一个Cell，uncontended为false，应扩容
          **/
            if (as == null || (m = as.length - 1) < 0 || (a = as[getProbe() & m]) == null || !(uncontended = a.cas(v = a.value, v + x)))
                longAccumulate(x, null, uncontended); // 创建cells数组的流程
        }
    }
}
```

**add 各种场景：**

1. cells = null，casBase(b = base, b + x)累加失败，执行 longAccumulate(x, null, uncontended);
2. cells != null，as[getProbe() & m] == null 表示当前线程还没创建cell，执行 longAccumulate(x, null, uncontended);
3. cells != null，如果as[getProbe() & m] != null 表示当前线程创建了cell，执行累加单元cell的cas操作：a.cas(v = a.value, v + x)，失败则执行 longAccumulate(x, null, uncontended);

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233815257.png" alt="image-20250613233815257" style="zoom:50%;" />

小结：

1. 最开始只更新base
2. 更新失败，则新创建一个Cell[]数组
3. 多个线程竞争到同一个Cell时，进行Cell[]数组扩容

#### 继承Striped64中的 longAccumulate方法

##### getProbe()方法获取线程hash值

```java
// Striped64中的longAccumulate方法
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    // 存储线程的hash值，有了hash值就可以知道当前线程进入哪个槽位
    int h;
    // 如果getProbe()方法返回0，说明随机数未初始化，需要初始化后，线程才能进入对应槽位
    if ((h = getProbe()) == 0) {
       // 使用ThreadLocalRandom为当前线程重新计算一个hash值，强制初始化
       ThreadLocalRandom.current(); 
       // 重新获取hash值
       h = getProbe();
       // 重新获取hash值后，认为此次不算是一次竞争，都未初始化，肯定还不存在竞争激烈，所以wasUncontended竞争状态为true
       wasUncontended = true;
}

// Striped64中的getProbe方法，得到当前线程的hash值PROBE
static final int getProbe() {
     return UNSAFE.getInt(Thread.currentThread(), PROBE);
}
```

##### longAccumulate方法总体逻辑

![image-20250613233837054](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233837054.png)

① 第一个线程创建cells 并初始化 一个累加单元cell

```java
long x: 累加值
LongBinaryOperator fn: 默认null
boolean wasUncontended: 是否没竞争，false表示有竞争；只有cells初始化之后，并且CAS累加值失败，才为false

long base: 类似于AtomicLong中全局的value值。在没有竞争情况下数据直接累加到base上，或者cells扩容时,也需要将数据写入到base上
boolean collide: 表示扩容意向，false一定不会扩容，true可能会扩容
cellsBusy: 初始化cells或者扩容cells需要获取锁，0表示无锁状态，1表示其他线程已经持有了锁
casCellsBusy: 通过CAS操作修改cellsBusy的值， CAS成功代表获取锁，返回true
NCPU: 当前计算机CPU数量，Cell数组扩容时会使用到
getProbe(): 获取当前线程的hash值
advanceProbe(): 重置当前线程的hash值

=================================================================================================

final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    int h;
    // 获取线程hash值，前面已经分析过，将代码隐藏
    if ((h = getProbe()) == 0) {...}
    boolean collide = false;             
    for (;;) {
        Cell[] as; Cell a; int n; long v;
        // 后面分析第一个if,先将代码隐藏
        if ((as = cells) != null && (n = as.length) > 0) {...}
            // 创建cells的场景
        else if (cellsBusy == 0 && cells == as && casCellsBusy()) {
            boolean init = false;
            try {                           // Initialize table
                if (cells == as) { // 再次检查cells引用是否改变，双重检测是为了避免并发场景下，重复创建cells
                    Cell[] rs = new Cell[2]; // 创建长度为2的cell数组
                    rs[h & 1] = new Cell(x); // 将累加值x随机存放到cell数组对应的索引下标位置
                    cells = rs; // 再将创建的cell数组引用赋值给cells
                    init = true;
                }
            } finally {
                cellsBusy = 0; // 创建完cell数组后，解锁
            }
            if (init)
                break; // 退出循环
        }
            // 尝试cas累加
        else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
            break;                          // Fall back on using base
    }
}
```

1. 进入for循环，先进入第一个else if，cellsBusy == 0 还未加锁，cells == as 表示cells是当前线程的引用，其他线程还未创建cells，casCellsBusy()方法通过cas尝试将cellsBusy改为1表示加锁，加锁成功，其他线程就不会来干扰cells的创建
2. casCellsBusy()方法通过cas尝试加锁失败后，进入第二个else if，casBase()方法尝试cas累加，成功则返回，失败则重新进入for循环

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233851198.png" alt="image-20250613233851198" style="zoom:50%;" />

② 在第一个线程基础上，第二个线程赋值给cell中的空槽位

```java
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    int h;
    if ((h = getProbe()) == 0) {...}
    boolean collide = false;         
    for (;;) {
        Cell[] as; Cell a; int n; long v;
        // 分析第一个if
        if ((as = cells) != null && (n = as.length) > 0) { // cells已经被创建
            if ((a = as[(n - 1) & h]) == null) {// cells虽然创建了，但是其中累加单元cell[0]或cell[1]还没被其他线程使用，则进入该if
                if (cellsBusy == 0) { // 其他线程没使用，自然也就没加锁  
                    Cell r = new Cell(x); // 创建累加单元，还没赋值到cells数组中 
                    // 该if是将创建的累加单元，设置到cells数组的空位置（cell[0]或cell[1]位置）
                    // 双重检测cellsBusy == 0，避免并发场景时重复赋值
                    if (cellsBusy == 0 && casCellsBusy()) {// 进入该if之前casCellsBusy()尝试加锁，保证赋值时是线程安全的
                        boolean created = false;
                        try {               // Recheck under lock
                            Cell[] rs; int m, j;
                            if ((rs = cells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {// 再次判断即将赋值的槽位不为空
                                rs[j] = r; // 赋值到空槽位
                                created = true;
                            }
                        } finally {
                            cellsBusy = 0; // 解锁
                        }
                        if (created)
                            break;  // 退出
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
                ......
        }
        else if (cellsBusy == 0 && cells == as && casCellsBusy()) {...}
        else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
            break;                          // Fall back on using base
    }
}
```

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233905427.png" alt="image-20250613233905427" style="zoom:50%;" />

③ 线程获取到了已经有值的累加单元cell，并在该cell上尝试进行累加

```java
final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {
    int h;
    if ((h = getProbe()) == 0) {...}
    boolean collide = false;           
    for (;;) {
        Cell[] as; Cell a; int n; long v;
        if ((as = cells) != null && (n = as.length) > 0) {
            // 已经分析过
            if ((a = as[(n - 1) & h]) == null) {...}
            else if (!wasUncontended)       // wasUncontended为false说明在同一个槽位竞争失败
                wasUncontended = true;      // 跳到下面h = advanceProbe(h)位置，重新hash换一个槽位累加

                // 尝试对已经有值的累加单元cell进行累加，成功则退出
            else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
                break;

                // 累加失败，判断是否超过CPU上限  
            else if (n >= NCPU || cells != as)
                // 这个设计很巧妙
                // 超过CPU上限后，设置collide = false，为了让下次循环进入 else if (!collide)而不是进入下面的else if (cellsBusy == 0 && casCellsBusy())，防止进行扩容
                // 跳到下面h = advanceProbe(h)位置，重新hash换一个槽位累加
                collide = false;       
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 && casCellsBusy()) {// 其他线程没加锁，当前线程进入时再自己加锁
                try {
                    // 对cells进行扩容
                    if (cells == as) {      // Expand table unless stale
                        Cell[] rs = new Cell[n << 1]; // 每次扩容2倍，创建更多空槽位的累加单元
                        for (int i = 0; i < n; ++i)
                        rs[i] = as[i]; // 将旧数组拷贝到新数组
                        cells = rs;
                    }
                } finally {
                    cellsBusy = 0; // 解锁
                }
                collide = false;
                continue;  // 重新找槽位                 // Retry with expanded table
            }
            // 执行到这一步说明，前面的步骤都没成功，需要尝试换一个累加单元进行累加
            h = advanceProbe(h);
        }
        else if (cellsBusy == 0 && cells == as && casCellsBusy()) {...}
        else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))
            break;                          // Fall back on using base
    }
}
```

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233919930.png" alt="image-20250613233919930" style="zoom:50%;" />

##### 小结：longAccumulate方法流程图

![image-20250613233931851](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233931851.png)

#### sum 方法

- 返回当前总和，返回的值不是原子快照；
- 在没有并发更新的情况下调用会返回准确的结果，但在计算总和时发生的并发更新可能不会被合并。

```java
public long sum() {
    Cell[] as = cells; Cell a;
    long sum = base;
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}
```

### **高并发下sum的值不精确的原因**

**sum执行时，并没有限制对base和cells的更新。所以LongAdder不是强一致性，而是最终一致性**

- 首先，最终返回的sum局部变量，初始被赋值为base，在最终返回时，可能有其他线程再次更新base，而此时局部变量sum不会更新，造成不一致
- 其次，这里对cell的读取也无法保证是最后一次写入的值

### LongAdder 总结

#### 采用分段CAS降低重试频率（这种分段的做法类似于JDK7中ConcurrentHashMap的分段锁）

- 高并发环境下，value变量其实是一个热点数据，也就是N个线程竞争一个热点。
- LongAdder的基本思路就是分散热点，将value值的新增操作分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个value值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。
- LongAdder有一个全局变量volatile long base值，当并发不高的情况下都是通过CAS来直接操作base值，如果CAS失败，则针对LongAdder中的Cell[]数组中的Cell进行CAS操作，减少失败的概率。
- 统计累加数据：sum() = base + Cell[]中的各Cell对象的value值之和。
- 而AtomicLong是多个线程针对单个热点value值进行原子操作。

#### 惰性求值

- LongAdder只有在使用longValue()获取当前累加值时才会真正的去结算计数的数据，longValue()方法底层就是调用sum()方法，对base和Cell数组的数据累加然后返回，做到数据写入和读取分离。
- 而AtomicLong使用incrementAndGet()每次都会返回long类型的计数值，每次递增后还会伴随着数据返回，增加了额外的开销。

#### AtomicLong VS LongAdder

AtomicLong：

- AtomicLong实现原理是基于CAS+自旋操作，CAS是基于硬件来实现原子性，保障线程安全。
- AtomicLong使用场景：低并发下的全局计数器、序列号生成器。
- AtomicLong优势：占用空间小；缺点：高并发下性能急剧下降（N个线程同时进行自旋，N-1个线程会自旋失败、不断重试）。

LongAdder：

- LongAdder设计思想：空间换时间，分散value值的热点数据；实现原理：高并发时采用Cell数组进行分段CAS。
- LongAdder使用场景：高并发下的全局计数器。
- LongAdder优势：能减少CAS重试次数、能防止伪共享、惰性求值；缺点：使用sum统计时如果有并发更新，可能导致统计的数据有误差。

![image-20250613233947075](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613233947075.png)

## threadlocal

### 作用

- 提供线程 `局部变量`，每个线程 `Thread` 拥有一份自己的 `副本变量`，多个线程互不干扰

### 使用场景

- 上下文 context 传递

  - 一个对象需要在多个方法中层次传递使用，比如用户身份、任务信息、调用链 ID、关联 ID(如日志的 uniqueID，方便串起多个日志)等，如果此时使用责任链模式给每个方法添加一个 context 参数会比较麻烦，而此时就可以使用 ThreadLocal 设置参数，需要使用时 get 一下即可。
- 线程间数据隔离

  - spring 事务通过 threadlocal 保证单个线程中的数据库操作使用的是同一个 `Connection` 链接

### 底层结构

![image-20250613234000563](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234000563.png)

- `Thread` 中有 `threadLocals` 对象

  - ThreadLocal.ThreadLocalMap，即 ThreadLocalMap 是 ThreadLocal 的静态内部类
- 也就是说每一个 `线程` 中都有一个 `ThreadLocalMap`（Map）对象，操作自己的 map 肯定线程安全

#### ThreadLocalMap 的底层结构

```java
static class ThreadLocalMap {

    private Entry[] table;
    
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
}
```

ThreadLocalMap 的数据结构其实是很像 HashMap，但是也有一些差异：

- 它并未实现 Map 接口，而且他的 Entry 是继承 WeakReference（弱引用）的。
- 没有像 HashMap 有 next 指针，所以 ThreadLocalMap 不存在链表。

> - key -> threadLocal
>
>   - 弱引用
> - value -> 存储的值

下面看个例子：

```java
public class Test {

    public ThreadLocal<String> threadLocal1 = new ThreadLocal<>();
    public ThreadLocal<Map<String, Integer>> threadLocal2 = new ThreadLocal<>();

    public void test() {
        threadLocal1.set("1");
        Map<String, Integer> hashMap = new HashMap<>();
        hashMap.put("test", 2);
        threadLocal2.set(hashMap);
    }
}
```

**最终 Thread 中的 threadLocals 对象为：**

![image-20250613234017660](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234017660.png)

一个线程可以有**多个** `ThreadLocal` 来存放不同类型的对象，所以需要数组来存。

#### **为什么要设计为弱引用**

我们在上文分析过，`ThreadLocal` 是和线程挂钩的，当一个线程的任务运行完毕后，`ThreadLocal` 的值就再也用不上了，因为它只服务于这个线程里面的任务，任务都运行完了，那么 `ThreadLocal` 的存在就没有用了。正是考虑到这个问题，所以 JVM 希望在一个任务运行完毕后，`ThreadLocal` 能够自己清理掉一部分无用数据以节省内存！

那么，`ThreadLocal` 是如何自己清理这一部分无用数据的呢？我们分析一下 `set` 方法：

```java
private void set(ThreadLocal<?> key, Object value) {
    ....
    if (!cleanSomeSlots(i, sz) && sz >= threshold)
      //重新进行哈希运算  
      rehash();
}
```

`rehash` 中会调用 `resize` 方法，最终在 `resize` 方法中会做 `key` 的清理：

```java
    private void resize() {
      ....
        for (int j = 0; j < oldLen; ++j) {
            Entry e = oldTab[j];
            if (e != null) {
                ThreadLocal<?> k = e.get();
                //如果key为空
                if (k == null) {
                    //将value也设置为空 以方便value被jvm回收
                    e.value = null; // Help the GC
                } else {
                   ....
                }
            }
        }
      ....
    }
```

我们在调用 set/get/remove/rehash 任意一个方法，ThreadLocal 都会验证 key 是否为 null，如果确实是 key 为 null，则将 value 也设置为 null。这样 value 的强引用就被断开了，value 就会被 JVM 回收。

事实上，我们通过分析可以得知，**弱引用的设计恰恰就是为了帮我们解决内存泄漏的问题的**，弱引用的存在能够使得对象在使用完毕后自动将 key 变为 null，从而使得 ThreadLocal 能够发现这些 key 为 null 的数据然后清除的。

但是因为 ThreadLocalMap 是定义在 Thread 中的，而 Thread 又是**线程池**里面的线程，是一个不会停止的线程，所以导致 ThreadLocalMap 永远也不会释放。我们在使用 ThreadLocal 往里面 set 值的时候如果不调用 set/get/remove/rehash 任意一个方法，那么就会导致 ThreadLocalMap 中的 `null -> value` 即使已经完全没有作用，但是这辈子也不会被释放的问题！

> **注意**，即使我们不使用线程池也绕不开这个问题，你不主动使用线程池但是你所用的 Tomcat 里面用的有线程池呀，一个请求被分发到 controller 这个过程其实就对应着一个 Tomcat 线程池中的线程执行任务的过程！
>
> 所以，在使用过程中一定要注意：使用完毕后调用 remove 删除！使用完毕后调用 remove 删除！使用完毕后调用 remove 删除！重要的事情说三遍。

#### 没有了链表怎么解决 Hash 冲突的

![image-20250613234032730](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234032730.png)

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234047454.png" alt="image-20250613234047454" style="zoom:60%;" />

先根据 key(ThreadLocal 对象)计算出在数组中的 index 位置：

1. 如果 index 为空，直接新建一个 Entry 对象放 index 位置上
2. 如果 index 不为空，key(ThreadLocal)对象相等，直接更新 Entry 中 value 值
3. 如果 index 不为空，且 key(ThreadLocal)对象不相等（出现 hash 冲突了），那就找下一个空位置，直到为空为止。

### 原理

- 通过 threadlocal 获取 thread 对象
- 获取 thread 对象中的 threadlocal map 对象
- 操作自己的 map 对象

### 内存泄漏

分析一下以下代码的引用关系：

```java
public class Test {

    public ThreadLocal<Map<String, Integer>> threadLocal1 = new ThreadLocal<>();

    public void test() {
        Map<String, Integer> hashMap = new HashMap<>();
        hashMap.put("key1", 1);
        hashMap.put("key2", 2);
        hashMap.put("key3", 3);
        hashMap.put("key4", 4);
        threadLocal1.set(hashMap);
    }
}
```

- ![image-20250613234107534](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234107534.png)
- 代码运行时

  - Thread `强引用` ThreadLocalMap，`强引用` value(hashMap)
  - Thread `强引用` ThreadLocalMap，`弱引用` key(threadLocal1 对象)
  - Test 对象 `强引用` threadLocal1 对象
- 代码运行完

  - Test 对象被回收，失去对 threadLocal1 的引用
  - ThreadLocalMap 对 ThreadLocal 对象是弱引用，gc 时也会被回收
  - value 对象是被 ThreadLocalMap 引用，而 ThreadLocalMap 被 Thread 引用线程池复用，只要 Thread 不被销毁，则 value 对象一直无法被回收

![image-20250613234121516](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234121516.png)

##### 如何解决

`Thread` 对象被线程池控制，我们很难干预。所以我们关键解决思路是去掉 `ThreadLocalMap` 对 `value` 对象的引用。

**当 ThreadLocal(key）被垃圾回收后，ThreadLocalMap 的 key 变为了 null, 但 value 值依然存在：**

![image-20250613234135566](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234135566.png)

- 在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录
- 使用完 ThreadLocal 对象后 `手动remove`

##### ThreadLocalMap 设计的时候为什么不把 value 也设计成弱引用？

ThreadLocalMap 的 key 设计成了弱引用，而弱引用在垃圾回收的时候就会被回收掉，如果我写的程序运行时间较长，岂不是很危险。程序运行到一半，ThreadLocal 对象就被回收了？

**看看上面我分析过的代码：**

```java
public class Test {

    public ThreadLocal<Map<String, Integer>> threadLocal1 = new ThreadLocal<>();

    public void test() {
        Map<String, Integer> hashMap = new HashMap<>();
        hashMap.put("key1", 1);
        hashMap.put("key2", 2);
        hashMap.put("key3", 3);
        hashMap.put("key4", 4);
        threadLocal1.set(hashMap);
    }
}
```

**引用关系：**

![image-20250613234150135](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234150135.png)

**为什么不会有问题？**

虽然 ThreadLocalMap 对 key（ThreadLocal）是弱引用，但是业务代码 Test 对象对 key（ThreadLocal）对象**是强引用**。所以 ThreadLocal 不会被垃圾回收，直到业务代码 Test 对象运行完毕被垃圾回收，然后才会回收 ThreadLocal 对象。这也是 ThreadLocal 设计的精妙的地方。ThreadLocal 对象随业务代码回收而回收。

**那为何 Value 不设置成弱引用？**

因为不清楚这个 Value 除了 ThreadLocalMap 的引用还是否还存在其他引用，如果不存在其他引用，当 GC 的时候就会直接将这个 Value 干掉了，而此时我们的 ThreadLocal 还处于使用期间，就会造成 Value 为 null 的错误，所以将其设置为强引用。

## FastThreadLocal

### **数数 ThreadLocal 的缺点**

ThreadLocal 的一个缺点：hash 冲突用的是[线性探测法](https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E6%8E%A2%E6%B5%8B%E6%B3%95&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，效率低。

![image-20250613234203130](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234203130.png)

图上显示的是经过两个遍历找到了空位，假设冲突多了，需要遍历的次数就多了。并且下次 get 的时候，hash 直接命中的位置发现不是要找的 Entry ，于是就接着遍历向后找，所以说这个效率低。

而像 HashMap 是通过[链表法](https://www.zhihu.com/search?q=%E9%93%BE%E8%A1%A8%E6%B3%95&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)来解决冲突，并且为了防止链表过长遍历的开销变大，在一定条件之后又会转变成[红黑树](https://www.zhihu.com/search?q=%E7%BA%A2%E9%BB%91%E6%A0%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)来查找，这样的解决方案在频繁冲突的条件下，肯定是优于线性探测法，所以这是一个优化方向。

还有一个缺点是 ThreadLocal 使用了 WeakReference 以保证资源可以被释放，但是这可能会产生一些 Etnry 的 key 为 null，即无用的 Entry 存在。

所以调用 ThreadLocal 的 set 方法时，会主动清理无用的 Entry，减轻[内存泄漏](https://www.zhihu.com/search?q=%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)的发生。

### **应该如何针对 ThreadLocal 缺点改进**

前面提到 ThreadLocal hash 冲突的线性探测法不好，还有 Entry 的弱引用可能会发生内存泄漏，这些都和 ThreadLocalMap 有关，所以需要搞个新的 map 来替换 ThreadLocalMap。

而这个 ThreadLocalMap 又是 Thread 里面的一个[成员变量](https://www.zhihu.com/search?q=%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，这么一看 Thread 也得动一动，但是我们又无法修改 Thread 的代码，所以配套的还得弄个新的 Thread。

所以我们不仅得弄个新的 ThreadLocal、ThreadLocalMap 还得弄个配套的 Thread 来用上新的 ThreadLocalMap 。

所以如果想改进 ThreadLocal ，就需要动这三个类。

对应到 Netty 的实现就是 FastThreadLocal、InternalThreadLocalMap、FastThreadLocalThread

![image-20250613234215764](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234215764.png)

然后发散一下思维，既然 Hash 冲突的想线性探测效果不好，你可能比较容易想到的就是上面提到的链表法，然后再基于链表法说个改成红黑树，这个确实是一方面，但是可以再想想。

比如，让 Hash 不冲突，所以设计一个不会冲突的 hash 算法？不存在的！

所以怎么样才不会产生冲突呢？

各自取号入座

什么意思？就是每往 InternalThreadLocalMap 中塞入一个新的 FastThreadLocal 对象，就给这个对象发个唯一的下标，然后让这个对象记住这个下标，到时候去 InternalThreadLocalMap 找 value 的时候，直接通过下标去取对应的 value 。

这样不就不会冲突了？

这就是 FastThreadLocal 给出的方案，具体下面分析。

还有个内存泄漏的问题，这个其实只要规范的使用即用完后 remove 就好了，其实也没太好的解决方案，不过 FastThreadLocal 曲线救国了一下，这个也且看下面的分析！

### **FastThreadLocal 的原理**

![image-20250613234227725](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234227725.png)

可以看到有个叫 variablesToRemoveIndex 的类成员，并且用 final 修饰的，所以等于每个 FastThreadLocal 都有个共同的不可变 int 值。

然后看到这个 index 没，在 FastThreadLocal 构造的时候就被赋值了，且也被 final 修饰，所以也不可变，这个 index 就是我上面说的给每个新 FastThreadLocal 都发个唯一的下标，这样每个 index 就都知道自己的位置了。

上面两个 index 都是通过 `InternalThreadLocalMap.nextVariableIndex()` 赋值的，盲猜一下，这个肯定是用原子类递增实现的。

![image-20250613234240124](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234240124.png)

确实，在 InternalThreadLocalMap 也定义了一个[静态原子类](https://www.zhihu.com/search?q=%E9%9D%99%E6%80%81%E5%8E%9F%E5%AD%90%E7%B1%BB&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，每次调用 nextVariableIndex 就返回且递增，没有什么别的赋值操作，从这里也可以得知 variablesToRemoveIndex 的值为 0，因为它属于[常量赋值](https://www.zhihu.com/search?q=%E5%B8%B8%E9%87%8F%E8%B5%8B%E5%80%BC&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)，第一次调用时 nextIndex 的值为 0 。

InternalThreadLocalMap 对标的就是之前的 ThreadLocalMap 也就是 ThreadLocal 缺点集中的类，需要重点看下。

我们再来回顾一下 ThreadLocalMap 的定义。

![image-20250613234252550](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234252550.png)

它是个 Entry 数组，然后 Entry 里面弱引用了 ThreadLocal 作为 Key。

而 InternalThreadLocalMap 有点不太一样：

![image-20250613234303899](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234303899.png)

可以看到， InternalThreadLocalMap 好像放弃了 map 的形式，没用定义 key 和 value，而是一个 Object 数组？

那它是如何通过 Object 来存储  FastThreadLocal 和对应的 value 的呢？我们从 `FastThreadLocal#set` 开始分析：

![image-20250613234321544](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234321544.png)

因为我们已经熟悉 ThreadLocal 的套路，所以我们知道 InternalThreadLocalMap 肯定是 FastThreadLocalThread 里面的一个变量。

然后我们从对应的 FastThreadLocalThread 里面拿到了 map 之后，就要执行塞入操作即 `setKnownNotUnset`。

我们先看一下塞入操作里面的 `setIndexedVariable` 方法：

![image-20250613234334584](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234334584.png)

可以看到，根据传入构造 FastThreadLocal 生成的唯一 index 可以直接从 Object 数组里面找到下标并且进行替换，这样一来压根就不会产生冲突，逻辑很简单，完美。

那如果塞入的 value 不是 UNSET(默认值)，则执行 `addToVariablesToRemove` 方法，这个方法又有什么用呢？

![image-20250613234346264](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234346264.png)

是不是看着有点奇怪？这是啥操作？别急，看我画个图来解释解释：

、![image-20250613234357876](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234357876.png)

这就是 Object 数组的核心关系图了，第一个位置放了一个 set ，set 里面存储了所有使用的 FastThreadLocal 对象，然后数组后面的位置都放 value。

那为什么要放一个 set 保存所有使用的 FastThreadLocal 对象？

用于删除，你想想看，假设现在要清空线程里面的所有 FastThreadLocal ，那必然得有一个地方来存放这些 FastThreadLocal 对象，这样才能找到这些家伙，然后干掉。

所以刚好就把数组的第一个位置腾出来放一个 set 来保存这些 FastThreadLocal 对象，如果要删除全部 FastThreadLocal 对象的时候，只需要遍历这个 set ，得到 FastThreadLocal 的 index 找到数组对应的 位置将 value 置空，然后把 FastThreadLocal 从 set 中移除即可。

刚好 FastThreadLocal 里面实现了这个方法，我们来看下：

![image-20250613234414028](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234414028.png)

我们做下小结，理一理上面说的：

首先 InternalThreadLocalMap 没有采用 ThreadLocalMap k-v形式的存储方式，而是用 Object 数组来存储 FastThreadLocal 对象和其 value，具体是在第一个位置存放了一个包含所使用的 FastThreadLocal 对象的 set，然后后面存储所有的 value。

之所以需要个 set 是为了存储所有使用的 FastThreadLocal 对象，这样就能找到这些对象，便于后面的删除工作。

之所以数组其他位置可以直接存储 value ，是因为每个 FastThreadLocal 构造的时候已经被分配了一个唯一的下标，这个下标对应的就是 value 所处的下标。

看到这里，不知道大家是否有感受到空间的浪费？

我举个例子。

假设系统里面一个 new 了 100 个 FastThreadLocal ，那第 100 个 FastThreadLocal 的下标就是 100 ，这个应该没有疑义。

从上面的 set 方法可以得知，只有调用 set 的时候，才会从当前线程中拿出 InternalThreadLocalMap ，然后往这个 map 的数组里面塞入 value，这里我们再回顾一下 set 的方法。

![image-20250613234426753](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234426753.png)

那这里是什么意思呢？

如果我这个线程之前都没塞过 FastThreadLocal ，此时要塞入第一个 FastThreadLocal ，构造出来的[数组长度](https://www.zhihu.com/search?q=%E6%95%B0%E7%BB%84%E9%95%BF%E5%BA%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)是32，但是这个 FastThreadLocal 的下标已经涨到了 100 了，所以这个线程第一次塞值，也仅仅只有这么一个值，数组就需要扩容。

看到没，这就是我所说的浪费，空间被浪费了。

Netty 相关实现者知道这样会浪费空间，所以数组的扩容是基于 index 而不是原先数组的大小，你看看如果是基于原先数组的扩容，那么第一次扩容 2 倍，32 变成 64，还是塞不下下标 100 的数据，所以还得扩容一次，这就不美了。

所以可以看到扩容传进去的参数是 index 。

![image-20250613234437845](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234437845.png)

可以看到，直接基于 index 的向上 2 次幂取整。然后就是扩容的拷贝，这里是直接进行数组拷贝，不需要进行 rehash，而 ThreadLocalMap 的扩容需要进行rehash，也就是重新基于 key 的 hash 值进行位置的分配，所以这个也是 FastThreadLocal 优于ThreadLocal 的一个点。

对了，上面那个向上 2 [次幂取整](https://www.zhihu.com/search?q=%E6%AC%A1%E5%B9%82%E5%8F%96%E6%95%B4&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)的操作，不知道你们熟悉不熟悉，这个和 HashMap 的实现是一致的。

![image-20250613234451501](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234451501.png)

所以从上面的实现可以得知 Netty 就是特意这样设计的，用多余的空间去换取不会冲突的 set 和 get ，这样写入和获取的速度就更快了，这就是典型的空间换时间。

好了，想必此时你已经弄懂了 FastThreadLocal 的核心原理了，我们再来看看 get 方法的实现，我想你应该能脑补这个实现了。

![image-20250613234520109](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234520109.png)

吧，没啥难度，index 就是 FastThreadLocal 构造时候预先分配好的那个下标，然后直接进行一个数组下标查找，如果没找到就调用 init 方法进行初始化。

我们这里再继续探究一下`InternalThreadLocalMap.get()`，这里面做了一个兼容。不过我要先介绍一下 FastThreadLocalThread ，就是这玩意替代了  Thread。

![image-20250613234532404](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234532404.png)

可以看到它继承了 Thread ，并且弄了一个成员变量就是我们前面说的 InternalThreadLocalMap。

然后我们再来看一下 get 方法，我截了好几个，不过逻辑很简单。

![image-20250613234542611](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234542611.png)

这里之所以分了 fastGet 和 slowGet 是为了做一个兼容，假设有个不熟悉的人，他用了 FastThreadLocal 但是没有配套使用 FastThreadLocalThread ，然后调用 FastThreadLocal#get 的时候去 Thread 里面找 InternalThreadLocalMap 那不就傻了吗，会报错的。

所以就再弄了个 slowThreadLocalMap ，它是个 ThreadLocal ，里面保存 InternalThreadLocalMap 来兼容一下这个情况。

从这里我们也能得知，FastThreadLocal 最好和 FastThreadLocalThread 配套使用，不然就隔了一层了。

```java
FastThreadLocal<String> threadLocal = new FastThreadLocal<String>();
Thread t = new FastThreadLocalThread(new Runnable() { //记得要 new FastThreadLocalThread
     public void run() {
      threadLocal.get()；
      ....
     }
 });
```

好了，get 和 set 这两个核心操作都分析完了，我们最后再来看一下 remove 操作吧。

![image-20250613234612985](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234612985.png)

很简单对吧，把数组里的 value 给覆盖了，然后再到  set  里把对应的 FastThreadLocal 对象给删了。

不过看到这里，可能有人会发出疑惑，内存泄漏相关的点呢？

其实吧，可以看到 FastThreadLocal 就没用弱引用，所以它把无用 FastThreadLocal 的清理就寄托到规范使用上，即没用了就主动调用 remove 方法。

但是它曲线救国了一下，我们来看一下 FastThreadLocalRunnable 这个类：

![image-20250613234627396](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234627396.png)

我已经把重点画出来了，可以看到这个 Runnable 执行完毕之后，会主动调用 FastThreadLocal.removeAll() 来清理所有的 FastThreadLocal，这就是我说的曲线救国，怕你完了调用 remove ，没事我帮你封装一下，就是这么贴心。

当然，这个前提是你不能用 Runnable 而是用 FastThreadLocalRunnable。不过这里 Netty 也是做了封装的。

Netty 实现了一个 DefaultThreadFactory 工厂类来创建线程。

![image-20250613234639716](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234639716.png)

你看，你传入 Runnable 是吧，没事，我把它包成 FastThreadLocalRunnable，并且我 new 回去的线程是 FastThreadLocalThread 类型，这样就能在很大程度上避免使用的错误，也减少了使用的难度。

这也是工厂方法这个[设计模式](https://www.zhihu.com/search?q=%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3081281023%7D)的好处之一啦。所以工程上如果怕对方没用对，我们就封装了再给别人使用，这样也屏蔽了一些细节，他好你也好。

### **FastThreadLocal VS ThreadLocal**

到此，我们已经充分了解了两者之间的不同，但是 Fast 到底有多 Fast 呢？

我们用实验说话，Netty 源码里面已经有 benchmark 了，我们直接跑就行了

里面有两个实验：

FastPath 对应的是使用 FastThreadLocalThread 线程对象。

SlowPath 对应的是使用 Thread 线程对象。

![image-20250613234654117](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234654117.png)

两个实验都是分别定义了 ThreadLocal 和 FastThreadLocal ：

![image-20250613234706513](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234706513.png)

我们来看一下执行的结果：

FastPath:

![image-20250613234718107](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234718107.png)

SlowPath:

![image-20250613234728224](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234728224.png)

可以看到搭配 FastThreadLocalThread 来使用 FastThreadLocal 吞吐确实比使用 ThreadLocal 大。

### 总结

- FastThreadLocal 通过分配下标直接定位 value ，不会有 hash 冲突，效率较高。

  - ![image-20250613234738634](https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250613234738634.png)

    可以看到有个叫 variablesToRemoveIndex 的类成员，并且用 final 修饰的，所以等于每个 FastThreadLocal 都有个共同的不可变 int 值。

    然后看到这个 index 没，在 FastThreadLocal 构造的时候就被赋值了，且也被 final 修饰，所以也不可变，这个 index 就是我上面说的给每个新 FastThreadLocal 都发个唯一的下标，这样每个 index 就都知道自己的位置了。
- FastThreadLocal 采用空间换时间的方式来提高效率。
- FastThreadLocal 需要配套 FastThreadLocalThread 使用，不然还不如原生 ThreadLocal。
- FastThreadLocal 使用最好配套 FastThreadLocalRunnable，这样执行完任务后会主动调用 removeAll 来移除所有 FastThreadLocal ，防止内存泄漏。
- FastThreadLocal 的使用也是推荐用完之后，主动调用 remove。





## 线程调度实现

### 抢占式调度

- 每条线程执行的时间、线程的切换都由系统控制
- 一个线程的堵塞不会导致整个进程堵塞
- 有的线程可能永远抢不到
- `JVM实现的是抢占式调度`

### 协同式调度

- 某一线程执行完后主动通知系统切换到另一线程上执行
- 像接力赛一样
- 如果一个线程编写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃

## 线程的调度策略

线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行:

1. 线程体中调用了 yield 方法让出了对 cpu 的占用权利
2. 线程体中调用了 sleep 方法使线程进入睡眠状态
3. 线程由于 IO 操作受到阻塞
4. 另外一个更高优先级线程出现
5. 在支持时间片的系统中，该线程的时间片用完

## 进程调度算法

### 优先调度算法

- 先来先服务调度算法(FCFS)

  - 每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。
- 短作业(进程)优先调度算法

  - 从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。

‍

### 高优先权优先调度算法

当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程。

### 高响应比优先调度算法

<img src="https://gitee.com/JBL_lun/tuchuang/raw/master/assets/image-20250614000559767.png" alt="image-20250614000559767" style="zoom:50%;" />

- 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。
- 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。

> 简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。

### 基于时间片的轮转调度算法

- 系统将所有的就绪进程按先来先服务的原则排成一个队列
- 每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片
- 由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾

### 多级反馈队列调度算法

- 设置多个就绪队列，并为各个队列赋予不同的优先级

  - 第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低
  - 在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小
- 当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度
- 当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统
- 如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行